{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acy925/CS598DLH_Project/blob/main/concare_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OecOHOeXmjL1",
        "outputId": "83570f90-3151-457c-ad42-fe1fcf4a10b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!ls drive/MyDrive/\n",
        "# unzip data.zip in /ColabData\n",
        "#!unzip 'drive/MyDrive/Colab Data/data.zip' -d 'drive/MyDrive/Colab Data/Conore Data'\n",
        "# take time: 8m 15s"
      ],
      "metadata": {
        "id": "nolG_w-b3xaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !/opt/bin/nvidia-smi"
      ],
      "metadata": {
        "id": "V6wX0omO0hHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load utilies dictionary\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/Conore')"
      ],
      "metadata": {
        "id": "r1zejOcC21CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "import imp\n",
        "import re\n",
        "import pickle\n",
        "import datetime\n",
        "import random\n",
        "import math\n",
        "import copy\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "from torch.utils import data\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from utils import utils\n",
        "from utils.readers import InHospitalMortalityReader\n",
        "from utils.preprocessing import Discretizer, Normalizer\n",
        "from utils import metrics\n",
        "from utils import common_utils"
      ],
      "metadata": {
        "id": "PhcWXm42AIY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWs2OrlQkmcV"
      },
      "source": [
        "### Prepare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:11:20.237620Z",
          "start_time": "2021-11-02T02:11:20.234044Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vVBpfvWkmcX",
        "outputId": "eaaecd64-419f-4c85-ef76-40299dcb7972"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/MyDrive/Colab Data/Conore Data/data\n"
          ]
        }
      ],
      "source": [
        "data_path = 'drive/MyDrive/Colab Data/Conore Data/data'\n",
        "file_name = 'drive/My Drive/Colab Notebooks/Conore/model'\n",
        "small_part = False\n",
        "arg_timestep = 1.0\n",
        "batch_size = 256\n",
        "epochs = 100\n",
        "\n",
        "print(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:11:20.399479Z",
          "start_time": "2021-11-02T02:11:20.239796Z"
        },
        "id": "DL_aQNDjkmcX"
      },
      "outputs": [],
      "source": [
        "# Build readers, discretizers, normalizers\n",
        "train_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data_path, 'train'),\n",
        "                                         listfile=os.path.join(data_path, 'train_listfile.csv'),\n",
        "                                         period_length=48.0)\n",
        "\n",
        "val_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data_path, 'train'),\n",
        "                                       listfile=os.path.join(data_path, 'val_listfile.csv'),\n",
        "                                       period_length=48.0)\n",
        "\n",
        "# 这个函数不理解用处\n",
        "discretizer = Discretizer(timestep=arg_timestep,\n",
        "                          store_masks=True,\n",
        "                          impute_strategy='previous',\n",
        "                          start_time='zero')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:11:20.411518Z",
          "start_time": "2021-11-02T02:11:20.401666Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2EdPp5MkmcY",
        "outputId": "acf2de87-47f1-4fc6-da5f-9b9ea154769b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ihm_normalizer\n",
            "drive/MyDrive/Colab Data/Conore Data/data/ihm_normalizer\n",
            "drive/MyDrive/Colab Data/Conore Data/data\n"
          ]
        }
      ],
      "source": [
        "discretizer_header = discretizer.transform(train_reader.read_example(0)[\"X\"])[1].split(',')\n",
        "cont_channels = [i for (i, x) in enumerate(discretizer_header) if x.find(\"->\") == -1]\n",
        "\n",
        "normalizer = Normalizer(fields=cont_channels)  # choose here which columns to standardize\n",
        "normalizer_state = 'ihm_normalizer'\n",
        "print(normalizer_state)\n",
        "normalizer_state = 'drive/MyDrive/Colab Data/Conore Data/data/ihm_normalizer'\n",
        "normalizer.load_params(normalizer_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:12:44.729970Z",
          "start_time": "2021-11-02T02:11:20.413422Z"
        },
        "id": "YqxmepTJkmcZ"
      },
      "outputs": [],
      "source": [
        "n_trained_chunks = 0\n",
        "train_raw = utils.load_data(train_reader, discretizer, normalizer, small_part, return_names=True)\n",
        "val_raw = utils.load_data(val_reader, discretizer, normalizer, small_part, return_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:12:48.064359Z",
          "start_time": "2021-11-02T02:12:44.733279Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeovCBL0kmca",
        "outputId": "006e37dd-85b7-4a26-8566-542fddfb7fc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ],
      "source": [
        "demographic_data = []\n",
        "diagnosis_data = []\n",
        "idx_list = []\n",
        "\n",
        "demo_path = 'drive/MyDrive/Colab Data/Conore Data/data/demographic/'\n",
        "for cur_name in os.listdir(demo_path):\n",
        "    cur_id, cur_episode = cur_name.split('_', 1)\n",
        "    cur_episode = cur_episode[:-4]\n",
        "    cur_file = demo_path + cur_name\n",
        "\n",
        "    with open(cur_file, \"r\") as tsfile:\n",
        "        header = tsfile.readline().strip().split(',')\n",
        "        if header[0] != \"Icustay\":\n",
        "            continue\n",
        "        cur_data = tsfile.readline().strip().split(',')\n",
        "        \n",
        "    if len(cur_data) == 1:\n",
        "        cur_demo = np.zeros(12)\n",
        "        cur_diag = np.zeros(128)\n",
        "    else:\n",
        "        if cur_data[3] == '':\n",
        "            cur_data[3] = 60.0\n",
        "        if cur_data[4] == '':\n",
        "            cur_data[4] = 160\n",
        "        if cur_data[5] == '':\n",
        "            cur_data[5] = 60\n",
        "\n",
        "        cur_demo = np.zeros(12)\n",
        "        cur_demo[int(cur_data[1])] = 1\n",
        "        cur_demo[5 + int(cur_data[2])] = 1\n",
        "        cur_demo[9:] = cur_data[3:6]\n",
        "        cur_diag = np.array(cur_data[8:], dtype=np.int)\n",
        "\n",
        "    demographic_data.append(cur_demo)\n",
        "    diagnosis_data.append(cur_diag)\n",
        "    idx_list.append(cur_id+'_'+cur_episode)\n",
        "\n",
        "for each_idx in range(9,12):\n",
        "    cur_val = []\n",
        "    for i in range(len(demographic_data)):\n",
        "        cur_val.append(demographic_data[i][each_idx])\n",
        "    cur_val = np.array(cur_val)\n",
        "    _mean = np.mean(cur_val)\n",
        "    _std = np.std(cur_val)\n",
        "    _std = _std if _std > 1e-7 else 1e-7\n",
        "    for i in range(len(demographic_data)):\n",
        "        demographic_data[i][each_idx] = (demographic_data[i][each_idx] - _mean) / _std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:12:48.079449Z",
          "start_time": "2021-11-02T02:12:48.067022Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzO1BESVkmcb",
        "outputId": "8831ae48-da7f-4bb9-c80f-9b2db145b191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "available device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() == True else 'cpu')\n",
        "#device = torch.device('cpu')\n",
        "print(\"available device: {}\".format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4p7kD3Xkmcc"
      },
      "source": [
        "### model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:12:48.189439Z",
          "start_time": "2021-11-02T02:12:48.082871Z"
        },
        "id": "wKMDoV05kmcc"
      },
      "outputs": [],
      "source": [
        "class SingleAttention(nn.Module):\n",
        "    def __init__(self, attention_input_dim, attention_hidden_dim, attention_type='add', demographic_dim=12, time_aware=False, use_demographic=False):\n",
        "        super(SingleAttention, self).__init__()\n",
        "        \n",
        "        self.attention_type = attention_type\n",
        "        self.attention_hidden_dim = attention_hidden_dim\n",
        "        self.attention_input_dim = attention_input_dim\n",
        "        self.use_demographic = use_demographic\n",
        "        self.demographic_dim = demographic_dim\n",
        "        self.time_aware = time_aware\n",
        "\n",
        "        # batch_time = torch.arange(0, batch_mask.size()[1], dtype=torch.float32).reshape(1, batch_mask.size()[1], 1)\n",
        "        # batch_time = batch_time.repeat(batch_mask.size()[0], 1, 1)\n",
        "        \n",
        "        if attention_type == 'add':\n",
        "            if self.time_aware == True:\n",
        "                # self.Wx = nn.Parameter(torch.randn(attention_input_dim+1, attention_hidden_dim))\n",
        "                self.Wx = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
        "                self.Wtime_aware = nn.Parameter(torch.randn(1, attention_hidden_dim))\n",
        "                nn.init.kaiming_uniform_(self.Wtime_aware, a=math.sqrt(5))\n",
        "            else:\n",
        "                self.Wx = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
        "            self.Wt = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
        "            self.Wd = nn.Parameter(torch.randn(demographic_dim, attention_hidden_dim))\n",
        "            self.bh = nn.Parameter(torch.zeros(attention_hidden_dim,))\n",
        "            self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
        "            self.ba = nn.Parameter(torch.zeros(1,))\n",
        "            \n",
        "            nn.init.kaiming_uniform_(self.Wd, a=math.sqrt(5))\n",
        "            nn.init.kaiming_uniform_(self.Wx, a=math.sqrt(5))\n",
        "            nn.init.kaiming_uniform_(self.Wt, a=math.sqrt(5))\n",
        "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
        "        elif attention_type == 'mul':\n",
        "            self.Wa = nn.Parameter(torch.randn(attention_input_dim, attention_input_dim))\n",
        "            self.ba = nn.Parameter(torch.zeros(1,))\n",
        "            \n",
        "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
        "        elif attention_type == 'concat':\n",
        "            if self.time_aware == True:\n",
        "                self.Wh = nn.Parameter(torch.randn(2*attention_input_dim+1, attention_hidden_dim))\n",
        "            else:\n",
        "                self.Wh = nn.Parameter(torch.randn(2*attention_input_dim, attention_hidden_dim))\n",
        "\n",
        "            self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
        "            self.ba = nn.Parameter(torch.zeros(1,))\n",
        "            \n",
        "            nn.init.kaiming_uniform_(self.Wh, a=math.sqrt(5))\n",
        "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
        "            \n",
        "        elif attention_type == 'new':\n",
        "            self.Wt = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
        "            self.Wx = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
        "\n",
        "            self.rate = nn.Parameter(torch.zeros(1)+0.8)\n",
        "            nn.init.kaiming_uniform_(self.Wx, a=math.sqrt(5))\n",
        "            nn.init.kaiming_uniform_(self.Wt, a=math.sqrt(5))\n",
        "            \n",
        "        else:\n",
        "            raise RuntimeError('Wrong attention type.')\n",
        "        \n",
        "        self.tanh = nn.Tanh()\n",
        "        self.softmax = nn.Softmax()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, input, demo=None):\n",
        " \n",
        "        batch_size, time_step, input_dim = input.size() # batch_size * time_step * hidden_dim(i)\n",
        "        #assert(input_dim == self.input_dim)\n",
        "\n",
        "        # time_decays = torch.zeros((time_step,time_step)).to(device)# t*t\n",
        "        # for this_time in range(time_step):\n",
        "        #     for pre_time in range(time_step):\n",
        "        #         if pre_time > this_time:\n",
        "        #             break\n",
        "        #         time_decays[this_time][pre_time] = torch.tensor(this_time - pre_time, dtype=torch.float32).to(device)\n",
        "        # b_time_decays = tile(time_decays, 0, batch_size).view(batch_size,time_step,time_step).unsqueeze(-1).to(device)# b t t 1\n",
        "\n",
        "        time_decays = torch.tensor(range(47,-1,-1), dtype=torch.float32).unsqueeze(-1).unsqueeze(0).to(device)# 1*t*1\n",
        "        b_time_decays = time_decays.repeat(batch_size,1,1)+1# b t 1\n",
        "        \n",
        "        if self.attention_type == 'add': #B*T*I  @ H*I\n",
        "            q = torch.matmul(input[:,-1,:], self.Wt)# b h\n",
        "            q = torch.reshape(q, (batch_size, 1, self.attention_hidden_dim)) #B*1*H\n",
        "            if self.time_aware == True:\n",
        "                # k_input = torch.cat((input, time), dim=-1)\n",
        "                k = torch.matmul(input, self.Wx)#b t h\n",
        "                # k = torch.reshape(k, (batch_size, 1, time_step, self.attention_hidden_dim)) #B*1*T*H\n",
        "                time_hidden = torch.matmul(b_time_decays, self.Wtime_aware)#  b t h\n",
        "            else:\n",
        "                k = torch.matmul(input, self.Wx)# b t h\n",
        "                # k = torch.reshape(k, (batch_size, 1, time_step, self.attention_hidden_dim)) #B*1*T*H\n",
        "            if self.use_demographic == True:\n",
        "                d = torch.matmul(demo, self.Wd) #B*H\n",
        "                d = torch.reshape(d, (batch_size, 1, self.attention_hidden_dim)) # b 1 h\n",
        "            h = q + k + self.bh # b t h\n",
        "            if self.time_aware == True:\n",
        "                h += time_hidden\n",
        "            h = self.tanh(h) #B*T*H\n",
        "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
        "            e = torch.reshape(e, (batch_size, time_step))# b t\n",
        "        elif self.attention_type == 'mul':\n",
        "            e = torch.matmul(input[:,-1,:], self.Wa)#b i\n",
        "            e = torch.matmul(e.unsqueeze(1), input.permute(0,2,1)).squeeze() + self.ba #b t\n",
        "        elif self.attention_type == 'concat':\n",
        "            q = input[:,-1,:].unsqueeze(1).repeat(1,time_step,1)# b t i\n",
        "            k = input\n",
        "            c = torch.cat((q, k), dim=-1) #B*T*2I\n",
        "            if self.time_aware == True:\n",
        "                c = torch.cat((c, b_time_decays), dim=-1) #B*T*2I+1\n",
        "            h = torch.matmul(c, self.Wh)\n",
        "            h = self.tanh(h)\n",
        "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
        "            e = torch.reshape(e, (batch_size, time_step)) # b t \n",
        "            \n",
        "        elif self.attention_type == 'new':\n",
        "            \n",
        "            q = torch.matmul(input[:,-1,:], self.Wt)# b h\n",
        "            q = torch.reshape(q, (batch_size, 1, self.attention_hidden_dim)) #B*1*H\n",
        "            k = torch.matmul(input, self.Wx)#b t h\n",
        "            dot_product = torch.matmul(q, k.transpose(1, 2)).squeeze() # b t\n",
        "            denominator =  self.sigmoid(self.rate) * (torch.log(2.72 +  (1-self.sigmoid(dot_product)))* (b_time_decays.squeeze()))\n",
        "            e = self.relu(self.sigmoid(dot_product)/(denominator)) # b * t\n",
        "#          * (b_time_decays.squeeze())\n",
        "        # e = torch.exp(e - torch.max(e, dim=-1, keepdim=True).values)\n",
        "        \n",
        "        # if self.attention_width is not None:\n",
        "        #     if self.history_only:\n",
        "        #         lower = torch.arange(0, time_step).to(device) - (self.attention_width - 1)\n",
        "        #     else:\n",
        "        #         lower = torch.arange(0, time_step).to(device) - self.attention_width // 2\n",
        "        #     lower = lower.unsqueeze(-1)\n",
        "        #     upper = lower + self.attention_width\n",
        "        #     indices = torch.arange(0, time_step).unsqueeze(0).to(device)\n",
        "        #     e = e * (lower <= indices).float() * (indices < upper).float()\n",
        "        \n",
        "        # s = torch.sum(e, dim=-1, keepdim=True)\n",
        "        # mask = subsequent_mask(time_step).to(device) # 1 t t 下三角\n",
        "        # scores = e.masked_fill(mask == 0, -1e9)# b t t 下三角\n",
        "        a = self.softmax(e) #B*T\n",
        "        v = torch.matmul(a.unsqueeze(1), input).squeeze() #B*I\n",
        "\n",
        "        return v, a\n",
        "\n",
        "class FinalAttentionQKV(nn.Module):\n",
        "    def __init__(self, attention_input_dim, attention_hidden_dim, attention_type='add', dropout=None):\n",
        "        super(FinalAttentionQKV, self).__init__()\n",
        "        \n",
        "        self.attention_type = attention_type\n",
        "        self.attention_hidden_dim = attention_hidden_dim\n",
        "        self.attention_input_dim = attention_input_dim\n",
        "\n",
        "\n",
        "        self.W_q = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
        "        self.W_k = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
        "        self.W_v = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
        "\n",
        "        self.W_out = nn.Linear(attention_hidden_dim, 1)\n",
        "\n",
        "        self.b_in = nn.Parameter(torch.zeros(1,))\n",
        "        self.b_out = nn.Parameter(torch.zeros(1,))\n",
        "\n",
        "        nn.init.kaiming_uniform_(self.W_q.weight, a=math.sqrt(5))\n",
        "        nn.init.kaiming_uniform_(self.W_k.weight, a=math.sqrt(5))\n",
        "        nn.init.kaiming_uniform_(self.W_v.weight, a=math.sqrt(5))\n",
        "        nn.init.kaiming_uniform_(self.W_out.weight, a=math.sqrt(5))\n",
        "\n",
        "        self.Wh = nn.Parameter(torch.randn(2*attention_input_dim, attention_hidden_dim))\n",
        "        self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
        "        self.ba = nn.Parameter(torch.zeros(1,))\n",
        "        \n",
        "        nn.init.kaiming_uniform_(self.Wh, a=math.sqrt(5))\n",
        "        nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.softmax = nn.Softmax()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, input):\n",
        " \n",
        "        batch_size, time_step, input_dim = input.size() # batch_size * input_dim + 1 * hidden_dim(i)\n",
        "        input_q = self.W_q(input[:, -1, :]) # b h\n",
        "        input_k = self.W_k(input)# b t h\n",
        "        input_v = self.W_v(input)# b t h\n",
        "\n",
        "        if self.attention_type == 'add': #B*T*I  @ H*I\n",
        "\n",
        "            q = torch.reshape(input_q, (batch_size, 1, self.attention_hidden_dim)) #B*1*H\n",
        "            h = q + input_k + self.b_in # b t h\n",
        "            h = self.tanh(h) #B*T*H\n",
        "            e = self.W_out(h) # b t 1\n",
        "            e = torch.reshape(e, (batch_size, time_step))# b t\n",
        "\n",
        "        elif self.attention_type == 'mul':\n",
        "            q = torch.reshape(input_q, (batch_size, self.attention_hidden_dim, 1)) #B*h 1\n",
        "            e = torch.matmul(input_k, q).squeeze()#b t\n",
        "            \n",
        "        elif self.attention_type == 'concat':\n",
        "            q = input_q.unsqueeze(1).repeat(1,time_step,1)# b t h\n",
        "            k = input_k\n",
        "            c = torch.cat((q, k), dim=-1) #B*T*2I\n",
        "            h = torch.matmul(c, self.Wh)\n",
        "            h = self.tanh(h)\n",
        "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
        "            e = torch.reshape(e, (batch_size, time_step)) # b t \n",
        "        \n",
        "        a = self.softmax(e) #B*T\n",
        "        if self.dropout is not None:\n",
        "            a = self.dropout(a)\n",
        "        v = torch.matmul(a.unsqueeze(1), input_v).squeeze() #B*I\n",
        "\n",
        "        return v, a\n",
        "\n",
        "def clones(module, N):\n",
        "    \"Produce N identical layers.\"\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
        "\n",
        "def tile(a, dim, n_tile):\n",
        "    init_dim = a.size(dim)\n",
        "    repeat_idx = [1] * a.dim()\n",
        "    repeat_idx[dim] = n_tile\n",
        "    a = a.repeat(*(repeat_idx))\n",
        "    order_index = torch.LongTensor(np.concatenate([init_dim * np.arange(n_tile) + i for i in range(init_dim)])).to(device)\n",
        "    return torch.index_select(a, dim, order_index).to(device)\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module): # new added\n",
        "    \"Implements FFN equation.\"\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.w_1 = nn.Linear(d_model, d_ff)\n",
        "        self.w_2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w_2(self.dropout(F.relu(self.w_1(x)))), None\n",
        "\n",
        "# class PositionwiseFeedForwardConv(nn.Module):\n",
        "\n",
        "#     def __init__(self, model_dim=512, ffn_dim=2048, dropout=0.0):\n",
        "#         super(PositionalWiseFeedForward, self).__init__()\n",
        "#         self.w1 = nn.Conv1d(model_dim, ffn_dim, 1)\n",
        "#         self.w2 = nn.Conv1d(model_dim, ffn_dim, 1)\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "#         self.layer_norm = nn.LayerNorm(model_dim)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         output = x.transpose(1, 2)\n",
        "#         output = self.w2(F.relu(self.w1(output)))\n",
        "#         output = self.dropout(output.transpose(1, 2))\n",
        "\n",
        "#         # add residual and norm layer\n",
        "#         output = self.layer_norm(x + output)\n",
        "#         return output\n",
        "\n",
        "class PositionalEncoding(nn.Module): # new added / not use anymore\n",
        "    \"Implement the PE function.\"\n",
        "    def __init__(self, d_model, dropout, max_len=400):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        \n",
        "        # Compute the positional encodings once in log space.\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0., max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0., d_model, 2) * -(math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x + Variable(self.pe[:, :x.size(1)], \n",
        "                         requires_grad=False)\n",
        "        return self.dropout(x)\n",
        "\n",
        "def subsequent_mask(size):\n",
        "    \"Mask out subsequent positions.\"\n",
        "    attn_shape = (1, size, size)\n",
        "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
        "    return torch.from_numpy(subsequent_mask) == 0 # 下三角矩阵\n",
        "\n",
        "def attention(query, key, value, mask=None, dropout=None):\n",
        "    \"Compute 'Scaled Dot Product Attention'\"\n",
        "    d_k = query.size(-1)# b h t d_k\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
        "             / math.sqrt(d_k) # b h t t\n",
        "    if mask is not None:# 1 1 t t\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)# b h t t 下三角\n",
        "    p_attn = F.softmax(scores, dim = -1)# b h t t\n",
        "    if dropout is not None:\n",
        "        p_attn = dropout(p_attn)\n",
        "    return torch.matmul(p_attn, value), p_attn # b h t v (d_k) \n",
        "    \n",
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, h, d_model, dropout=0):\n",
        "        \"Take in model size and number of heads.\"\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        assert d_model % h == 0\n",
        "        # We assume d_v always equals d_k\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.linears = clones(nn.Linear(d_model, self.d_k * self.h), 3)\n",
        "        self.final_linear = nn.Linear(d_model, d_model)\n",
        "        self.attn = None\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        \n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        if mask is not None:\n",
        "            # Same mask applied to all h heads.\n",
        "            mask = mask.unsqueeze(1) # 1 1 t t\n",
        "\n",
        "        nbatches = query.size(0)# b\n",
        "        input_dim = query.size(1)# i+1\n",
        "        feature_dim = query.size(-1)# i+1\n",
        "\n",
        "        #input size -> # batch_size * d_input * hidden_dim\n",
        "        \n",
        "        # d_model => h * d_k \n",
        "        query, key, value = \\\n",
        "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "             for l, x in zip(self.linears, (query, key, value))] # b num_head d_input d_k\n",
        "        \n",
        "       \n",
        "        x, self.attn = attention(query, key, value, mask=mask, \n",
        "                                 dropout=self.dropout)# b num_head d_input d_v (d_k) \n",
        "\n",
        "      \n",
        "        x = x.transpose(1, 2).contiguous() \\\n",
        "             .view(nbatches, -1, self.h * self.d_k)# batch_size * d_input * hidden_dim\n",
        "\n",
        "        #DeCov \n",
        "        DeCov_contexts = x.transpose(0, 1).transpose(1, 2) # I+1 H B\n",
        "        Covs = cov(DeCov_contexts[0,:,:])\n",
        "        DeCov_loss = 0.5 * (torch.norm(Covs, p = 'fro')**2 - torch.norm(torch.diag(Covs))**2 ) \n",
        "        for i in range(feature_dim -1 + 1):\n",
        "            Covs = cov(DeCov_contexts[i+1,:,:])\n",
        "            DeCov_loss += 0.5 * (torch.norm(Covs, p = 'fro')**2 - torch.norm(torch.diag(Covs))**2 ) \n",
        "\n",
        "\n",
        "        return self.final_linear(x), DeCov_loss\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, features, eps=1e-7):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
        "\n",
        "def cov(m, y=None):\n",
        "    if y is not None:\n",
        "        m = torch.cat((m, y), dim=0)\n",
        "    m_exp = torch.mean(m, dim=1)\n",
        "    x = m - m_exp[:, None]\n",
        "    cov = 1 / (x.size(1) - 1) * x.mm(x.t())\n",
        "    return cov\n",
        "\n",
        "class SublayerConnection(nn.Module):\n",
        "    \"\"\"\n",
        "    A residual connection followed by a layer norm.\n",
        "    Note for code simplicity the norm is first as opposed to last.\n",
        "    \"\"\"\n",
        "    def __init__(self, size, dropout):\n",
        "        super(SublayerConnection, self).__init__()\n",
        "        self.norm = LayerNorm(size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        \"Apply residual connection to any sublayer with the same size.\"\n",
        "        returned_value = sublayer(self.norm(x))\n",
        "        return x + self.dropout(returned_value[0]) , returned_value[1]\n",
        "\n",
        "class ConCare(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, d_model,  MHD_num_head, d_ff, output_dim, keep_prob=0.5):\n",
        "        super(ConCare, self).__init__()\n",
        "\n",
        "        # hyperparameters\n",
        "        self.input_dim = input_dim  \n",
        "        self.hidden_dim = hidden_dim  # d_model\n",
        "        self.d_model = d_model\n",
        "        self.MHD_num_head = MHD_num_head\n",
        "        self.d_ff = d_ff\n",
        "        self.output_dim = output_dim\n",
        "        self.keep_prob = keep_prob\n",
        "\n",
        "        # layers\n",
        "        self.PositionalEncoding = PositionalEncoding(self.d_model, dropout = 0, max_len = 400)\n",
        "\n",
        "        self.GRUs = clones(nn.GRU(1, self.hidden_dim, batch_first = True), self.input_dim)\n",
        "        self.LastStepAttentions = clones(SingleAttention(self.hidden_dim, 8, attention_type='new', demographic_dim=12, time_aware=True, use_demographic=False),self.input_dim)\n",
        "        \n",
        "        self.FinalAttentionQKV = FinalAttentionQKV(self.hidden_dim, self.hidden_dim, attention_type='mul',dropout = 1 - self.keep_prob)\n",
        "\n",
        "        self.MultiHeadedAttention = MultiHeadedAttention(self.MHD_num_head, self.d_model,dropout = 1 - self.keep_prob)\n",
        "        self.SublayerConnection = SublayerConnection(self.d_model, dropout = 1 - self.keep_prob)\n",
        "\n",
        "        self.PositionwiseFeedForward = PositionwiseFeedForward(self.d_model, self.d_ff, dropout=0.1)\n",
        "\n",
        "        self.demo_proj_main = nn.Linear(12, self.hidden_dim)\n",
        "        self.demo_proj = nn.Linear(12, self.hidden_dim)\n",
        "        self.output0 = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "        self.output1 = nn.Linear(self.hidden_dim, self.output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(p = 1 - self.keep_prob)\n",
        "        self.tanh=nn.Tanh()\n",
        "        self.softmax = nn.Softmax()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.relu=nn.ReLU()\n",
        "\n",
        "    def forward(self, input, demo_input):\n",
        "        # input shape [batch_size, timestep, feature_dim]\n",
        "        demo_main = self.tanh(self.demo_proj_main(demo_input)).unsqueeze(1)# b hidden_dim\n",
        "        \n",
        "        batch_size = input.size(0)\n",
        "        time_step = input.size(1)\n",
        "        feature_dim = input.size(2)\n",
        "        assert(feature_dim == self.input_dim)# input Tensor : 256 * 48 * 76\n",
        "        assert(self.d_model % self.MHD_num_head == 0)\n",
        "\n",
        "        # Initialization\n",
        "        #cur_hs = Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0))\n",
        "\n",
        "        # forward\n",
        "        GRU_embeded_input = self.GRUs[0](input[:,:,0].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0)).to(device))[0] # b t h\n",
        "        Attention_embeded_input = self.LastStepAttentions[0](GRU_embeded_input)[0].unsqueeze(1)# b 1 h\n",
        "        for i in range(feature_dim-1):\n",
        "            embeded_input = self.GRUs[i+1](input[:,:,i+1].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0)).to(device))[0] # b 1 h\n",
        "            embeded_input = self.LastStepAttentions[i+1](embeded_input)[0].unsqueeze(1)# b 1 h\n",
        "            Attention_embeded_input = torch.cat((Attention_embeded_input, embeded_input), 1)# b i h\n",
        "\n",
        "        Attention_embeded_input = torch.cat((Attention_embeded_input, demo_main), 1)# b i+1 h\n",
        "        posi_input = self.dropout(Attention_embeded_input) # batch_size * d_input+1 * hidden_dim\n",
        "\n",
        "#         GRU_embeded_input = self.GRUs[0](input[:,:,0].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0)).to(device))[0][:,-1,:].unsqueeze(1) # b 1 h\n",
        "#         for i in range(feature_dim-1):\n",
        "#             embeded_input = self.GRUs[i+1](input[:,:,i+1].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0)).to(device))[0][:,-1,:].unsqueeze(1) # b 1 h\n",
        "#             GRU_embeded_input = torch.cat((GRU_embeded_input, embeded_input), 1)\n",
        "\n",
        "#         GRU_embeded_input = torch.cat((GRU_embeded_input, demo_main), 1)# b i+1 h\n",
        "#         posi_input = self.dropout(GRU_embeded_input) # batch_size * d_input * hidden_dim\n",
        "\n",
        "\n",
        "        #mask = subsequent_mask(time_step).to(device) # 1 t t 下三角 N to 1任务不用mask\n",
        "        contexts = self.SublayerConnection(posi_input, lambda x: self.MultiHeadedAttention(posi_input, posi_input, posi_input, None))# # batch_size * d_input * hidden_dim\n",
        "    \n",
        "        DeCov_loss = contexts[1]\n",
        "        contexts = contexts[0]\n",
        "\n",
        "        contexts = self.SublayerConnection(contexts, lambda x: self.PositionwiseFeedForward(contexts))[0]# # batch_size * d_input * hidden_dim\n",
        "        #contexts = contexts.view(batch_size, feature_dim * self.hidden_dim)#\n",
        "        # contexts = torch.matmul(self.Wproj, contexts) + self.bproj\n",
        "        # contexts = contexts.squeeze()\n",
        "        # demo_key = self.demo_proj(demo_input)# b hidden_dim\n",
        "        # demo_key = self.relu(demo_key)\n",
        "        # input_dim_scores = torch.matmul(contexts, demo_key.unsqueeze(-1)).squeeze() # b i\n",
        "        # input_dim_scores = self.dropout(self.sigmoid(input_dim_scores)).unsqueeze(1)# b i\n",
        "        \n",
        "        # weighted_contexts = torch.matmul(input_dim_scores, contexts).squeeze()\n",
        "\n",
        "        weighted_contexts = self.FinalAttentionQKV(contexts)[0]\n",
        "        output = self.output1(self.relu(self.output0(weighted_contexts)))# b 1\n",
        "        output = self.sigmoid(output)\n",
        "          \n",
        "        return output, DeCov_loss\n",
        "    #, self.MultiHeadedAttention.attn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:12:48.282265Z",
          "start_time": "2021-11-02T02:12:48.191901Z"
        },
        "id": "SBmPEKdKkmcf"
      },
      "outputs": [],
      "source": [
        "def get_loss(y_pred, y_true):\n",
        "    loss = torch.nn.BCELoss()\n",
        "    return loss(y_pred, y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:12:48.355893Z",
          "start_time": "2021-11-02T02:12:48.284802Z"
        },
        "id": "iPkFjqErkmcg"
      },
      "outputs": [],
      "source": [
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, x, y, name):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.name = name\n",
        "\n",
        "    def __getitem__(self, index):#返回的是tensor\n",
        "        return self.x[index], self.y[index], self.name[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:12:48.442051Z",
          "start_time": "2021-11-02T02:12:48.358759Z"
        },
        "id": "k5Yr2lP0kmch"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset(train_raw['data'][0], train_raw['data'][1], train_raw['names'])\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_dataset = Dataset(val_raw['data'][0], val_raw['data'][1], val_raw['names'])\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFK_WZ_rkmch"
      },
      "source": [
        "### Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T03:27:01.575443Z",
          "start_time": "2021-11-02T02:12:48.445259Z"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVJeeQ5skmch",
        "outputId": "9386ecca-0e38-4852-f3da-49a84635039f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Batch 0: Train Loss = 0.9401\n",
            "Model Loss = 0.7103, Decov Loss = 0.0003\n",
            "Epoch 0 Batch 30: Train Loss = 0.5329\n",
            "Model Loss = 0.4960, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3949\n",
            "valid_model Loss = 0.3949\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2786    0]\n",
            " [ 436    0]]\n",
            "accuracy = 0.8646803498268127\n",
            "precision class 0 = 0.8646803498268127\n",
            "precision class 1 = nan\n",
            "recall class 0 = 1.0\n",
            "recall class 1 = 0.0\n",
            "AUC of ROC = 0.737697333324552\n",
            "AUC of PRC = 0.32170599585603554\n",
            "min(+P, Se) = 0.3524027459954233\n",
            "f1_score = nan\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Conore/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
            "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0: Train Loss = 0.4264\n",
            "Model Loss = 0.4223, Decov Loss = 0.0000\n",
            "Epoch 1 Batch 30: Train Loss = 0.3982\n",
            "Model Loss = 0.3948, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3893\n",
            "valid_model Loss = 0.3893\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2786    0]\n",
            " [ 436    0]]\n",
            "accuracy = 0.8646803498268127\n",
            "precision class 0 = 0.8646803498268127\n",
            "precision class 1 = nan\n",
            "recall class 0 = 1.0\n",
            "recall class 1 = 0.0\n",
            "AUC of ROC = 0.7261417671582024\n",
            "AUC of PRC = 0.2987670138592318\n",
            "min(+P, Se) = 0.36281179138321995\n",
            "f1_score = nan\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Conore/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
            "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Batch 0: Train Loss = 0.4185\n",
            "Model Loss = 0.4160, Decov Loss = 0.0000\n",
            "Epoch 2 Batch 30: Train Loss = 0.3929\n",
            "Model Loss = 0.3904, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3410\n",
            "valid_model Loss = 0.3410\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2758   28]\n",
            " [ 402   34]]\n",
            "accuracy = 0.8665425181388855\n",
            "precision class 0 = 0.8727847933769226\n",
            "precision class 1 = 0.5483871102333069\n",
            "recall class 0 = 0.9899497628211975\n",
            "recall class 1 = 0.07798165082931519\n",
            "AUC of ROC = 0.7803647990937649\n",
            "AUC of PRC = 0.3869810793742962\n",
            "min(+P, Se) = 0.4334862385321101\n",
            "f1_score = 0.13654618431788462\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Batch 0: Train Loss = 0.3195\n",
            "Model Loss = 0.3175, Decov Loss = 0.0000\n",
            "Epoch 3 Batch 30: Train Loss = 0.3588\n",
            "Model Loss = 0.3562, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3379\n",
            "valid_model Loss = 0.3379\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2772   14]\n",
            " [ 396   40]]\n",
            "accuracy = 0.8727498650550842\n",
            "precision class 0 = 0.875\n",
            "precision class 1 = 0.7407407164573669\n",
            "recall class 0 = 0.9949748516082764\n",
            "recall class 1 = 0.0917431190609932\n",
            "AUC of ROC = 0.8136225030789597\n",
            "AUC of PRC = 0.4575385635364178\n",
            "min(+P, Se) = 0.463302752293578\n",
            "f1_score = 0.16326530666909386\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Batch 0: Train Loss = 0.3191\n",
            "Model Loss = 0.3173, Decov Loss = 0.0000\n",
            "Epoch 4 Batch 30: Train Loss = 0.3429\n",
            "Model Loss = 0.3410, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3187\n",
            "valid_model Loss = 0.3187\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2786    0]\n",
            " [ 436    0]]\n",
            "accuracy = 0.8646803498268127\n",
            "precision class 0 = 0.8646803498268127\n",
            "precision class 1 = nan\n",
            "recall class 0 = 1.0\n",
            "recall class 1 = 0.0\n",
            "AUC of ROC = 0.8161284798830324\n",
            "AUC of PRC = 0.4024362278780608\n",
            "min(+P, Se) = 0.4518348623853211\n",
            "f1_score = nan\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Conore/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
            "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Batch 0: Train Loss = 0.3639\n",
            "Model Loss = 0.3619, Decov Loss = 0.0000\n",
            "Epoch 5 Batch 30: Train Loss = 0.3389\n",
            "Model Loss = 0.3373, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3139\n",
            "valid_model Loss = 0.3139\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2786    0]\n",
            " [ 434    2]]\n",
            "accuracy = 0.8653010725975037\n",
            "precision class 0 = 0.865217387676239\n",
            "precision class 1 = 1.0\n",
            "recall class 0 = 1.0\n",
            "recall class 1 = 0.004587155766785145\n",
            "AUC of ROC = 0.8195951908954999\n",
            "AUC of PRC = 0.4485770704619446\n",
            "min(+P, Se) = 0.46396396396396394\n",
            "f1_score = 0.00913241954100871\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Batch 0: Train Loss = 0.3441\n",
            "Model Loss = 0.3426, Decov Loss = 0.0000\n",
            "Epoch 6 Batch 30: Train Loss = 0.3392\n",
            "Model Loss = 0.3377, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3173\n",
            "valid_model Loss = 0.3173\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2786    0]\n",
            " [ 436    0]]\n",
            "accuracy = 0.8646803498268127\n",
            "precision class 0 = 0.8646803498268127\n",
            "precision class 1 = nan\n",
            "recall class 0 = 1.0\n",
            "recall class 1 = 0.0\n",
            "AUC of ROC = 0.8111482214480001\n",
            "AUC of PRC = 0.4124137258043849\n",
            "min(+P, Se) = 0.44724770642201833\n",
            "f1_score = nan\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Conore/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
            "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Batch 0: Train Loss = 0.3040\n",
            "Model Loss = 0.3027, Decov Loss = 0.0000\n",
            "Epoch 7 Batch 30: Train Loss = 0.3304\n",
            "Model Loss = 0.3289, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3154\n",
            "valid_model Loss = 0.3154\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2712   74]\n",
            " [ 346   90]]\n",
            "accuracy = 0.8696461915969849\n",
            "precision class 0 = 0.8868541717529297\n",
            "precision class 1 = 0.5487805008888245\n",
            "recall class 0 = 0.9734386205673218\n",
            "recall class 1 = 0.20642201602458954\n",
            "AUC of ROC = 0.8170357027601969\n",
            "AUC of PRC = 0.42057004860200026\n",
            "min(+P, Se) = 0.4541284403669725\n",
            "f1_score = 0.2999999935812422\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Batch 0: Train Loss = 0.3491\n",
            "Model Loss = 0.3477, Decov Loss = 0.0000\n",
            "Epoch 8 Batch 30: Train Loss = 0.3241\n",
            "Model Loss = 0.3228, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3086\n",
            "valid_model Loss = 0.3086\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2714   72]\n",
            " [ 341   95]]\n",
            "accuracy = 0.8718187212944031\n",
            "precision class 0 = 0.888379693031311\n",
            "precision class 1 = 0.56886225938797\n",
            "recall class 0 = 0.9741564989089966\n",
            "recall class 1 = 0.2178899049758911\n",
            "AUC of ROC = 0.8279816513761468\n",
            "AUC of PRC = 0.43626569634886975\n",
            "min(+P, Se) = 0.46559633027522934\n",
            "f1_score = 0.3150912047191796\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Batch 0: Train Loss = 0.3258\n",
            "Model Loss = 0.3242, Decov Loss = 0.0000\n",
            "Epoch 9 Batch 30: Train Loss = 0.3259\n",
            "Model Loss = 0.3242, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3199\n",
            "valid_model Loss = 0.3199\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2731   55]\n",
            " [ 364   72]]\n",
            "accuracy = 0.8699565529823303\n",
            "precision class 0 = 0.8823909759521484\n",
            "precision class 1 = 0.5669291615486145\n",
            "recall class 0 = 0.9802584648132324\n",
            "recall class 1 = 0.1651376187801361\n",
            "AUC of ROC = 0.830670389957652\n",
            "AUC of PRC = 0.43663843590444473\n",
            "min(+P, Se) = 0.4660633484162896\n",
            "f1_score = 0.25577266468620335\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Batch 0: Train Loss = 0.2952\n",
            "Model Loss = 0.2931, Decov Loss = 0.0000\n",
            "Epoch 10 Batch 30: Train Loss = 0.3280\n",
            "Model Loss = 0.3262, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3097\n",
            "valid_model Loss = 0.3097\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2760   26]\n",
            " [ 397   39]]\n",
            "accuracy = 0.8687151074409485\n",
            "precision class 0 = 0.8742477297782898\n",
            "precision class 1 = 0.6000000238418579\n",
            "recall class 0 = 0.9906676411628723\n",
            "recall class 1 = 0.08944953978061676\n",
            "AUC of ROC = 0.8266306960753966\n",
            "AUC of PRC = 0.4385169225270195\n",
            "min(+P, Se) = 0.45871559633027525\n",
            "f1_score = 0.1556886246442593\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Batch 0: Train Loss = 0.3223\n",
            "Model Loss = 0.3206, Decov Loss = 0.0000\n",
            "Epoch 11 Batch 30: Train Loss = 0.3217\n",
            "Model Loss = 0.3203, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3086\n",
            "valid_model Loss = 0.3086\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2682  104]\n",
            " [ 307  129]]\n",
            "accuracy = 0.8724395036697388\n",
            "precision class 0 = 0.897290050983429\n",
            "precision class 1 = 0.553648054599762\n",
            "recall class 0 = 0.9626705050468445\n",
            "recall class 1 = 0.2958715558052063\n",
            "AUC of ROC = 0.8327861456693693\n",
            "AUC of PRC = 0.4486775679180261\n",
            "min(+P, Se) = 0.46788990825688076\n",
            "f1_score = 0.38565021755029133\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------ Save best model ------------\n",
            "\n",
            "Epoch 12 Batch 0: Train Loss = 0.3060\n",
            "Model Loss = 0.3045, Decov Loss = 0.0000\n",
            "Epoch 12 Batch 30: Train Loss = 0.3101\n",
            "Model Loss = 0.3086, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3045\n",
            "valid_model Loss = 0.3045\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2701   85]\n",
            " [ 323  113]]\n",
            "accuracy = 0.8733705878257751\n",
            "precision class 0 = 0.8931878209114075\n",
            "precision class 1 = 0.5707070827484131\n",
            "recall class 0 = 0.9694902896881104\n",
            "recall class 1 = 0.25917431712150574\n",
            "AUC of ROC = 0.8356609390333054\n",
            "AUC of PRC = 0.45244240801186975\n",
            "min(+P, Se) = 0.4752252252252252\n",
            "f1_score = 0.3564668714328123\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------ Save best model ------------\n",
            "\n",
            "Epoch 13 Batch 0: Train Loss = 0.2840\n",
            "Model Loss = 0.2823, Decov Loss = 0.0000\n",
            "Epoch 13 Batch 30: Train Loss = 0.3188\n",
            "Model Loss = 0.3173, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3042\n",
            "valid_model Loss = 0.3042\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2730   56]\n",
            " [ 362   74]]\n",
            "accuracy = 0.8702669143676758\n",
            "precision class 0 = 0.8829236626625061\n",
            "precision class 1 = 0.5692307949066162\n",
            "recall class 0 = 0.979899525642395\n",
            "recall class 1 = 0.16972477734088898\n",
            "AUC of ROC = 0.8311989172599563\n",
            "AUC of PRC = 0.43631560553449356\n",
            "min(+P, Se) = 0.45701357466063347\n",
            "f1_score = 0.26148411487166323\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Batch 0: Train Loss = 0.3156\n",
            "Model Loss = 0.3143, Decov Loss = 0.0000\n",
            "Epoch 14 Batch 30: Train Loss = 0.3100\n",
            "Model Loss = 0.3086, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2960\n",
            "valid_model Loss = 0.2960\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2751   35]\n",
            " [ 368   68]]\n",
            "accuracy = 0.8749223947525024\n",
            "precision class 0 = 0.8820134401321411\n",
            "precision class 1 = 0.6601941585540771\n",
            "recall class 0 = 0.9874371886253357\n",
            "recall class 1 = 0.15596330165863037\n",
            "AUC of ROC = 0.843937907097743\n",
            "AUC of PRC = 0.46571837807327127\n",
            "min(+P, Se) = 0.47477064220183485\n",
            "f1_score = 0.25231910684734804\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Batch 0: Train Loss = 0.2989\n",
            "Model Loss = 0.2966, Decov Loss = 0.0000\n",
            "Epoch 15 Batch 30: Train Loss = 0.3042\n",
            "Model Loss = 0.3024, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3033\n",
            "valid_model Loss = 0.3033\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2717   69]\n",
            " [ 324  112]]\n",
            "accuracy = 0.8780260682106018\n",
            "precision class 0 = 0.8934561014175415\n",
            "precision class 1 = 0.6187845468521118\n",
            "recall class 0 = 0.9752333164215088\n",
            "recall class 1 = 0.2568807303905487\n",
            "AUC of ROC = 0.8475099942701713\n",
            "AUC of PRC = 0.4719797852832624\n",
            "min(+P, Se) = 0.48623853211009177\n",
            "f1_score = 0.36304698854899303\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Batch 0: Train Loss = 0.3383\n",
            "Model Loss = 0.3357, Decov Loss = 0.0000\n",
            "Epoch 16 Batch 30: Train Loss = 0.3113\n",
            "Model Loss = 0.3092, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3093\n",
            "valid_model Loss = 0.3092\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2722   64]\n",
            " [ 340   96]]\n",
            "accuracy = 0.874612033367157\n",
            "precision class 0 = 0.8889614343643188\n",
            "precision class 1 = 0.6000000238418579\n",
            "recall class 0 = 0.9770280122756958\n",
            "recall class 1 = 0.22018349170684814\n",
            "AUC of ROC = 0.846002621231979\n",
            "AUC of PRC = 0.46898187583220124\n",
            "min(+P, Se) = 0.4793577981651376\n",
            "f1_score = 0.3221476602960259\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 Batch 0: Train Loss = 0.2856\n",
            "Model Loss = 0.2836, Decov Loss = 0.0000\n",
            "Epoch 17 Batch 30: Train Loss = 0.3153\n",
            "Model Loss = 0.3135, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3023\n",
            "valid_model Loss = 0.3023\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2689   97]\n",
            " [ 310  126]]\n",
            "accuracy = 0.8736809492111206\n",
            "precision class 0 = 0.896632194519043\n",
            "precision class 1 = 0.5650224089622498\n",
            "recall class 0 = 0.9651830792427063\n",
            "recall class 1 = 0.2889908254146576\n",
            "AUC of ROC = 0.8466180015411264\n",
            "AUC of PRC = 0.46495611722774655\n",
            "min(+P, Se) = 0.4782608695652174\n",
            "f1_score = 0.38239758230697996\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 Batch 0: Train Loss = 0.2769\n",
            "Model Loss = 0.2744, Decov Loss = 0.0000\n",
            "Epoch 18 Batch 30: Train Loss = 0.3133\n",
            "Model Loss = 0.3112, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3132\n",
            "valid_model Loss = 0.3132\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2712   74]\n",
            " [ 323  113]]\n",
            "accuracy = 0.87678462266922\n",
            "precision class 0 = 0.8935749530792236\n",
            "precision class 1 = 0.6042780876159668\n",
            "recall class 0 = 0.9734386205673218\n",
            "recall class 1 = 0.25917431712150574\n",
            "AUC of ROC = 0.8446109149943689\n",
            "AUC of PRC = 0.4808000448386853\n",
            "min(+P, Se) = 0.48623853211009177\n",
            "f1_score = 0.36276082953620903\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 Batch 0: Train Loss = 0.2855\n",
            "Model Loss = 0.2833, Decov Loss = 0.0000\n",
            "Epoch 19 Batch 30: Train Loss = 0.3075\n",
            "Model Loss = 0.3057, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3034\n",
            "valid_model Loss = 0.3034\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2695   91]\n",
            " [ 311  125]]\n",
            "accuracy = 0.8752327561378479\n",
            "precision class 0 = 0.8965402245521545\n",
            "precision class 1 = 0.5787037014961243\n",
            "recall class 0 = 0.9673366546630859\n",
            "recall class 1 = 0.28669723868370056\n",
            "AUC of ROC = 0.8509478914888993\n",
            "AUC of PRC = 0.4809701628218962\n",
            "min(+P, Se) = 0.5\n",
            "f1_score = 0.38343558747263484\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Batch 0: Train Loss = 0.3231\n",
            "Model Loss = 0.3216, Decov Loss = 0.0000\n",
            "Epoch 20 Batch 30: Train Loss = 0.3069\n",
            "Model Loss = 0.3050, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2889\n",
            "valid_model Loss = 0.2888\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2714   72]\n",
            " [ 319  117]]\n",
            "accuracy = 0.8786467909812927\n",
            "precision class 0 = 0.8948236107826233\n",
            "precision class 1 = 0.6190476417541504\n",
            "recall class 0 = 0.9741564989089966\n",
            "recall class 1 = 0.2683486342430115\n",
            "AUC of ROC = 0.8554346107997391\n",
            "AUC of PRC = 0.4930406734631453\n",
            "min(+P, Se) = 0.5137614678899083\n",
            "f1_score = 0.3744000142651367\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 Batch 0: Train Loss = 0.3345\n",
            "Model Loss = 0.3327, Decov Loss = 0.0000\n",
            "Epoch 21 Batch 30: Train Loss = 0.3091\n",
            "Model Loss = 0.3068, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2877\n",
            "valid_model Loss = 0.2877\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2695   91]\n",
            " [ 307  129]]\n",
            "accuracy = 0.8764742612838745\n",
            "precision class 0 = 0.8977348208427429\n",
            "precision class 1 = 0.5863636136054993\n",
            "recall class 0 = 0.9673366546630859\n",
            "recall class 1 = 0.2958715558052063\n",
            "AUC of ROC = 0.8541906781614493\n",
            "AUC of PRC = 0.49545245080451816\n",
            "min(+P, Se) = 0.505720823798627\n",
            "f1_score = 0.39329267442580984\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 Batch 0: Train Loss = 0.3220\n",
            "Model Loss = 0.3201, Decov Loss = 0.0000\n",
            "Epoch 22 Batch 30: Train Loss = 0.3026\n",
            "Model Loss = 0.3001, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2918\n",
            "valid_model Loss = 0.2917\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2737   49]\n",
            " [ 348   88]]\n",
            "accuracy = 0.87678462266922\n",
            "precision class 0 = 0.8871961236000061\n",
            "precision class 1 = 0.6423357725143433\n",
            "recall class 0 = 0.9824120402336121\n",
            "recall class 1 = 0.20183485746383667\n",
            "AUC of ROC = 0.8496446847606315\n",
            "AUC of PRC = 0.48973682349833153\n",
            "min(+P, Se) = 0.48853211009174313\n",
            "f1_score = 0.3071553178596298\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 Batch 0: Train Loss = 0.3027\n",
            "Model Loss = 0.3012, Decov Loss = 0.0000\n",
            "Epoch 23 Batch 30: Train Loss = 0.2949\n",
            "Model Loss = 0.2927, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2837\n",
            "valid_model Loss = 0.2837\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2718   68]\n",
            " [ 310  126]]\n",
            "accuracy = 0.8826815485954285\n",
            "precision class 0 = 0.8976221680641174\n",
            "precision class 1 = 0.6494845151901245\n",
            "recall class 0 = 0.9755922555923462\n",
            "recall class 1 = 0.2889908254146576\n",
            "AUC of ROC = 0.8594561931545011\n",
            "AUC of PRC = 0.5068028340633928\n",
            "min(+P, Se) = 0.5169300225733634\n",
            "f1_score = 0.3999999830734224\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 Batch 0: Train Loss = 0.3357\n",
            "Model Loss = 0.3343, Decov Loss = 0.0000\n",
            "Epoch 24 Batch 30: Train Loss = 0.2986\n",
            "Model Loss = 0.2965, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2859\n",
            "valid_model Loss = 0.2858\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2693   93]\n",
            " [ 292  144]]\n",
            "accuracy = 0.8805090188980103\n",
            "precision class 0 = 0.9021775722503662\n",
            "precision class 1 = 0.607594907283783\n",
            "recall class 0 = 0.9666188359260559\n",
            "recall class 1 = 0.3302752375602722\n",
            "AUC of ROC = 0.8611504442263743\n",
            "AUC of PRC = 0.5091358385933135\n",
            "min(+P, Se) = 0.5194508009153318\n",
            "f1_score = 0.42793462068659854\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 Batch 0: Train Loss = 0.2925\n",
            "Model Loss = 0.2906, Decov Loss = 0.0000\n",
            "Epoch 25 Batch 30: Train Loss = 0.2919\n",
            "Model Loss = 0.2900, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2829\n",
            "valid_model Loss = 0.2829\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2727   59]\n",
            " [ 321  115]]\n",
            "accuracy = 0.8820608258247375\n",
            "precision class 0 = 0.8946850299835205\n",
            "precision class 1 = 0.6609195470809937\n",
            "recall class 0 = 0.9788227081298828\n",
            "recall class 1 = 0.2637614607810974\n",
            "AUC of ROC = 0.8603173139616825\n",
            "AUC of PRC = 0.5105263591629122\n",
            "min(+P, Se) = 0.510250569476082\n",
            "f1_score = 0.3770491741793477\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 Batch 0: Train Loss = 0.2715\n",
            "Model Loss = 0.2695, Decov Loss = 0.0000\n",
            "Epoch 26 Batch 30: Train Loss = 0.3010\n",
            "Model Loss = 0.2988, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3000\n",
            "valid_model Loss = 0.2999\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2721   65]\n",
            " [ 340   96]]\n",
            "accuracy = 0.8743016719818115\n",
            "precision class 0 = 0.8889251947402954\n",
            "precision class 1 = 0.5962733030319214\n",
            "recall class 0 = 0.9766690731048584\n",
            "recall class 1 = 0.22018349170684814\n",
            "AUC of ROC = 0.8528759459156859\n",
            "AUC of PRC = 0.4917218302732291\n",
            "min(+P, Se) = 0.5\n",
            "f1_score = 0.3216080476497251\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 Batch 0: Train Loss = 0.3513\n",
            "Model Loss = 0.3494, Decov Loss = 0.0000\n",
            "Epoch 27 Batch 30: Train Loss = 0.3013\n",
            "Model Loss = 0.2995, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3298\n",
            "valid_model Loss = 0.3298\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2745   41]\n",
            " [ 352   84]]\n",
            "accuracy = 0.8780260682106018\n",
            "precision class 0 = 0.8863416314125061\n",
            "precision class 1 = 0.671999990940094\n",
            "recall class 0 = 0.9852835536003113\n",
            "recall class 1 = 0.19266055524349213\n",
            "AUC of ROC = 0.8557441532696247\n",
            "AUC of PRC = 0.5032088224381114\n",
            "min(+P, Se) = 0.5068181818181818\n",
            "f1_score = 0.29946524036141564\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 Batch 0: Train Loss = 0.2833\n",
            "Model Loss = 0.2814, Decov Loss = 0.0000\n",
            "Epoch 28 Batch 30: Train Loss = 0.3011\n",
            "Model Loss = 0.2996, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2908\n",
            "valid_model Loss = 0.2908\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2732   54]\n",
            " [ 331  105]]\n",
            "accuracy = 0.8805090188980103\n",
            "precision class 0 = 0.8919360041618347\n",
            "precision class 1 = 0.6603773832321167\n",
            "recall class 0 = 0.980617344379425\n",
            "recall class 1 = 0.24082568287849426\n",
            "AUC of ROC = 0.857957052628806\n",
            "AUC of PRC = 0.5083404663451102\n",
            "min(+P, Se) = 0.510250569476082\n",
            "f1_score = 0.35294118609690023\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 Batch 0: Train Loss = 0.2261\n",
            "Model Loss = 0.2242, Decov Loss = 0.0000\n",
            "Epoch 29 Batch 30: Train Loss = 0.2927\n",
            "Model Loss = 0.2908, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2874\n",
            "valid_model Loss = 0.2874\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2701   85]\n",
            " [ 295  141]]\n",
            "accuracy = 0.8820608258247375\n",
            "precision class 0 = 0.9015353918075562\n",
            "precision class 1 = 0.6238937973976135\n",
            "recall class 0 = 0.9694902896881104\n",
            "recall class 1 = 0.3233945071697235\n",
            "AUC of ROC = 0.8561722439194663\n",
            "AUC of PRC = 0.5064512987806012\n",
            "min(+P, Se) = 0.5113122171945701\n",
            "f1_score = 0.42598189486869414\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 Batch 0: Train Loss = 0.3124\n",
            "Model Loss = 0.3104, Decov Loss = 0.0000\n",
            "Epoch 30 Batch 30: Train Loss = 0.2880\n",
            "Model Loss = 0.2862, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2838\n",
            "valid_model Loss = 0.2838\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2680  106]\n",
            " [ 284  152]]\n",
            "accuracy = 0.8789571523666382\n",
            "precision class 0 = 0.9041835069656372\n",
            "precision class 1 = 0.5891472697257996\n",
            "recall class 0 = 0.9619526267051697\n",
            "recall class 1 = 0.3486238420009613\n",
            "AUC of ROC = 0.8589885864446742\n",
            "AUC of PRC = 0.5077161427899622\n",
            "min(+P, Se) = 0.5137614678899083\n",
            "f1_score = 0.4380403461678388\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31 Batch 0: Train Loss = 0.3676\n",
            "Model Loss = 0.3655, Decov Loss = 0.0000\n",
            "Epoch 31 Batch 30: Train Loss = 0.2941\n",
            "Model Loss = 0.2923, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2827\n",
            "valid_model Loss = 0.2826\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2720   66]\n",
            " [ 304  132]]\n",
            "accuracy = 0.8851644992828369\n",
            "precision class 0 = 0.8994709253311157\n",
            "precision class 1 = 0.6666666865348816\n",
            "recall class 0 = 0.976310133934021\n",
            "recall class 1 = 0.302752286195755\n",
            "AUC of ROC = 0.8630052292919381\n",
            "AUC of PRC = 0.52399559824559\n",
            "min(+P, Se) = 0.5344036697247706\n",
            "f1_score = 0.4164037695807846\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32 Batch 0: Train Loss = 0.3321\n",
            "Model Loss = 0.3307, Decov Loss = 0.0000\n",
            "Epoch 32 Batch 30: Train Loss = 0.2852\n",
            "Model Loss = 0.2834, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2881\n",
            "valid_model Loss = 0.2881\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2703   83]\n",
            " [ 284  152]]\n",
            "accuracy = 0.8860955834388733\n",
            "precision class 0 = 0.9049213528633118\n",
            "precision class 1 = 0.6468085050582886\n",
            "recall class 0 = 0.9702081680297852\n",
            "recall class 1 = 0.3486238420009613\n",
            "AUC of ROC = 0.8600505805567813\n",
            "AUC of PRC = 0.522056858472807\n",
            "min(+P, Se) = 0.5263157894736842\n",
            "f1_score = 0.4530551171808559\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33 Batch 0: Train Loss = 0.3271\n",
            "Model Loss = 0.3256, Decov Loss = 0.0000\n",
            "Epoch 33 Batch 30: Train Loss = 0.2953\n",
            "Model Loss = 0.2937, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2828\n",
            "valid_model Loss = 0.2828\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2719   67]\n",
            " [ 303  133]]\n",
            "accuracy = 0.8851644992828369\n",
            "precision class 0 = 0.8997352719306946\n",
            "precision class 1 = 0.6650000214576721\n",
            "recall class 0 = 0.9759511947631836\n",
            "recall class 1 = 0.30504587292671204\n",
            "AUC of ROC = 0.8592660221158215\n",
            "AUC of PRC = 0.5185778433762357\n",
            "min(+P, Se) = 0.5160550458715596\n",
            "f1_score = 0.4182389863900791\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34 Batch 0: Train Loss = 0.2530\n",
            "Model Loss = 0.2513, Decov Loss = 0.0000\n",
            "Epoch 34 Batch 30: Train Loss = 0.2877\n",
            "Model Loss = 0.2859, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2893\n",
            "valid_model Loss = 0.2893\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2704   82]\n",
            " [ 292  144]]\n",
            "accuracy = 0.8839230537414551\n",
            "precision class 0 = 0.9025366902351379\n",
            "precision class 1 = 0.6371681690216064\n",
            "recall class 0 = 0.9705671072006226\n",
            "recall class 1 = 0.3302752375602722\n",
            "AUC of ROC = 0.8616534507399383\n",
            "AUC of PRC = 0.5107897944587134\n",
            "min(+P, Se) = 0.5160550458715596\n",
            "f1_score = 0.4350453307299362\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 Batch 0: Train Loss = 0.2535\n",
            "Model Loss = 0.2519, Decov Loss = 0.0000\n",
            "Epoch 35 Batch 30: Train Loss = 0.2909\n",
            "Model Loss = 0.2890, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2822\n",
            "valid_model Loss = 0.2822\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2697   89]\n",
            " [ 288  148]]\n",
            "accuracy = 0.8829919099807739\n",
            "precision class 0 = 0.9035176038742065\n",
            "precision class 1 = 0.6244725584983826\n",
            "recall class 0 = 0.9680545330047607\n",
            "recall class 1 = 0.33944955468177795\n",
            "AUC of ROC = 0.8624865810046298\n",
            "AUC of PRC = 0.5209993466468578\n",
            "min(+P, Se) = 0.5252293577981652\n",
            "f1_score = 0.43982168775039476\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36 Batch 0: Train Loss = 0.2651\n",
            "Model Loss = 0.2638, Decov Loss = 0.0000\n",
            "Epoch 36 Batch 30: Train Loss = 0.2850\n",
            "Model Loss = 0.2833, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2785\n",
            "valid_model Loss = 0.2785\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2682  104]\n",
            " [ 275  161]]\n",
            "accuracy = 0.882371187210083\n",
            "precision class 0 = 0.9070003628730774\n",
            "precision class 1 = 0.6075471639633179\n",
            "recall class 0 = 0.9626705050468445\n",
            "recall class 1 = 0.3692660629749298\n",
            "AUC of ROC = 0.8650139623411949\n",
            "AUC of PRC = 0.5198192107921716\n",
            "min(+P, Se) = 0.5330296127562643\n",
            "f1_score = 0.45934381305681793\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37 Batch 0: Train Loss = 0.2669\n",
            "Model Loss = 0.2654, Decov Loss = 0.0000\n",
            "Epoch 37 Batch 30: Train Loss = 0.2885\n",
            "Model Loss = 0.2870, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2879\n",
            "valid_model Loss = 0.2879\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2709   77]\n",
            " [ 289  147]]\n",
            "accuracy = 0.8864059448242188\n",
            "precision class 0 = 0.9036024212837219\n",
            "precision class 1 = 0.65625\n",
            "recall class 0 = 0.9723618030548096\n",
            "recall class 1 = 0.3371559679508209\n",
            "AUC of ROC = 0.8643166685327028\n",
            "AUC of PRC = 0.5292451907723642\n",
            "min(+P, Se) = 0.5206422018348624\n",
            "f1_score = 0.44545456287508434\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38 Batch 0: Train Loss = 0.2983\n",
            "Model Loss = 0.2968, Decov Loss = 0.0000\n",
            "Epoch 38 Batch 30: Train Loss = 0.2915\n",
            "Model Loss = 0.2901, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2832\n",
            "valid_model Loss = 0.2832\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2695   91]\n",
            " [ 275  161]]\n",
            "accuracy = 0.8864059448242188\n",
            "precision class 0 = 0.9074074029922485\n",
            "precision class 1 = 0.6388888955116272\n",
            "recall class 0 = 0.9673366546630859\n",
            "recall class 1 = 0.3692660629749298\n",
            "AUC of ROC = 0.8604333923878896\n",
            "AUC of PRC = 0.5179901390150896\n",
            "min(+P, Se) = 0.5321100917431193\n",
            "f1_score = 0.46802325012427304\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39 Batch 0: Train Loss = 0.2272\n",
            "Model Loss = 0.2259, Decov Loss = 0.0000\n",
            "Epoch 39 Batch 30: Train Loss = 0.2849\n",
            "Model Loss = 0.2834, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2781\n",
            "valid_model Loss = 0.2781\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2716   70]\n",
            " [ 298  138]]\n",
            "accuracy = 0.8857852220535278\n",
            "precision class 0 = 0.9011280536651611\n",
            "precision class 1 = 0.6634615659713745\n",
            "recall class 0 = 0.9748743772506714\n",
            "recall class 1 = 0.3165137469768524\n",
            "AUC of ROC = 0.8654280577197916\n",
            "AUC of PRC = 0.538625070898873\n",
            "min(+P, Se) = 0.5294117647058824\n",
            "f1_score = 0.428571407993443\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40 Batch 0: Train Loss = 0.3592\n",
            "Model Loss = 0.3580, Decov Loss = 0.0000\n",
            "Epoch 40 Batch 30: Train Loss = 0.2887\n",
            "Model Loss = 0.2873, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2846\n",
            "valid_model Loss = 0.2846\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2704   82]\n",
            " [ 296  140]]\n",
            "accuracy = 0.8826815485954285\n",
            "precision class 0 = 0.9013333320617676\n",
            "precision class 1 = 0.630630612373352\n",
            "recall class 0 = 0.9705671072006226\n",
            "recall class 1 = 0.3211009204387665\n",
            "AUC of ROC = 0.8638243642853849\n",
            "AUC of PRC = 0.5296200744942346\n",
            "min(+P, Se) = 0.5321100917431193\n",
            "f1_score = 0.4255319000531669\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41 Batch 0: Train Loss = 0.2544\n",
            "Model Loss = 0.2531, Decov Loss = 0.0000\n",
            "Epoch 41 Batch 30: Train Loss = 0.2842\n",
            "Model Loss = 0.2826, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2836\n",
            "valid_model Loss = 0.2836\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2725   61]\n",
            " [ 306  130]]\n",
            "accuracy = 0.8860955834388733\n",
            "precision class 0 = 0.8990432024002075\n",
            "precision class 1 = 0.6806282997131348\n",
            "recall class 0 = 0.978104829788208\n",
            "recall class 1 = 0.29816514253616333\n",
            "AUC of ROC = 0.8657450094509245\n",
            "AUC of PRC = 0.5360434468015801\n",
            "min(+P, Se) = 0.5298165137614679\n",
            "f1_score = 0.41467305610824623\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42 Batch 0: Train Loss = 0.2772\n",
            "Model Loss = 0.2755, Decov Loss = 0.0000\n",
            "Epoch 42 Batch 30: Train Loss = 0.2808\n",
            "Model Loss = 0.2793, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2804\n",
            "valid_model Loss = 0.2804\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2667  119]\n",
            " [ 252  184]]\n",
            "accuracy = 0.8848541378974915\n",
            "precision class 0 = 0.9136690497398376\n",
            "precision class 1 = 0.6072607040405273\n",
            "recall class 0 = 0.9572864174842834\n",
            "recall class 1 = 0.4220183491706848\n",
            "AUC of ROC = 0.8647274709063008\n",
            "AUC of PRC = 0.5495243031753885\n",
            "min(+P, Se) = 0.5377574370709383\n",
            "f1_score = 0.49797025185062704\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43 Batch 0: Train Loss = 0.2051\n",
            "Model Loss = 0.2041, Decov Loss = 0.0000\n",
            "Epoch 43 Batch 30: Train Loss = 0.2880\n",
            "Model Loss = 0.2867, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2889\n",
            "valid_model Loss = 0.2889\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2739   47]\n",
            " [ 325  111]]\n",
            "accuracy = 0.884543776512146\n",
            "precision class 0 = 0.8939294815063477\n",
            "precision class 1 = 0.702531635761261\n",
            "recall class 0 = 0.9831299185752869\n",
            "recall class 1 = 0.2545871436595917\n",
            "AUC of ROC = 0.865340793087324\n",
            "AUC of PRC = 0.5357029995612169\n",
            "min(+P, Se) = 0.5298165137614679\n",
            "f1_score = 0.3737373707290654\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44 Batch 0: Train Loss = 0.3334\n",
            "Model Loss = 0.3325, Decov Loss = 0.0000\n",
            "Epoch 44 Batch 30: Train Loss = 0.2737\n",
            "Model Loss = 0.2723, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2875\n",
            "valid_model Loss = 0.2875\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2717   69]\n",
            " [ 296  140]]\n",
            "accuracy = 0.8867163062095642\n",
            "precision class 0 = 0.9017590284347534\n",
            "precision class 1 = 0.6698564887046814\n",
            "recall class 0 = 0.9752333164215088\n",
            "recall class 1 = 0.3211009204387665\n",
            "AUC of ROC = 0.8612352391050929\n",
            "AUC of PRC = 0.531151047756774\n",
            "min(+P, Se) = 0.536697247706422\n",
            "f1_score = 0.4341085491042307\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45 Batch 0: Train Loss = 0.2617\n",
            "Model Loss = 0.2602, Decov Loss = 0.0000\n",
            "Epoch 45 Batch 30: Train Loss = 0.2730\n",
            "Model Loss = 0.2717, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2735\n",
            "valid_model Loss = 0.2735\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2690   96]\n",
            " [ 265  171]]\n",
            "accuracy = 0.8879578113555908\n",
            "precision class 0 = 0.9103214740753174\n",
            "precision class 1 = 0.6404494643211365\n",
            "recall class 0 = 0.9655420184135437\n",
            "recall class 1 = 0.39220184087753296\n",
            "AUC of ROC = 0.8704194300466949\n",
            "AUC of PRC = 0.5673247964096535\n",
            "min(+P, Se) = 0.5353075170842825\n",
            "f1_score = 0.48648649864913424\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46 Batch 0: Train Loss = 0.2764\n",
            "Model Loss = 0.2750, Decov Loss = 0.0000\n",
            "Epoch 46 Batch 30: Train Loss = 0.2821\n",
            "Model Loss = 0.2809, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2932\n",
            "valid_model Loss = 0.2932\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2749   37]\n",
            " [ 343   93]]\n",
            "accuracy = 0.8820608258247375\n",
            "precision class 0 = 0.8890685439109802\n",
            "precision class 1 = 0.7153846025466919\n",
            "recall class 0 = 0.9867193102836609\n",
            "recall class 1 = 0.21330274641513824\n",
            "AUC of ROC = 0.8678706441776379\n",
            "AUC of PRC = 0.5476194634942679\n",
            "min(+P, Se) = 0.5308924485125858\n",
            "f1_score = 0.32862190506916705\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47 Batch 0: Train Loss = 0.2986\n",
            "Model Loss = 0.2974, Decov Loss = 0.0000\n",
            "Epoch 47 Batch 30: Train Loss = 0.2686\n",
            "Model Loss = 0.2670, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2873\n",
            "valid_model Loss = 0.2873\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2739   47]\n",
            " [ 325  111]]\n",
            "accuracy = 0.884543776512146\n",
            "precision class 0 = 0.8939294815063477\n",
            "precision class 1 = 0.702531635761261\n",
            "recall class 0 = 0.9831299185752869\n",
            "recall class 1 = 0.2545871436595917\n",
            "AUC of ROC = 0.8670251651442007\n",
            "AUC of PRC = 0.5480635457693798\n",
            "min(+P, Se) = 0.5361990950226244\n",
            "f1_score = 0.3737373707290654\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48 Batch 0: Train Loss = 0.3273\n",
            "Model Loss = 0.3264, Decov Loss = 0.0000\n",
            "Epoch 48 Batch 30: Train Loss = 0.2863\n",
            "Model Loss = 0.2852, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2743\n",
            "valid_model Loss = 0.2743\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2682  104]\n",
            " [ 259  177]]\n",
            "accuracy = 0.8873370289802551\n",
            "precision class 0 = 0.9119347333908081\n",
            "precision class 1 = 0.6298932433128357\n",
            "recall class 0 = 0.9626705050468445\n",
            "recall class 1 = 0.40596330165863037\n",
            "AUC of ROC = 0.869748480278193\n",
            "AUC of PRC = 0.5423819014774184\n",
            "min(+P, Se) = 0.5412844036697247\n",
            "f1_score = 0.4937238784718089\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49 Batch 0: Train Loss = 0.2434\n",
            "Model Loss = 0.2420, Decov Loss = 0.0000\n",
            "Epoch 49 Batch 30: Train Loss = 0.2817\n",
            "Model Loss = 0.2803, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2758\n",
            "valid_model Loss = 0.2757\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2676  110]\n",
            " [ 259  177]]\n",
            "accuracy = 0.8854748606681824\n",
            "precision class 0 = 0.9117546677589417\n",
            "precision class 1 = 0.6167247295379639\n",
            "recall class 0 = 0.9605168700218201\n",
            "recall class 1 = 0.40596330165863037\n",
            "AUC of ROC = 0.867738100726437\n",
            "AUC of PRC = 0.5431879317318519\n",
            "min(+P, Se) = 0.5504587155963303\n",
            "f1_score = 0.4896265523413147\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 Batch 0: Train Loss = 0.2777\n",
            "Model Loss = 0.2763, Decov Loss = 0.0000\n",
            "Epoch 50 Batch 30: Train Loss = 0.2723\n",
            "Model Loss = 0.2711, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2754\n",
            "valid_model Loss = 0.2754\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2722   64]\n",
            " [ 298  138]]\n",
            "accuracy = 0.8876474499702454\n",
            "precision class 0 = 0.9013245105743408\n",
            "precision class 1 = 0.6831682920455933\n",
            "recall class 0 = 0.9770280122756958\n",
            "recall class 1 = 0.3165137469768524\n",
            "AUC of ROC = 0.8706878099540956\n",
            "AUC of PRC = 0.5461267975248485\n",
            "min(+P, Se) = 0.5344036697247706\n",
            "f1_score = 0.43260184947666624\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51 Batch 0: Train Loss = 0.2496\n",
            "Model Loss = 0.2489, Decov Loss = 0.0000\n",
            "Epoch 51 Batch 30: Train Loss = 0.2750\n",
            "Model Loss = 0.2738, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2951\n",
            "valid_model Loss = 0.2951\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2747   39]\n",
            " [ 324  112]]\n",
            "accuracy = 0.8873370289802551\n",
            "precision class 0 = 0.8944969177246094\n",
            "precision class 1 = 0.7417218685150146\n",
            "recall class 0 = 0.9860014319419861\n",
            "recall class 1 = 0.2568807303905487\n",
            "AUC of ROC = 0.8670803229779304\n",
            "AUC of PRC = 0.5461212608028092\n",
            "min(+P, Se) = 0.5331807780320366\n",
            "f1_score = 0.38160134943228774\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52 Batch 0: Train Loss = 0.3527\n",
            "Model Loss = 0.3496, Decov Loss = 0.0000\n",
            "Epoch 52 Batch 30: Train Loss = 0.2793\n",
            "Model Loss = 0.2783, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2765\n",
            "valid_model Loss = 0.2765\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2709   77]\n",
            " [ 279  157]]\n",
            "accuracy = 0.8895096182823181\n",
            "precision class 0 = 0.9066265225410461\n",
            "precision class 1 = 0.6709401607513428\n",
            "recall class 0 = 0.9723618030548096\n",
            "recall class 1 = 0.3600917458534241\n",
            "AUC of ROC = 0.8687103604523272\n",
            "AUC of PRC = 0.5518081663478791\n",
            "min(+P, Se) = 0.536697247706422\n",
            "f1_score = 0.4686567433413129\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53 Batch 0: Train Loss = 0.2428\n",
            "Model Loss = 0.2416, Decov Loss = 0.0000\n",
            "Epoch 53 Batch 30: Train Loss = 0.2724\n",
            "Model Loss = 0.2714, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2758\n",
            "valid_model Loss = 0.2758\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2720   66]\n",
            " [ 303  133]]\n",
            "accuracy = 0.8854748606681824\n",
            "precision class 0 = 0.8997684717178345\n",
            "precision class 1 = 0.6683416962623596\n",
            "recall class 0 = 0.976310133934021\n",
            "recall class 1 = 0.30504587292671204\n",
            "AUC of ROC = 0.86732400534784\n",
            "AUC of PRC = 0.5520686068261319\n",
            "min(+P, Se) = 0.5405405405405406\n",
            "f1_score = 0.4188976238467025\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54 Batch 0: Train Loss = 0.2315\n",
            "Model Loss = 0.2307, Decov Loss = 0.0000\n",
            "Epoch 54 Batch 30: Train Loss = 0.2702\n",
            "Model Loss = 0.2692, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2719\n",
            "valid_model Loss = 0.2718\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2704   82]\n",
            " [ 272  164]]\n",
            "accuracy = 0.890130341053009\n",
            "precision class 0 = 0.9086021780967712\n",
            "precision class 1 = 0.6666666865348816\n",
            "recall class 0 = 0.9705671072006226\n",
            "recall class 1 = 0.3761467933654785\n",
            "AUC of ROC = 0.8708368184302904\n",
            "AUC of PRC = 0.5611707351645787\n",
            "min(+P, Se) = 0.536697247706422\n",
            "f1_score = 0.4809383976788706\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55 Batch 0: Train Loss = 0.2926\n",
            "Model Loss = 0.2918, Decov Loss = 0.0000\n",
            "Epoch 55 Batch 30: Train Loss = 0.2756\n",
            "Model Loss = 0.2747, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2835\n",
            "valid_model Loss = 0.2835\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2746   40]\n",
            " [ 326  110]]\n",
            "accuracy = 0.8864059448242188\n",
            "precision class 0 = 0.8938801884651184\n",
            "precision class 1 = 0.7333333492279053\n",
            "recall class 0 = 0.9856424927711487\n",
            "recall class 1 = 0.25229358673095703\n",
            "AUC of ROC = 0.8710549800114598\n",
            "AUC of PRC = 0.5532889935832376\n",
            "min(+P, Se) = 0.5344036697247706\n",
            "f1_score = 0.37542663293012074\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56 Batch 0: Train Loss = 0.2874\n",
            "Model Loss = 0.2867, Decov Loss = 0.0000\n",
            "Epoch 56 Batch 30: Train Loss = 0.2707\n",
            "Model Loss = 0.2698, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2798\n",
            "valid_model Loss = 0.2798\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2732   54]\n",
            " [ 303  133]]\n",
            "accuracy = 0.8891992568969727\n",
            "precision class 0 = 0.9001647233963013\n",
            "precision class 1 = 0.7112299203872681\n",
            "recall class 0 = 0.980617344379425\n",
            "recall class 1 = 0.30504587292671204\n",
            "AUC of ROC = 0.8674392605227975\n",
            "AUC of PRC = 0.5546663413557111\n",
            "min(+P, Se) = 0.5330296127562643\n",
            "f1_score = 0.42696630128509677\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57 Batch 0: Train Loss = 0.2525\n",
            "Model Loss = 0.2516, Decov Loss = 0.0000\n",
            "Epoch 57 Batch 30: Train Loss = 0.2804\n",
            "Model Loss = 0.2790, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2864\n",
            "valid_model Loss = 0.2864\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2741   45]\n",
            " [ 326  110]]\n",
            "accuracy = 0.8848541378974915\n",
            "precision class 0 = 0.8937072157859802\n",
            "precision class 1 = 0.7096773982048035\n",
            "recall class 0 = 0.9838477969169617\n",
            "recall class 1 = 0.25229358673095703\n",
            "AUC of ROC = 0.8683226091137207\n",
            "AUC of PRC = 0.5463420607753644\n",
            "min(+P, Se) = 0.5206422018348624\n",
            "f1_score = 0.37225042962587923\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58 Batch 0: Train Loss = 0.2328\n",
            "Model Loss = 0.2320, Decov Loss = 0.0000\n",
            "Epoch 58 Batch 30: Train Loss = 0.2755\n",
            "Model Loss = 0.2743, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2758\n",
            "valid_model Loss = 0.2758\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2696   90]\n",
            " [ 277  159]]\n",
            "accuracy = 0.8860955834388733\n",
            "precision class 0 = 0.9068281054496765\n",
            "precision class 1 = 0.6385542154312134\n",
            "recall class 0 = 0.9676955938339233\n",
            "recall class 1 = 0.36467888951301575\n",
            "AUC of ROC = 0.8655136758497599\n",
            "AUC of PRC = 0.5571922812327355\n",
            "min(+P, Se) = 0.5354691075514875\n",
            "f1_score = 0.4642335822996485\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59 Batch 0: Train Loss = 0.3068\n",
            "Model Loss = 0.3056, Decov Loss = 0.0000\n",
            "Epoch 59 Batch 30: Train Loss = 0.2700\n",
            "Model Loss = 0.2690, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2776\n",
            "valid_model Loss = 0.2776\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2722   64]\n",
            " [ 297  139]]\n",
            "accuracy = 0.8879578113555908\n",
            "precision class 0 = 0.9016230702400208\n",
            "precision class 1 = 0.6847290396690369\n",
            "recall class 0 = 0.9770280122756958\n",
            "recall class 1 = 0.31880733370780945\n",
            "AUC of ROC = 0.8674433767790458\n",
            "AUC of PRC = 0.5579512465072175\n",
            "min(+P, Se) = 0.5275229357798165\n",
            "f1_score = 0.4350547757376433\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60 Batch 0: Train Loss = 0.3069\n",
            "Model Loss = 0.3062, Decov Loss = 0.0000\n",
            "Epoch 60 Batch 30: Train Loss = 0.2718\n",
            "Model Loss = 0.2709, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2876\n",
            "valid_model Loss = 0.2876\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2734   52]\n",
            " [ 302  134]]\n",
            "accuracy = 0.890130341053009\n",
            "precision class 0 = 0.9005270004272461\n",
            "precision class 1 = 0.7204301357269287\n",
            "recall class 0 = 0.9813352227210999\n",
            "recall class 1 = 0.30733945965766907\n",
            "AUC of ROC = 0.8660471426595626\n",
            "AUC of PRC = 0.5582858106075738\n",
            "min(+P, Se) = 0.5321100917431193\n",
            "f1_score = 0.43086819468131166\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61 Batch 0: Train Loss = 0.2842\n",
            "Model Loss = 0.2833, Decov Loss = 0.0000\n",
            "Epoch 61 Batch 30: Train Loss = 0.2761\n",
            "Model Loss = 0.2754, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2885\n",
            "valid_model Loss = 0.2885\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2736   50]\n",
            " [ 307  129]]\n",
            "accuracy = 0.8891992568969727\n",
            "precision class 0 = 0.8991127014160156\n",
            "precision class 1 = 0.7206704020500183\n",
            "recall class 0 = 0.9820531010627747\n",
            "recall class 1 = 0.2958715558052063\n",
            "AUC of ROC = 0.8661006539907927\n",
            "AUC of PRC = 0.5556296837070915\n",
            "min(+P, Se) = 0.5377574370709383\n",
            "f1_score = 0.4195121931359964\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62 Batch 0: Train Loss = 0.2332\n",
            "Model Loss = 0.2324, Decov Loss = 0.0000\n",
            "Epoch 62 Batch 30: Train Loss = 0.2733\n",
            "Model Loss = 0.2723, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2741\n",
            "valid_model Loss = 0.2741\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2685  101]\n",
            " [ 268  168]]\n",
            "accuracy = 0.8854748606681824\n",
            "precision class 0 = 0.9092448353767395\n",
            "precision class 1 = 0.624535322189331\n",
            "recall class 0 = 0.9637473225593567\n",
            "recall class 1 = 0.38532111048698425\n",
            "AUC of ROC = 0.8690548911003247\n",
            "AUC of PRC = 0.5586831152577838\n",
            "min(+P, Se) = 0.5306122448979592\n",
            "f1_score = 0.47659573974242925\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63 Batch 0: Train Loss = 0.2397\n",
            "Model Loss = 0.2388, Decov Loss = 0.0000\n",
            "Epoch 63 Batch 30: Train Loss = 0.2646\n",
            "Model Loss = 0.2638, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2763\n",
            "valid_model Loss = 0.2763\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2726   60]\n",
            " [ 298  138]]\n",
            "accuracy = 0.8888888955116272\n",
            "precision class 0 = 0.9014550447463989\n",
            "precision class 1 = 0.6969696879386902\n",
            "recall class 0 = 0.9784637689590454\n",
            "recall class 1 = 0.3165137469768524\n",
            "AUC of ROC = 0.8694101240145684\n",
            "AUC of PRC = 0.5708864399313536\n",
            "min(+P, Se) = 0.5419501133786848\n",
            "f1_score = 0.43533122761712756\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64 Batch 0: Train Loss = 0.2376\n",
            "Model Loss = 0.2371, Decov Loss = 0.0000\n",
            "Epoch 64 Batch 30: Train Loss = 0.2798\n",
            "Model Loss = 0.2787, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2867\n",
            "valid_model Loss = 0.2867\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2737   49]\n",
            " [ 319  117]]\n",
            "accuracy = 0.8857852220535278\n",
            "precision class 0 = 0.8956151604652405\n",
            "precision class 1 = 0.7048192620277405\n",
            "recall class 0 = 0.9824120402336121\n",
            "recall class 1 = 0.2683486342430115\n",
            "AUC of ROC = 0.8619671094660721\n",
            "AUC of PRC = 0.5536956333760095\n",
            "min(+P, Se) = 0.5275229357798165\n",
            "f1_score = 0.38870432754327144\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65 Batch 0: Train Loss = 0.2277\n",
            "Model Loss = 0.2265, Decov Loss = 0.0000\n",
            "Epoch 65 Batch 30: Train Loss = 0.2747\n",
            "Model Loss = 0.2733, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2778\n",
            "valid_model Loss = 0.2778\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2706   80]\n",
            " [ 275  161]]\n",
            "accuracy = 0.8898199796676636\n",
            "precision class 0 = 0.9077490568161011\n",
            "precision class 1 = 0.6680498123168945\n",
            "recall class 0 = 0.9712849855422974\n",
            "recall class 1 = 0.3692660629749298\n",
            "AUC of ROC = 0.8649448092362204\n",
            "AUC of PRC = 0.5627639339150671\n",
            "min(+P, Se) = 0.5321100917431193\n",
            "f1_score = 0.4756277948284691\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66 Batch 0: Train Loss = 0.2498\n",
            "Model Loss = 0.2491, Decov Loss = 0.0000\n",
            "Epoch 66 Batch 30: Train Loss = 0.2656\n",
            "Model Loss = 0.2647, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2790\n",
            "valid_model Loss = 0.2790\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2734   52]\n",
            " [ 303  133]]\n",
            "accuracy = 0.8898199796676636\n",
            "precision class 0 = 0.9002304673194885\n",
            "precision class 1 = 0.7189189195632935\n",
            "recall class 0 = 0.9813352227210999\n",
            "recall class 1 = 0.30504587292671204\n",
            "AUC of ROC = 0.8664233684806733\n",
            "AUC of PRC = 0.5653623878589753\n",
            "min(+P, Se) = 0.5321100917431193\n",
            "f1_score = 0.428341398792065\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67 Batch 0: Train Loss = 0.3013\n",
            "Model Loss = 0.3003, Decov Loss = 0.0000\n",
            "Epoch 67 Batch 30: Train Loss = 0.2724\n",
            "Model Loss = 0.2717, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2759\n",
            "valid_model Loss = 0.2759\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2710   76]\n",
            " [ 284  152]]\n",
            "accuracy = 0.8882681727409363\n",
            "precision class 0 = 0.9051436185836792\n",
            "precision class 1 = 0.6666666865348816\n",
            "recall class 0 = 0.972720742225647\n",
            "recall class 1 = 0.3486238420009613\n",
            "AUC of ROC = 0.8654618110210293\n",
            "AUC of PRC = 0.5683370861505758\n",
            "min(+P, Se) = 0.528604118993135\n",
            "f1_score = 0.45783133375867885\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68 Batch 0: Train Loss = 0.2406\n",
            "Model Loss = 0.2400, Decov Loss = 0.0000\n",
            "Epoch 68 Batch 30: Train Loss = 0.2651\n",
            "Model Loss = 0.2645, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2887\n",
            "valid_model Loss = 0.2887\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2734   52]\n",
            " [ 313  123]]\n",
            "accuracy = 0.8867163062095642\n",
            "precision class 0 = 0.897275984287262\n",
            "precision class 1 = 0.7028571367263794\n",
            "recall class 0 = 0.9813352227210999\n",
            "recall class 1 = 0.2821100950241089\n",
            "AUC of ROC = 0.8667032739055699\n",
            "AUC of PRC = 0.5660898061613449\n",
            "min(+P, Se) = 0.5396825396825397\n",
            "f1_score = 0.4026186602733217\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69 Batch 0: Train Loss = 0.3392\n",
            "Model Loss = 0.3383, Decov Loss = 0.0000\n",
            "Epoch 69 Batch 30: Train Loss = 0.2634\n",
            "Model Loss = 0.2627, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2954\n",
            "valid_model Loss = 0.2954\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2760   26]\n",
            " [ 341   95]]\n",
            "accuracy = 0.8860955834388733\n",
            "precision class 0 = 0.8900354504585266\n",
            "precision class 1 = 0.7851239442825317\n",
            "recall class 0 = 0.9906676411628723\n",
            "recall class 1 = 0.2178899049758911\n",
            "AUC of ROC = 0.8661632210857697\n",
            "AUC of PRC = 0.5683682569002391\n",
            "min(+P, Se) = 0.5298165137614679\n",
            "f1_score = 0.34111309976526943\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70 Batch 0: Train Loss = 0.2972\n",
            "Model Loss = 0.2967, Decov Loss = 0.0000\n",
            "Epoch 70 Batch 30: Train Loss = 0.2726\n",
            "Model Loss = 0.2720, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2732\n",
            "valid_model Loss = 0.2732\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2714   72]\n",
            " [ 281  155]]\n",
            "accuracy = 0.8904407024383545\n",
            "precision class 0 = 0.9061769843101501\n",
            "precision class 1 = 0.6828193664550781\n",
            "recall class 0 = 0.9741564989089966\n",
            "recall class 1 = 0.35550457239151\n",
            "AUC of ROC = 0.8673363541165855\n",
            "AUC of PRC = 0.5692111601427386\n",
            "min(+P, Se) = 0.54337899543379\n",
            "f1_score = 0.4675716541730259\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71 Batch 0: Train Loss = 0.2206\n",
            "Model Loss = 0.2199, Decov Loss = 0.0000\n",
            "Epoch 71 Batch 30: Train Loss = 0.2667\n",
            "Model Loss = 0.2659, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2741\n",
            "valid_model Loss = 0.2741\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2722   64]\n",
            " [ 289  147]]\n",
            "accuracy = 0.8904407024383545\n",
            "precision class 0 = 0.9040185809135437\n",
            "precision class 1 = 0.6966824531555176\n",
            "recall class 0 = 0.9770280122756958\n",
            "recall class 1 = 0.3371559679508209\n",
            "AUC of ROC = 0.8665904884843616\n",
            "AUC of PRC = 0.5686665969538587\n",
            "min(+P, Se) = 0.536697247706422\n",
            "f1_score = 0.45440496082124654\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72 Batch 0: Train Loss = 0.2320\n",
            "Model Loss = 0.2313, Decov Loss = 0.0000\n",
            "Epoch 72 Batch 30: Train Loss = 0.2639\n",
            "Model Loss = 0.2631, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2938\n",
            "valid_model Loss = 0.2938\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2744   42]\n",
            " [ 330  106]]\n",
            "accuracy = 0.884543776512146\n",
            "precision class 0 = 0.8926480412483215\n",
            "precision class 1 = 0.7162162065505981\n",
            "recall class 0 = 0.9849246144294739\n",
            "recall class 1 = 0.2431192696094513\n",
            "AUC of ROC = 0.8679381507801128\n",
            "AUC of PRC = 0.5634352280321901\n",
            "min(+P, Se) = 0.536697247706422\n",
            "f1_score = 0.3630137126281132\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73 Batch 0: Train Loss = 0.2908\n",
            "Model Loss = 0.2885, Decov Loss = 0.0000\n",
            "Epoch 73 Batch 30: Train Loss = 0.2729\n",
            "Model Loss = 0.2720, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2923\n",
            "valid_model Loss = 0.2923\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2748   38]\n",
            " [ 326  110]]\n",
            "accuracy = 0.8870266675949097\n",
            "precision class 0 = 0.8939492702484131\n",
            "precision class 1 = 0.7432432174682617\n",
            "recall class 0 = 0.9863603711128235\n",
            "recall class 1 = 0.25229358673095703\n",
            "AUC of ROC = 0.8652411796861108\n",
            "AUC of PRC = 0.563948364535913\n",
            "min(+P, Se) = 0.545662100456621\n",
            "f1_score = 0.37671233520965913\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74 Batch 0: Train Loss = 0.2767\n",
            "Model Loss = 0.2758, Decov Loss = 0.0000\n",
            "Epoch 74 Batch 30: Train Loss = 0.2584\n",
            "Model Loss = 0.2576, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2758\n",
            "valid_model Loss = 0.2758\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2708   78]\n",
            " [ 279  157]]\n",
            "accuracy = 0.8891992568969727\n",
            "precision class 0 = 0.9065952301025391\n",
            "precision class 1 = 0.6680850982666016\n",
            "recall class 0 = 0.9720028638839722\n",
            "recall class 1 = 0.3600917458534241\n",
            "AUC of ROC = 0.8647381731725468\n",
            "AUC of PRC = 0.5689125492472866\n",
            "min(+P, Se) = 0.5389908256880734\n",
            "f1_score = 0.4679582986827848\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75 Batch 0: Train Loss = 0.2506\n",
            "Model Loss = 0.2498, Decov Loss = 0.0000\n",
            "Epoch 75 Batch 30: Train Loss = 0.2673\n",
            "Model Loss = 0.2666, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2946\n",
            "valid_model Loss = 0.2946\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2747   39]\n",
            " [ 324  112]]\n",
            "accuracy = 0.8873370289802551\n",
            "precision class 0 = 0.8944969177246094\n",
            "precision class 1 = 0.7417218685150146\n",
            "recall class 0 = 0.9860014319419861\n",
            "recall class 1 = 0.2568807303905487\n",
            "AUC of ROC = 0.8624692927283863\n",
            "AUC of PRC = 0.5606642524097678\n",
            "min(+P, Se) = 0.536697247706422\n",
            "f1_score = 0.38160134943228774\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76 Batch 0: Train Loss = 0.2525\n",
            "Model Loss = 0.2519, Decov Loss = 0.0000\n",
            "Epoch 76 Batch 30: Train Loss = 0.2674\n",
            "Model Loss = 0.2668, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2760\n",
            "valid_model Loss = 0.2760\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2723   63]\n",
            " [ 300  136]]\n",
            "accuracy = 0.8873370289802551\n",
            "precision class 0 = 0.9007608294487\n",
            "precision class 1 = 0.6834170818328857\n",
            "recall class 0 = 0.9773869514465332\n",
            "recall class 1 = 0.31192660331726074\n",
            "AUC of ROC = 0.8641363765090195\n",
            "AUC of PRC = 0.566746717567714\n",
            "min(+P, Se) = 0.5458715596330275\n",
            "f1_score = 0.4283464539245439\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77 Batch 0: Train Loss = 0.2244\n",
            "Model Loss = 0.2237, Decov Loss = 0.0000\n",
            "Epoch 77 Batch 30: Train Loss = 0.2650\n",
            "Model Loss = 0.2641, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2765\n",
            "valid_model Loss = 0.2765\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2716   70]\n",
            " [ 280  156]]\n",
            "accuracy = 0.8913718461990356\n",
            "precision class 0 = 0.9065420627593994\n",
            "precision class 1 = 0.6902654767036438\n",
            "recall class 0 = 0.9748743772506714\n",
            "recall class 1 = 0.35779815912246704\n",
            "AUC of ROC = 0.8629179646594702\n",
            "AUC of PRC = 0.5705189320337574\n",
            "min(+P, Se) = 0.5491990846681922\n",
            "f1_score = 0.4712990861011665\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78 Batch 0: Train Loss = 0.2240\n",
            "Model Loss = 0.2230, Decov Loss = 0.0000\n",
            "Epoch 78 Batch 30: Train Loss = 0.2643\n",
            "Model Loss = 0.2636, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2764\n",
            "valid_model Loss = 0.2764\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2742   44]\n",
            " [ 325  111]]\n",
            "accuracy = 0.8854748606681824\n",
            "precision class 0 = 0.8940332531929016\n",
            "precision class 1 = 0.7161290049552917\n",
            "recall class 0 = 0.9842067360877991\n",
            "recall class 1 = 0.2545871436595917\n",
            "AUC of ROC = 0.868670021141092\n",
            "AUC of PRC = 0.5776825182104437\n",
            "min(+P, Se) = 0.5600907029478458\n",
            "f1_score = 0.37563451215042115\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79 Batch 0: Train Loss = 0.2677\n",
            "Model Loss = 0.2670, Decov Loss = 0.0000\n",
            "Epoch 79 Batch 30: Train Loss = 0.2582\n",
            "Model Loss = 0.2574, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2728\n",
            "valid_model Loss = 0.2728\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2708   78]\n",
            " [ 277  159]]\n",
            "accuracy = 0.8898199796676636\n",
            "precision class 0 = 0.9072026610374451\n",
            "precision class 1 = 0.6708860993385315\n",
            "recall class 0 = 0.9720028638839722\n",
            "recall class 1 = 0.36467888951301575\n",
            "AUC of ROC = 0.8678813464438838\n",
            "AUC of PRC = 0.5659793158423259\n",
            "min(+P, Se) = 0.5435779816513762\n",
            "f1_score = 0.4725111283008096\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80 Batch 0: Train Loss = 0.2797\n",
            "Model Loss = 0.2792, Decov Loss = 0.0000\n",
            "Epoch 80 Batch 30: Train Loss = 0.2701\n",
            "Model Loss = 0.2694, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2732\n",
            "valid_model Loss = 0.2732\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2721   65]\n",
            " [ 299  137]]\n",
            "accuracy = 0.8870266675949097\n",
            "precision class 0 = 0.9009934067726135\n",
            "precision class 1 = 0.6782178282737732\n",
            "recall class 0 = 0.9766690731048584\n",
            "recall class 1 = 0.3142201900482178\n",
            "AUC of ROC = 0.8683687111837036\n",
            "AUC of PRC = 0.5652590524672535\n",
            "min(+P, Se) = 0.5412844036697247\n",
            "f1_score = 0.42946709207009093\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81 Batch 0: Train Loss = 0.2587\n",
            "Model Loss = 0.2581, Decov Loss = 0.0000\n",
            "Epoch 81 Batch 30: Train Loss = 0.2644\n",
            "Model Loss = 0.2638, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2767\n",
            "valid_model Loss = 0.2767\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2691   95]\n",
            " [ 266  170]]\n",
            "accuracy = 0.8879578113555908\n",
            "precision class 0 = 0.9100439548492432\n",
            "precision class 1 = 0.6415094137191772\n",
            "recall class 0 = 0.9659009575843811\n",
            "recall class 1 = 0.3899082541465759\n",
            "AUC of ROC = 0.8641981203527467\n",
            "AUC of PRC = 0.5640997106819916\n",
            "min(+P, Se) = 0.5527522935779816\n",
            "f1_score = 0.4850214181306013\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82 Batch 0: Train Loss = 0.2756\n",
            "Model Loss = 0.2752, Decov Loss = 0.0000\n",
            "Epoch 82 Batch 30: Train Loss = 0.2588\n",
            "Model Loss = 0.2583, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2790\n",
            "valid_model Loss = 0.2790\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2731   55]\n",
            " [ 314  122]]\n",
            "accuracy = 0.8854748606681824\n",
            "precision class 0 = 0.8968801498413086\n",
            "precision class 1 = 0.6892655491828918\n",
            "recall class 0 = 0.9802584648132324\n",
            "recall class 1 = 0.27981650829315186\n",
            "AUC of ROC = 0.8665172191231386\n",
            "AUC of PRC = 0.5598840524799347\n",
            "min(+P, Se) = 0.5321100917431193\n",
            "f1_score = 0.3980424109005575\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83 Batch 0: Train Loss = 0.2666\n",
            "Model Loss = 0.2659, Decov Loss = 0.0000\n",
            "Epoch 83 Batch 30: Train Loss = 0.2736\n",
            "Model Loss = 0.2729, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2760\n",
            "valid_model Loss = 0.2759\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2707   79]\n",
            " [ 279  157]]\n",
            "accuracy = 0.8888888955116272\n",
            "precision class 0 = 0.906563937664032\n",
            "precision class 1 = 0.6652542352676392\n",
            "recall class 0 = 0.9716439247131348\n",
            "recall class 1 = 0.3600917458534241\n",
            "AUC of ROC = 0.8664554752794115\n",
            "AUC of PRC = 0.5637724146890357\n",
            "min(+P, Se) = 0.5298165137614679\n",
            "f1_score = 0.46726187940290065\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84 Batch 0: Train Loss = 0.2150\n",
            "Model Loss = 0.2145, Decov Loss = 0.0000\n",
            "Epoch 84 Batch 30: Train Loss = 0.2652\n",
            "Model Loss = 0.2646, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2814\n",
            "valid_model Loss = 0.2814\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2744   42]\n",
            " [ 325  111]]\n",
            "accuracy = 0.8860955834388733\n",
            "precision class 0 = 0.8941023349761963\n",
            "precision class 1 = 0.7254902124404907\n",
            "recall class 0 = 0.9849246144294739\n",
            "recall class 1 = 0.2545871436595917\n",
            "AUC of ROC = 0.8649324604674749\n",
            "AUC of PRC = 0.5695667702473405\n",
            "min(+P, Se) = 0.5327313769751693\n",
            "f1_score = 0.37690999424122457\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85 Batch 0: Train Loss = 0.2553\n",
            "Model Loss = 0.2543, Decov Loss = 0.0000\n",
            "Epoch 85 Batch 30: Train Loss = 0.2632\n",
            "Model Loss = 0.2626, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2772\n",
            "valid_model Loss = 0.2772\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2694   92]\n",
            " [ 269  167]]\n",
            "accuracy = 0.8879578113555908\n",
            "precision class 0 = 0.909213662147522\n",
            "precision class 1 = 0.6447876691818237\n",
            "recall class 0 = 0.9669777750968933\n",
            "recall class 1 = 0.3830275237560272\n",
            "AUC of ROC = 0.8626553475108175\n",
            "AUC of PRC = 0.5637810492328929\n",
            "min(+P, Se) = 0.5504587155963303\n",
            "f1_score = 0.48057553305487005\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86 Batch 0: Train Loss = 0.2505\n",
            "Model Loss = 0.2496, Decov Loss = 0.0000\n",
            "Epoch 86 Batch 30: Train Loss = 0.2691\n",
            "Model Loss = 0.2684, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2810\n",
            "valid_model Loss = 0.2810\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2747   39]\n",
            " [ 332  104]]\n",
            "accuracy = 0.8848541378974915\n",
            "precision class 0 = 0.8921727538108826\n",
            "precision class 1 = 0.7272727489471436\n",
            "recall class 0 = 0.9860014319419861\n",
            "recall class 1 = 0.23853211104869843\n",
            "AUC of ROC = 0.8653951276698038\n",
            "AUC of PRC = 0.5678799483467133\n",
            "min(+P, Se) = 0.5458715596330275\n",
            "f1_score = 0.359240067271461\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87 Batch 0: Train Loss = 0.2596\n",
            "Model Loss = 0.2589, Decov Loss = 0.0000\n",
            "Epoch 87 Batch 30: Train Loss = 0.2604\n",
            "Model Loss = 0.2598, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2812\n",
            "valid_model Loss = 0.2812\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2746   40]\n",
            " [ 320  116]]\n",
            "accuracy = 0.8882681727409363\n",
            "precision class 0 = 0.8956294655799866\n",
            "precision class 1 = 0.7435897588729858\n",
            "recall class 0 = 0.9856424927711487\n",
            "recall class 1 = 0.26605504751205444\n",
            "AUC of ROC = 0.8626314732245766\n",
            "AUC of PRC = 0.5697404877512575\n",
            "min(+P, Se) = 0.5458715596330275\n",
            "f1_score = 0.39189191892950037\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 88 Batch 0: Train Loss = 0.2400\n",
            "Model Loss = 0.2395, Decov Loss = 0.0000\n",
            "Epoch 88 Batch 30: Train Loss = 0.2603\n",
            "Model Loss = 0.2597, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2756\n",
            "valid_model Loss = 0.2756\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2727   59]\n",
            " [ 303  133]]\n",
            "accuracy = 0.8876474499702454\n",
            "precision class 0 = 0.8999999761581421\n",
            "precision class 1 = 0.6927083134651184\n",
            "recall class 0 = 0.9788227081298828\n",
            "recall class 1 = 0.30504587292671204\n",
            "AUC of ROC = 0.8656824423559476\n",
            "AUC of PRC = 0.5581529911505811\n",
            "min(+P, Se) = 0.5298165137614679\n",
            "f1_score = 0.42356686393282883\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89 Batch 0: Train Loss = 0.2653\n",
            "Model Loss = 0.2650, Decov Loss = 0.0000\n",
            "Epoch 89 Batch 30: Train Loss = 0.2529\n",
            "Model Loss = 0.2524, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2774\n",
            "valid_model Loss = 0.2774\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2722   64]\n",
            " [ 293  143]]\n",
            "accuracy = 0.8891992568969727\n",
            "precision class 0 = 0.9028192162513733\n",
            "precision class 1 = 0.6908212304115295\n",
            "recall class 0 = 0.9770280122756958\n",
            "recall class 1 = 0.3279816508293152\n",
            "AUC of ROC = 0.8660915982270461\n",
            "AUC of PRC = 0.5684189863325853\n",
            "min(+P, Se) = 0.536697247706422\n",
            "f1_score = 0.4447900408415698\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90 Batch 0: Train Loss = 0.2555\n",
            "Model Loss = 0.2551, Decov Loss = 0.0000\n",
            "Epoch 90 Batch 30: Train Loss = 0.2664\n",
            "Model Loss = 0.2658, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2748\n",
            "valid_model Loss = 0.2748\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2713   73]\n",
            " [ 281  155]]\n",
            "accuracy = 0.890130341053009\n",
            "precision class 0 = 0.9061456322669983\n",
            "precision class 1 = 0.6798245906829834\n",
            "recall class 0 = 0.9737975597381592\n",
            "recall class 1 = 0.35550457239151\n",
            "AUC of ROC = 0.8665303911431338\n",
            "AUC of PRC = 0.5679880922618735\n",
            "min(+P, Se) = 0.55125284738041\n",
            "f1_score = 0.46686749093019325\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91 Batch 0: Train Loss = 0.2375\n",
            "Model Loss = 0.2371, Decov Loss = 0.0000\n",
            "Epoch 91 Batch 30: Train Loss = 0.2624\n",
            "Model Loss = 0.2619, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2816\n",
            "valid_model Loss = 0.2816\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2737   49]\n",
            " [ 317  119]]\n",
            "accuracy = 0.8864059448242188\n",
            "precision class 0 = 0.8962017297744751\n",
            "precision class 1 = 0.7083333134651184\n",
            "recall class 0 = 0.9824120402336121\n",
            "recall class 1 = 0.27293577790260315\n",
            "AUC of ROC = 0.8656931446221934\n",
            "AUC of PRC = 0.5716586623839491\n",
            "min(+P, Se) = 0.536697247706422\n",
            "f1_score = 0.39403971806309085\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92 Batch 0: Train Loss = 0.2637\n",
            "Model Loss = 0.2631, Decov Loss = 0.0000\n",
            "Epoch 92 Batch 30: Train Loss = 0.2659\n",
            "Model Loss = 0.2654, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2784\n",
            "valid_model Loss = 0.2784\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2680  106]\n",
            " [ 248  188]]\n",
            "accuracy = 0.890130341053009\n",
            "precision class 0 = 0.9153005480766296\n",
            "precision class 1 = 0.6394557952880859\n",
            "recall class 0 = 0.9619526267051697\n",
            "recall class 1 = 0.43119266629219055\n",
            "AUC of ROC = 0.8638778756166152\n",
            "AUC of PRC = 0.5650447487559352\n",
            "min(+P, Se) = 0.5491990846681922\n",
            "f1_score = 0.5150685157935156\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93 Batch 0: Train Loss = 0.2899\n",
            "Model Loss = 0.2885, Decov Loss = 0.0000\n",
            "Epoch 93 Batch 30: Train Loss = 0.2660\n",
            "Model Loss = 0.2654, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2755\n",
            "valid_model Loss = 0.2755\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2721   65]\n",
            " [ 293  143]]\n",
            "accuracy = 0.8888888955116272\n",
            "precision class 0 = 0.9027869701385498\n",
            "precision class 1 = 0.6875\n",
            "recall class 0 = 0.9766690731048584\n",
            "recall class 1 = 0.3279816508293152\n",
            "AUC of ROC = 0.8673396471215842\n",
            "AUC of PRC = 0.5745192429477964\n",
            "min(+P, Se) = 0.5389908256880734\n",
            "f1_score = 0.44409935231387576\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94 Batch 0: Train Loss = 0.2577\n",
            "Model Loss = 0.2573, Decov Loss = 0.0000\n",
            "Epoch 94 Batch 30: Train Loss = 0.2521\n",
            "Model Loss = 0.2515, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2738\n",
            "valid_model Loss = 0.2738\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2698   88]\n",
            " [ 255  181]]\n",
            "accuracy = 0.8935443758964539\n",
            "precision class 0 = 0.9136471152305603\n",
            "precision class 1 = 0.6728624701499939\n",
            "recall class 0 = 0.9684134721755981\n",
            "recall class 1 = 0.4151376187801361\n",
            "AUC of ROC = 0.8665180423743883\n",
            "AUC of PRC = 0.5759911839182275\n",
            "min(+P, Se) = 0.5446224256292906\n",
            "f1_score = 0.5134751993460616\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95 Batch 0: Train Loss = 0.3024\n",
            "Model Loss = 0.3017, Decov Loss = 0.0000\n",
            "Epoch 95 Batch 30: Train Loss = 0.2551\n",
            "Model Loss = 0.2546, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2753\n",
            "valid_model Loss = 0.2753\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2740   46]\n",
            " [ 311  125]]\n",
            "accuracy = 0.8891992568969727\n",
            "precision class 0 = 0.8980662226676941\n",
            "precision class 1 = 0.7309941649436951\n",
            "recall class 0 = 0.9834888577461243\n",
            "recall class 1 = 0.28669723868370056\n",
            "AUC of ROC = 0.8683641833018303\n",
            "AUC of PRC = 0.5740027637628194\n",
            "min(+P, Se) = 0.5435779816513762\n",
            "f1_score = 0.4118616192953557\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96 Batch 0: Train Loss = 0.2598\n",
            "Model Loss = 0.2594, Decov Loss = 0.0000\n",
            "Epoch 96 Batch 30: Train Loss = 0.2510\n",
            "Model Loss = 0.2505, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2757\n",
            "valid_model Loss = 0.2757\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2718   68]\n",
            " [ 291  145]]\n",
            "accuracy = 0.8885785341262817\n",
            "precision class 0 = 0.9032901525497437\n",
            "precision class 1 = 0.6807511448860168\n",
            "recall class 0 = 0.9755922555923462\n",
            "recall class 1 = 0.33256879448890686\n",
            "AUC of ROC = 0.8668514591305149\n",
            "AUC of PRC = 0.5712279324507019\n",
            "min(+P, Se) = 0.5452488687782805\n",
            "f1_score = 0.44684126334844854\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97 Batch 0: Train Loss = 0.2809\n",
            "Model Loss = 0.2803, Decov Loss = 0.0000\n",
            "Epoch 97 Batch 30: Train Loss = 0.2626\n",
            "Model Loss = 0.2622, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2713\n",
            "valid_model Loss = 0.2713\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2693   93]\n",
            " [ 257  179]]\n",
            "accuracy = 0.8913718461990356\n",
            "precision class 0 = 0.9128813743591309\n",
            "precision class 1 = 0.658088207244873\n",
            "recall class 0 = 0.9666188359260559\n",
            "recall class 1 = 0.41055044531822205\n",
            "AUC of ROC = 0.8708837437515231\n",
            "AUC of PRC = 0.5831096228445573\n",
            "min(+P, Se) = 0.5446224256292906\n",
            "f1_score = 0.5056496849711948\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98 Batch 0: Train Loss = 0.3216\n",
            "Model Loss = 0.3211, Decov Loss = 0.0000\n",
            "Epoch 98 Batch 30: Train Loss = 0.2577\n",
            "Model Loss = 0.2566, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2735\n",
            "valid_model Loss = 0.2735\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2710   76]\n",
            " [ 281  155]]\n",
            "accuracy = 0.8891992568969727\n",
            "precision class 0 = 0.906051516532898\n",
            "precision class 1 = 0.6709956526756287\n",
            "recall class 0 = 0.972720742225647\n",
            "recall class 1 = 0.35550457239151\n",
            "AUC of ROC = 0.8703469839367216\n",
            "AUC of PRC = 0.5714402027473506\n",
            "min(+P, Se) = 0.5583524027459954\n",
            "f1_score = 0.4647675991798435\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99 Batch 0: Train Loss = 0.2081\n",
            "Model Loss = 0.2064, Decov Loss = 0.0000\n",
            "Epoch 99 Batch 30: Train Loss = 0.2488\n",
            "Model Loss = 0.2475, Decov Loss = 0.0000\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2894\n",
            "valid_model Loss = 0.2894\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2746   40]\n",
            " [ 334  102]]\n",
            "accuracy = 0.8839230537414551\n",
            "precision class 0 = 0.8915584683418274\n",
            "precision class 1 = 0.7183098793029785\n",
            "recall class 0 = 0.9856424927711487\n",
            "recall class 1 = 0.23394495248794556\n",
            "AUC of ROC = 0.8651094594861596\n",
            "AUC of PRC = 0.5569158232865234\n",
            "min(+P, Se) = 0.5481651376146789\n",
            "f1_score = 0.35294117703579786\n",
            "\n"
          ]
        }
      ],
      "source": [
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED) #numpy\n",
        "random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED) # cpu\n",
        "torch.cuda.manual_seed(RANDOM_SEED) #gpu\n",
        "torch.backends.cudnn.deterministic=True # cudnn\n",
        "\n",
        "model = ConCare(input_dim = 76, hidden_dim = 64, d_model = 64,  MHD_num_head = 4 , d_ff = 256, output_dim = 1).to(device)\n",
        "# input_dim, d_model, d_k, d_v, MHD_num_head, d_ff, output_dim\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "max_roc = 0\n",
        "max_prc = 0\n",
        "train_loss = []\n",
        "train_model_loss = []\n",
        "train_decov_loss = []\n",
        "valid_loss = []\n",
        "valid_model_loss = []\n",
        "valid_decov_loss = []\n",
        "history = []\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "np.set_printoptions(precision=2)\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "for each_epoch in range(100):\n",
        "    batch_loss = []\n",
        "    model_batch_loss = []\n",
        "    decov_batch_loss = []\n",
        "\n",
        "    model.train()\n",
        " \n",
        "    for step, (batch_x, batch_y, batch_name) in enumerate(train_loader):   \n",
        "        optimizer.zero_grad()\n",
        "        batch_x = batch_x.float().to(device)\n",
        "        batch_y = batch_y.float().to(device)\n",
        "\n",
        "        batch_demo = []\n",
        "        for i in range(len(batch_name)):\n",
        "            cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n",
        "            cur_idx = cur_id + '_' + cur_ep\n",
        "            cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n",
        "            batch_demo.append(cur_demo)\n",
        "        \n",
        "        batch_demo = torch.stack(batch_demo).to(device)\n",
        "        output, decov_loss = model(batch_x, batch_demo)\n",
        "        \n",
        "        \n",
        "        model_loss = get_loss(output, batch_y.unsqueeze(-1))\n",
        "        loss = model_loss + 800* decov_loss\n",
        "        \n",
        "        batch_loss.append(loss.cpu().detach().numpy())\n",
        "        model_batch_loss.append(model_loss.cpu().detach().numpy())\n",
        "        decov_batch_loss.append(decov_loss.cpu().detach().numpy())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if step % 30 == 0:\n",
        "            print('Epoch %d Batch %d: Train Loss = %.4f'%(each_epoch, step, np.mean(np.array(batch_loss))))\n",
        "            print('Model Loss = %.4f, Decov Loss = %.4f'%(np.mean(np.array(model_batch_loss)), np.mean(np.array(decov_batch_loss))))\n",
        "    train_loss.append(np.mean(np.array(batch_loss)))\n",
        "    train_model_loss.append(np.mean(np.array(model_batch_loss)))\n",
        "    train_decov_loss.append(np.mean(np.array(decov_batch_loss)))\n",
        "    \n",
        "    batch_loss = []\n",
        "    model_batch_loss = []\n",
        "    decov_batch_loss = []\n",
        "    \n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for step, (batch_x, batch_y, batch_name) in enumerate(valid_loader):\n",
        "            batch_x = batch_x.float().to(device)\n",
        "            batch_y = batch_y.float().to(device)\n",
        "            batch_demo = []\n",
        "            for i in range(len(batch_name)):\n",
        "                cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n",
        "                cur_idx = cur_id + '_' + cur_ep\n",
        "                cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n",
        "                batch_demo.append(cur_demo)\n",
        "\n",
        "            batch_demo = torch.stack(batch_demo).to(device)\n",
        "            output,decov_loss = model(batch_x, batch_demo)\n",
        "            \n",
        "            model_loss = get_loss(output, batch_y.unsqueeze(-1))\n",
        "\n",
        "            loss = model_loss + 10* decov_loss\n",
        "            batch_loss.append(loss.cpu().detach().numpy())\n",
        "            model_batch_loss.append(model_loss.cpu().detach().numpy())\n",
        "            decov_batch_loss.append(decov_loss.cpu().detach().numpy())\n",
        "            y_pred += list(output.cpu().detach().numpy().flatten())\n",
        "            y_true += list(batch_y.cpu().numpy().flatten())\n",
        "            \n",
        "    valid_loss.append(np.mean(np.array(batch_loss)))\n",
        "    valid_model_loss.append(np.mean(np.array(model_batch_loss)))\n",
        "    valid_decov_loss.append(np.mean(np.array(decov_batch_loss)))\n",
        "    \n",
        "    print(\"\\n==>Predicting on validation\")\n",
        "    print('Valid Loss = %.4f'%(valid_loss[-1]))\n",
        "    print('valid_model Loss = %.4f'%(valid_model_loss[-1]))\n",
        "    print('valid_decov Loss = %.4f'%(valid_decov_loss[-1]))\n",
        "    y_pred = np.array(y_pred)\n",
        "    y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n",
        "    ret = metrics.print_metrics_binary(y_true, y_pred)\n",
        "    history.append(ret)\n",
        "    print()\n",
        "\n",
        "    cur_auroc = ret['auroc']\n",
        "    \n",
        "    if cur_auroc > max_roc:\n",
        "        max_roc = cur_auroc\n",
        "        state = {\n",
        "            'net': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'epoch': each_epoch\n",
        "        }\n",
        "        torch.save(state, file_name)\n",
        "        print('\\n------------ Save best model ------------\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZQbDZOdkmci"
      },
      "source": [
        "### Run for test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T03:27:16.741911Z",
          "start_time": "2021-11-02T03:27:01.578022Z"
        },
        "id": "VBdjo2Hhkmci"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load(file_name)\n",
        "save_epoch = checkpoint['epoch']\n",
        "model.load_state_dict(checkpoint['net'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "model.eval()\n",
        "\n",
        "test_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data_path, 'test'),\n",
        "                                            listfile=os.path.join(data_path, 'test_listfile.csv'),\n",
        "                                            period_length=48.0)\n",
        "test_raw = utils.load_data(test_reader, discretizer, normalizer, small_part, return_names=True)\n",
        "test_dataset = Dataset(test_raw['data'][0], test_raw['data'][1], test_raw['names'])\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T03:27:20.964397Z",
          "start_time": "2021-11-02T03:27:16.745558Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKzF0xjMkmci",
        "outputId": "2489b426-2aee-4d77-e061-2404b757491a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==>Predicting on test\n",
            "Test Loss = 0.2578\n",
            "confusion matrix:\n",
            "[[2821   41]\n",
            " [ 279   95]]\n",
            "accuracy = 0.9011124968528748\n",
            "precision class 0 = 0.9100000262260437\n",
            "precision class 1 = 0.6985294222831726\n",
            "recall class 0 = 0.9856743812561035\n",
            "recall class 1 = 0.25401070713996887\n",
            "AUC of ROC = 0.8667473850603706\n",
            "AUC of PRC = 0.5146237594452785\n",
            "min(+P, Se) = 0.49736842105263157\n",
            "f1_score = 0.3725490223036873\n"
          ]
        }
      ],
      "source": [
        "batch_loss = []\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for step, (batch_x, batch_y, batch_name) in enumerate(test_loader):\n",
        "        batch_x = batch_x.float().to(device)\n",
        "        batch_y = batch_y.float().to(device)\n",
        "        batch_demo = []\n",
        "        for i in range(len(batch_name)):\n",
        "            cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n",
        "            cur_idx = cur_id + '_' + cur_ep\n",
        "            cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n",
        "            batch_demo.append(cur_demo)\n",
        "\n",
        "        batch_demo = torch.stack(batch_demo).to(device)\n",
        "        output = model(batch_x, batch_demo)[0]\n",
        "\n",
        "        loss = get_loss(output, batch_y.unsqueeze(-1))\n",
        "        batch_loss.append(loss.cpu().detach().numpy())\n",
        "        y_pred += list(output.cpu().detach().numpy().flatten())\n",
        "        y_true += list(batch_y.cpu().numpy().flatten())\n",
        "\n",
        "print(\"\\n==>Predicting on test\")\n",
        "print('Test Loss = %.4f'%(np.mean(np.array(batch_loss))))\n",
        "y_pred = np.array(y_pred)\n",
        "y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n",
        "test_res = metrics.print_metrics_binary(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T03:27:35.542743Z",
          "start_time": "2021-11-02T03:27:20.967136Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clDjYlGekmcj",
        "outputId": "a05c634d-30e6-4dad-9187-f57c72cb4441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1000\n",
            "2/1000\n",
            "3/1000\n",
            "4/1000\n",
            "5/1000\n",
            "6/1000\n",
            "7/1000\n",
            "8/1000\n",
            "9/1000\n",
            "10/1000\n",
            "11/1000\n",
            "12/1000\n",
            "13/1000\n",
            "14/1000\n",
            "15/1000\n",
            "16/1000\n",
            "17/1000\n",
            "18/1000\n",
            "19/1000\n",
            "20/1000\n",
            "21/1000\n",
            "22/1000\n",
            "23/1000\n",
            "24/1000\n",
            "25/1000\n",
            "26/1000\n",
            "27/1000\n",
            "28/1000\n",
            "29/1000\n",
            "30/1000\n",
            "31/1000\n",
            "32/1000\n",
            "33/1000\n",
            "34/1000\n",
            "35/1000\n",
            "36/1000\n",
            "37/1000\n",
            "38/1000\n",
            "39/1000\n",
            "40/1000\n",
            "41/1000\n",
            "42/1000\n",
            "43/1000\n",
            "44/1000\n",
            "45/1000\n",
            "46/1000\n",
            "47/1000\n",
            "48/1000\n",
            "49/1000\n",
            "50/1000\n",
            "51/1000\n",
            "52/1000\n",
            "53/1000\n",
            "54/1000\n",
            "55/1000\n",
            "56/1000\n",
            "57/1000\n",
            "58/1000\n",
            "59/1000\n",
            "60/1000\n",
            "61/1000\n",
            "62/1000\n",
            "63/1000\n",
            "64/1000\n",
            "65/1000\n",
            "66/1000\n",
            "67/1000\n",
            "68/1000\n",
            "69/1000\n",
            "70/1000\n",
            "71/1000\n",
            "72/1000\n",
            "73/1000\n",
            "74/1000\n",
            "75/1000\n",
            "76/1000\n",
            "77/1000\n",
            "78/1000\n",
            "79/1000\n",
            "80/1000\n",
            "81/1000\n",
            "82/1000\n",
            "83/1000\n",
            "84/1000\n",
            "85/1000\n",
            "86/1000\n",
            "87/1000\n",
            "88/1000\n",
            "89/1000\n",
            "90/1000\n",
            "91/1000\n",
            "92/1000\n",
            "93/1000\n",
            "94/1000\n",
            "95/1000\n",
            "96/1000\n",
            "97/1000\n",
            "98/1000\n",
            "99/1000\n",
            "100/1000\n",
            "101/1000\n",
            "102/1000\n",
            "103/1000\n",
            "104/1000\n",
            "105/1000\n",
            "106/1000\n",
            "107/1000\n",
            "108/1000\n",
            "109/1000\n",
            "110/1000\n",
            "111/1000\n",
            "112/1000\n",
            "113/1000\n",
            "114/1000\n",
            "115/1000\n",
            "116/1000\n",
            "117/1000\n",
            "118/1000\n",
            "119/1000\n",
            "120/1000\n",
            "121/1000\n",
            "122/1000\n",
            "123/1000\n",
            "124/1000\n",
            "125/1000\n",
            "126/1000\n",
            "127/1000\n",
            "128/1000\n",
            "129/1000\n",
            "130/1000\n",
            "131/1000\n",
            "132/1000\n",
            "133/1000\n",
            "134/1000\n",
            "135/1000\n",
            "136/1000\n",
            "137/1000\n",
            "138/1000\n",
            "139/1000\n",
            "140/1000\n",
            "141/1000\n",
            "142/1000\n",
            "143/1000\n",
            "144/1000\n",
            "145/1000\n",
            "146/1000\n",
            "147/1000\n",
            "148/1000\n",
            "149/1000\n",
            "150/1000\n",
            "151/1000\n",
            "152/1000\n",
            "153/1000\n",
            "154/1000\n",
            "155/1000\n",
            "156/1000\n",
            "157/1000\n",
            "158/1000\n",
            "159/1000\n",
            "160/1000\n",
            "161/1000\n",
            "162/1000\n",
            "163/1000\n",
            "164/1000\n",
            "165/1000\n",
            "166/1000\n",
            "167/1000\n",
            "168/1000\n",
            "169/1000\n",
            "170/1000\n",
            "171/1000\n",
            "172/1000\n",
            "173/1000\n",
            "174/1000\n",
            "175/1000\n",
            "176/1000\n",
            "177/1000\n",
            "178/1000\n",
            "179/1000\n",
            "180/1000\n",
            "181/1000\n",
            "182/1000\n",
            "183/1000\n",
            "184/1000\n",
            "185/1000\n",
            "186/1000\n",
            "187/1000\n",
            "188/1000\n",
            "189/1000\n",
            "190/1000\n",
            "191/1000\n",
            "192/1000\n",
            "193/1000\n",
            "194/1000\n",
            "195/1000\n",
            "196/1000\n",
            "197/1000\n",
            "198/1000\n",
            "199/1000\n",
            "200/1000\n",
            "201/1000\n",
            "202/1000\n",
            "203/1000\n",
            "204/1000\n",
            "205/1000\n",
            "206/1000\n",
            "207/1000\n",
            "208/1000\n",
            "209/1000\n",
            "210/1000\n",
            "211/1000\n",
            "212/1000\n",
            "213/1000\n",
            "214/1000\n",
            "215/1000\n",
            "216/1000\n",
            "217/1000\n",
            "218/1000\n",
            "219/1000\n",
            "220/1000\n",
            "221/1000\n",
            "222/1000\n",
            "223/1000\n",
            "224/1000\n",
            "225/1000\n",
            "226/1000\n",
            "227/1000\n",
            "228/1000\n",
            "229/1000\n",
            "230/1000\n",
            "231/1000\n",
            "232/1000\n",
            "233/1000\n",
            "234/1000\n",
            "235/1000\n",
            "236/1000\n",
            "237/1000\n",
            "238/1000\n",
            "239/1000\n",
            "240/1000\n",
            "241/1000\n",
            "242/1000\n",
            "243/1000\n",
            "244/1000\n",
            "245/1000\n",
            "246/1000\n",
            "247/1000\n",
            "248/1000\n",
            "249/1000\n",
            "250/1000\n",
            "251/1000\n",
            "252/1000\n",
            "253/1000\n",
            "254/1000\n",
            "255/1000\n",
            "256/1000\n",
            "257/1000\n",
            "258/1000\n",
            "259/1000\n",
            "260/1000\n",
            "261/1000\n",
            "262/1000\n",
            "263/1000\n",
            "264/1000\n",
            "265/1000\n",
            "266/1000\n",
            "267/1000\n",
            "268/1000\n",
            "269/1000\n",
            "270/1000\n",
            "271/1000\n",
            "272/1000\n",
            "273/1000\n",
            "274/1000\n",
            "275/1000\n",
            "276/1000\n",
            "277/1000\n",
            "278/1000\n",
            "279/1000\n",
            "280/1000\n",
            "281/1000\n",
            "282/1000\n",
            "283/1000\n",
            "284/1000\n",
            "285/1000\n",
            "286/1000\n",
            "287/1000\n",
            "288/1000\n",
            "289/1000\n",
            "290/1000\n",
            "291/1000\n",
            "292/1000\n",
            "293/1000\n",
            "294/1000\n",
            "295/1000\n",
            "296/1000\n",
            "297/1000\n",
            "298/1000\n",
            "299/1000\n",
            "300/1000\n",
            "301/1000\n",
            "302/1000\n",
            "303/1000\n",
            "304/1000\n",
            "305/1000\n",
            "306/1000\n",
            "307/1000\n",
            "308/1000\n",
            "309/1000\n",
            "310/1000\n",
            "311/1000\n",
            "312/1000\n",
            "313/1000\n",
            "314/1000\n",
            "315/1000\n",
            "316/1000\n",
            "317/1000\n",
            "318/1000\n",
            "319/1000\n",
            "320/1000\n",
            "321/1000\n",
            "322/1000\n",
            "323/1000\n",
            "324/1000\n",
            "325/1000\n",
            "326/1000\n",
            "327/1000\n",
            "328/1000\n",
            "329/1000\n",
            "330/1000\n",
            "331/1000\n",
            "332/1000\n",
            "333/1000\n",
            "334/1000\n",
            "335/1000\n",
            "336/1000\n",
            "337/1000\n",
            "338/1000\n",
            "339/1000\n",
            "340/1000\n",
            "341/1000\n",
            "342/1000\n",
            "343/1000\n",
            "344/1000\n",
            "345/1000\n",
            "346/1000\n",
            "347/1000\n",
            "348/1000\n",
            "349/1000\n",
            "350/1000\n",
            "351/1000\n",
            "352/1000\n",
            "353/1000\n",
            "354/1000\n",
            "355/1000\n",
            "356/1000\n",
            "357/1000\n",
            "358/1000\n",
            "359/1000\n",
            "360/1000\n",
            "361/1000\n",
            "362/1000\n",
            "363/1000\n",
            "364/1000\n",
            "365/1000\n",
            "366/1000\n",
            "367/1000\n",
            "368/1000\n",
            "369/1000\n",
            "370/1000\n",
            "371/1000\n",
            "372/1000\n",
            "373/1000\n",
            "374/1000\n",
            "375/1000\n",
            "376/1000\n",
            "377/1000\n",
            "378/1000\n",
            "379/1000\n",
            "380/1000\n",
            "381/1000\n",
            "382/1000\n",
            "383/1000\n",
            "384/1000\n",
            "385/1000\n",
            "386/1000\n",
            "387/1000\n",
            "388/1000\n",
            "389/1000\n",
            "390/1000\n",
            "391/1000\n",
            "392/1000\n",
            "393/1000\n",
            "394/1000\n",
            "395/1000\n",
            "396/1000\n",
            "397/1000\n",
            "398/1000\n",
            "399/1000\n",
            "400/1000\n",
            "401/1000\n",
            "402/1000\n",
            "403/1000\n",
            "404/1000\n",
            "405/1000\n",
            "406/1000\n",
            "407/1000\n",
            "408/1000\n",
            "409/1000\n",
            "410/1000\n",
            "411/1000\n",
            "412/1000\n",
            "413/1000\n",
            "414/1000\n",
            "415/1000\n",
            "416/1000\n",
            "417/1000\n",
            "418/1000\n",
            "419/1000\n",
            "420/1000\n",
            "421/1000\n",
            "422/1000\n",
            "423/1000\n",
            "424/1000\n",
            "425/1000\n",
            "426/1000\n",
            "427/1000\n",
            "428/1000\n",
            "429/1000\n",
            "430/1000\n",
            "431/1000\n",
            "432/1000\n",
            "433/1000\n",
            "434/1000\n",
            "435/1000\n",
            "436/1000\n",
            "437/1000\n",
            "438/1000\n",
            "439/1000\n",
            "440/1000\n",
            "441/1000\n",
            "442/1000\n",
            "443/1000\n",
            "444/1000\n",
            "445/1000\n",
            "446/1000\n",
            "447/1000\n",
            "448/1000\n",
            "449/1000\n",
            "450/1000\n",
            "451/1000\n",
            "452/1000\n",
            "453/1000\n",
            "454/1000\n",
            "455/1000\n",
            "456/1000\n",
            "457/1000\n",
            "458/1000\n",
            "459/1000\n",
            "460/1000\n",
            "461/1000\n",
            "462/1000\n",
            "463/1000\n",
            "464/1000\n",
            "465/1000\n",
            "466/1000\n",
            "467/1000\n",
            "468/1000\n",
            "469/1000\n",
            "470/1000\n",
            "471/1000\n",
            "472/1000\n",
            "473/1000\n",
            "474/1000\n",
            "475/1000\n",
            "476/1000\n",
            "477/1000\n",
            "478/1000\n",
            "479/1000\n",
            "480/1000\n",
            "481/1000\n",
            "482/1000\n",
            "483/1000\n",
            "484/1000\n",
            "485/1000\n",
            "486/1000\n",
            "487/1000\n",
            "488/1000\n",
            "489/1000\n",
            "490/1000\n",
            "491/1000\n",
            "492/1000\n",
            "493/1000\n",
            "494/1000\n",
            "495/1000\n",
            "496/1000\n",
            "497/1000\n",
            "498/1000\n",
            "499/1000\n",
            "500/1000\n",
            "501/1000\n",
            "502/1000\n",
            "503/1000\n",
            "504/1000\n",
            "505/1000\n",
            "506/1000\n",
            "507/1000\n",
            "508/1000\n",
            "509/1000\n",
            "510/1000\n",
            "511/1000\n",
            "512/1000\n",
            "513/1000\n",
            "514/1000\n",
            "515/1000\n",
            "516/1000\n",
            "517/1000\n",
            "518/1000\n",
            "519/1000\n",
            "520/1000\n",
            "521/1000\n",
            "522/1000\n",
            "523/1000\n",
            "524/1000\n",
            "525/1000\n",
            "526/1000\n",
            "527/1000\n",
            "528/1000\n",
            "529/1000\n",
            "530/1000\n",
            "531/1000\n",
            "532/1000\n",
            "533/1000\n",
            "534/1000\n",
            "535/1000\n",
            "536/1000\n",
            "537/1000\n",
            "538/1000\n",
            "539/1000\n",
            "540/1000\n",
            "541/1000\n",
            "542/1000\n",
            "543/1000\n",
            "544/1000\n",
            "545/1000\n",
            "546/1000\n",
            "547/1000\n",
            "548/1000\n",
            "549/1000\n",
            "550/1000\n",
            "551/1000\n",
            "552/1000\n",
            "553/1000\n",
            "554/1000\n",
            "555/1000\n",
            "556/1000\n",
            "557/1000\n",
            "558/1000\n",
            "559/1000\n",
            "560/1000\n",
            "561/1000\n",
            "562/1000\n",
            "563/1000\n",
            "564/1000\n",
            "565/1000\n",
            "566/1000\n",
            "567/1000\n",
            "568/1000\n",
            "569/1000\n",
            "570/1000\n",
            "571/1000\n",
            "572/1000\n",
            "573/1000\n",
            "574/1000\n",
            "575/1000\n",
            "576/1000\n",
            "577/1000\n",
            "578/1000\n",
            "579/1000\n",
            "580/1000\n",
            "581/1000\n",
            "582/1000\n",
            "583/1000\n",
            "584/1000\n",
            "585/1000\n",
            "586/1000\n",
            "587/1000\n",
            "588/1000\n",
            "589/1000\n",
            "590/1000\n",
            "591/1000\n",
            "592/1000\n",
            "593/1000\n",
            "594/1000\n",
            "595/1000\n",
            "596/1000\n",
            "597/1000\n",
            "598/1000\n",
            "599/1000\n",
            "600/1000\n",
            "601/1000\n",
            "602/1000\n",
            "603/1000\n",
            "604/1000\n",
            "605/1000\n",
            "606/1000\n",
            "607/1000\n",
            "608/1000\n",
            "609/1000\n",
            "610/1000\n",
            "611/1000\n",
            "612/1000\n",
            "613/1000\n",
            "614/1000\n",
            "615/1000\n",
            "616/1000\n",
            "617/1000\n",
            "618/1000\n",
            "619/1000\n",
            "620/1000\n",
            "621/1000\n",
            "622/1000\n",
            "623/1000\n",
            "624/1000\n",
            "625/1000\n",
            "626/1000\n",
            "627/1000\n",
            "628/1000\n",
            "629/1000\n",
            "630/1000\n",
            "631/1000\n",
            "632/1000\n",
            "633/1000\n",
            "634/1000\n",
            "635/1000\n",
            "636/1000\n",
            "637/1000\n",
            "638/1000\n",
            "639/1000\n",
            "640/1000\n",
            "641/1000\n",
            "642/1000\n",
            "643/1000\n",
            "644/1000\n",
            "645/1000\n",
            "646/1000\n",
            "647/1000\n",
            "648/1000\n",
            "649/1000\n",
            "650/1000\n",
            "651/1000\n",
            "652/1000\n",
            "653/1000\n",
            "654/1000\n",
            "655/1000\n",
            "656/1000\n",
            "657/1000\n",
            "658/1000\n",
            "659/1000\n",
            "660/1000\n",
            "661/1000\n",
            "662/1000\n",
            "663/1000\n",
            "664/1000\n",
            "665/1000\n",
            "666/1000\n",
            "667/1000\n",
            "668/1000\n",
            "669/1000\n",
            "670/1000\n",
            "671/1000\n",
            "672/1000\n",
            "673/1000\n",
            "674/1000\n",
            "675/1000\n",
            "676/1000\n",
            "677/1000\n",
            "678/1000\n",
            "679/1000\n",
            "680/1000\n",
            "681/1000\n",
            "682/1000\n",
            "683/1000\n",
            "684/1000\n",
            "685/1000\n",
            "686/1000\n",
            "687/1000\n",
            "688/1000\n",
            "689/1000\n",
            "690/1000\n",
            "691/1000\n",
            "692/1000\n",
            "693/1000\n",
            "694/1000\n",
            "695/1000\n",
            "696/1000\n",
            "697/1000\n",
            "698/1000\n",
            "699/1000\n",
            "700/1000\n",
            "701/1000\n",
            "702/1000\n",
            "703/1000\n",
            "704/1000\n",
            "705/1000\n",
            "706/1000\n",
            "707/1000\n",
            "708/1000\n",
            "709/1000\n",
            "710/1000\n",
            "711/1000\n",
            "712/1000\n",
            "713/1000\n",
            "714/1000\n",
            "715/1000\n",
            "716/1000\n",
            "717/1000\n",
            "718/1000\n",
            "719/1000\n",
            "720/1000\n",
            "721/1000\n",
            "722/1000\n",
            "723/1000\n",
            "724/1000\n",
            "725/1000\n",
            "726/1000\n",
            "727/1000\n",
            "728/1000\n",
            "729/1000\n",
            "730/1000\n",
            "731/1000\n",
            "732/1000\n",
            "733/1000\n",
            "734/1000\n",
            "735/1000\n",
            "736/1000\n",
            "737/1000\n",
            "738/1000\n",
            "739/1000\n",
            "740/1000\n",
            "741/1000\n",
            "742/1000\n",
            "743/1000\n",
            "744/1000\n",
            "745/1000\n",
            "746/1000\n",
            "747/1000\n",
            "748/1000\n",
            "749/1000\n",
            "750/1000\n",
            "751/1000\n",
            "752/1000\n",
            "753/1000\n",
            "754/1000\n",
            "755/1000\n",
            "756/1000\n",
            "757/1000\n",
            "758/1000\n",
            "759/1000\n",
            "760/1000\n",
            "761/1000\n",
            "762/1000\n",
            "763/1000\n",
            "764/1000\n",
            "765/1000\n",
            "766/1000\n",
            "767/1000\n",
            "768/1000\n",
            "769/1000\n",
            "770/1000\n",
            "771/1000\n",
            "772/1000\n",
            "773/1000\n",
            "774/1000\n",
            "775/1000\n",
            "776/1000\n",
            "777/1000\n",
            "778/1000\n",
            "779/1000\n",
            "780/1000\n",
            "781/1000\n",
            "782/1000\n",
            "783/1000\n",
            "784/1000\n",
            "785/1000\n",
            "786/1000\n",
            "787/1000\n",
            "788/1000\n",
            "789/1000\n",
            "790/1000\n",
            "791/1000\n",
            "792/1000\n",
            "793/1000\n",
            "794/1000\n",
            "795/1000\n",
            "796/1000\n",
            "797/1000\n",
            "798/1000\n",
            "799/1000\n",
            "800/1000\n",
            "801/1000\n",
            "802/1000\n",
            "803/1000\n",
            "804/1000\n",
            "805/1000\n",
            "806/1000\n",
            "807/1000\n",
            "808/1000\n",
            "809/1000\n",
            "810/1000\n",
            "811/1000\n",
            "812/1000\n",
            "813/1000\n",
            "814/1000\n",
            "815/1000\n",
            "816/1000\n",
            "817/1000\n",
            "818/1000\n",
            "819/1000\n",
            "820/1000\n",
            "821/1000\n",
            "822/1000\n",
            "823/1000\n",
            "824/1000\n",
            "825/1000\n",
            "826/1000\n",
            "827/1000\n",
            "828/1000\n",
            "829/1000\n",
            "830/1000\n",
            "831/1000\n",
            "832/1000\n",
            "833/1000\n",
            "834/1000\n",
            "835/1000\n",
            "836/1000\n",
            "837/1000\n",
            "838/1000\n",
            "839/1000\n",
            "840/1000\n",
            "841/1000\n",
            "842/1000\n",
            "843/1000\n",
            "844/1000\n",
            "845/1000\n",
            "846/1000\n",
            "847/1000\n",
            "848/1000\n",
            "849/1000\n",
            "850/1000\n",
            "851/1000\n",
            "852/1000\n",
            "853/1000\n",
            "854/1000\n",
            "855/1000\n",
            "856/1000\n",
            "857/1000\n",
            "858/1000\n",
            "859/1000\n",
            "860/1000\n",
            "861/1000\n",
            "862/1000\n",
            "863/1000\n",
            "864/1000\n",
            "865/1000\n",
            "866/1000\n",
            "867/1000\n",
            "868/1000\n",
            "869/1000\n",
            "870/1000\n",
            "871/1000\n",
            "872/1000\n",
            "873/1000\n",
            "874/1000\n",
            "875/1000\n",
            "876/1000\n",
            "877/1000\n",
            "878/1000\n",
            "879/1000\n",
            "880/1000\n",
            "881/1000\n",
            "882/1000\n",
            "883/1000\n",
            "884/1000\n",
            "885/1000\n",
            "886/1000\n",
            "887/1000\n",
            "888/1000\n",
            "889/1000\n",
            "890/1000\n",
            "891/1000\n",
            "892/1000\n",
            "893/1000\n",
            "894/1000\n",
            "895/1000\n",
            "896/1000\n",
            "897/1000\n",
            "898/1000\n",
            "899/1000\n",
            "900/1000\n",
            "901/1000\n",
            "902/1000\n",
            "903/1000\n",
            "904/1000\n",
            "905/1000\n",
            "906/1000\n",
            "907/1000\n",
            "908/1000\n",
            "909/1000\n",
            "910/1000\n",
            "911/1000\n",
            "912/1000\n",
            "913/1000\n",
            "914/1000\n",
            "915/1000\n",
            "916/1000\n",
            "917/1000\n",
            "918/1000\n",
            "919/1000\n",
            "920/1000\n",
            "921/1000\n",
            "922/1000\n",
            "923/1000\n",
            "924/1000\n",
            "925/1000\n",
            "926/1000\n",
            "927/1000\n",
            "928/1000\n",
            "929/1000\n",
            "930/1000\n",
            "931/1000\n",
            "932/1000\n",
            "933/1000\n",
            "934/1000\n",
            "935/1000\n",
            "936/1000\n",
            "937/1000\n",
            "938/1000\n",
            "939/1000\n",
            "940/1000\n",
            "941/1000\n",
            "942/1000\n",
            "943/1000\n",
            "944/1000\n",
            "945/1000\n",
            "946/1000\n",
            "947/1000\n",
            "948/1000\n",
            "949/1000\n",
            "950/1000\n",
            "951/1000\n",
            "952/1000\n",
            "953/1000\n",
            "954/1000\n",
            "955/1000\n",
            "956/1000\n",
            "957/1000\n",
            "958/1000\n",
            "959/1000\n",
            "960/1000\n",
            "961/1000\n",
            "962/1000\n",
            "963/1000\n",
            "964/1000\n",
            "965/1000\n",
            "966/1000\n",
            "967/1000\n",
            "968/1000\n",
            "969/1000\n",
            "970/1000\n",
            "971/1000\n",
            "972/1000\n",
            "973/1000\n",
            "974/1000\n",
            "975/1000\n",
            "976/1000\n",
            "977/1000\n",
            "978/1000\n",
            "979/1000\n",
            "980/1000\n",
            "981/1000\n",
            "982/1000\n",
            "983/1000\n",
            "984/1000\n",
            "985/1000\n",
            "986/1000\n",
            "987/1000\n",
            "988/1000\n",
            "989/1000\n",
            "990/1000\n",
            "991/1000\n",
            "992/1000\n",
            "993/1000\n",
            "994/1000\n",
            "995/1000\n",
            "996/1000\n",
            "997/1000\n",
            "998/1000\n",
            "999/1000\n",
            "1000/1000\n",
            "auroc 0.8673(0.0089)\n",
            "auprc 0.5171(0.0275)\n",
            "minpse 0.5020(0.0224)\n"
          ]
        }
      ],
      "source": [
        "# Bootstrap\n",
        "N = len(y_true)\n",
        "N_idx = np.arange(N)\n",
        "K = 1000\n",
        "\n",
        "auroc = []\n",
        "auprc = []\n",
        "minpse = []\n",
        "for i in range(K):\n",
        "    boot_idx = np.random.choice(N_idx, N, replace=True)\n",
        "    boot_true = np.array(y_true)[boot_idx]\n",
        "    boot_pred = y_pred[boot_idx, :]\n",
        "    test_ret = metrics.print_metrics_binary(boot_true, boot_pred, verbose=0)\n",
        "    auroc.append(test_ret['auroc'])\n",
        "    auprc.append(test_ret['auprc'])\n",
        "    minpse.append(test_ret['minpse'])\n",
        "    print('%d/%d'%(i+1,K))\n",
        "    \n",
        "print('auroc %.4f(%.4f)'%(np.mean(auroc), np.std(auroc)))\n",
        "print('auprc %.4f(%.4f)'%(np.mean(auprc), np.std(auprc)))\n",
        "print('minpse %.4f(%.4f)'%(np.mean(minpse), np.std(minpse)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7Pp3FFBkmcj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoM0T1vjkmcj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7HvWubWkmcj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "concare-notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}