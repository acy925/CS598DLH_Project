{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acy925/CS598DLH_Project/blob/main/ConCare_GRU_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OecOHOeXmjL1",
        "outputId": "cbe7ad06-4498-4415-e18b-ce7ff4c49b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!ls drive/MyDrive/\n",
        "# unzip data.zip in /ColabData\n",
        "# !unzip 'drive/MyDrive/Colab Data/data.zip' -d 'drive/MyDrive/Colab Data/Conore Data'\n",
        "# take time: 8m 15s"
      ],
      "metadata": {
        "id": "nolG_w-b3xaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !/opt/bin/nvidia-smi"
      ],
      "metadata": {
        "id": "V6wX0omO0hHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load utilies dictionary\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/Conore')"
      ],
      "metadata": {
        "id": "r1zejOcC21CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "import imp\n",
        "import re\n",
        "import pickle\n",
        "import datetime\n",
        "import random\n",
        "import math\n",
        "import copy\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "from torch.utils import data\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from utils import utils\n",
        "from utils.readers import InHospitalMortalityReader\n",
        "from utils.preprocessing import Discretizer, Normalizer\n",
        "from utils import metrics\n",
        "from utils import common_utils"
      ],
      "metadata": {
        "id": "PhcWXm42AIY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWs2OrlQkmcV"
      },
      "source": [
        "### Prepare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:11:20.237620Z",
          "start_time": "2021-11-02T02:11:20.234044Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vVBpfvWkmcX",
        "outputId": "5dc89fa6-a2a7-4442-92a6-3e58fe38c6f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/MyDrive/Colab Data/Conore Data/data\n"
          ]
        }
      ],
      "source": [
        "data_path = 'drive/MyDrive/Colab Data/Conore Data/data'\n",
        "file_name = 'drive/My Drive/Colab Notebooks/Conore/model'\n",
        "small_part = False\n",
        "arg_timestep = 1.0\n",
        "batch_size = 256\n",
        "epochs = 100\n",
        "\n",
        "print(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:11:20.399479Z",
          "start_time": "2021-11-02T02:11:20.239796Z"
        },
        "id": "DL_aQNDjkmcX"
      },
      "outputs": [],
      "source": [
        "# Build readers, discretizers, normalizers\n",
        "train_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data_path, 'train'),\n",
        "                                         listfile=os.path.join(data_path, 'train_listfile.csv'),\n",
        "                                         period_length=48.0)\n",
        "\n",
        "val_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data_path, 'train'),\n",
        "                                       listfile=os.path.join(data_path, 'val_listfile.csv'),\n",
        "                                       period_length=48.0)\n",
        "\n",
        "# 这个函数不理解用处\n",
        "discretizer = Discretizer(timestep=arg_timestep,\n",
        "                          store_masks=True,\n",
        "                          impute_strategy='previous',\n",
        "                          start_time='zero')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:11:20.411518Z",
          "start_time": "2021-11-02T02:11:20.401666Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2EdPp5MkmcY",
        "outputId": "6d114fa5-136e-4150-cdb8-69f152564960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ihm_normalizer\n"
          ]
        }
      ],
      "source": [
        "discretizer_header = discretizer.transform(train_reader.read_example(0)[\"X\"])[1].split(',')\n",
        "cont_channels = [i for (i, x) in enumerate(discretizer_header) if x.find(\"->\") == -1]\n",
        "\n",
        "normalizer = Normalizer(fields=cont_channels)  # choose here which columns to standardize\n",
        "normalizer_state = 'ihm_normalizer'\n",
        "print(normalizer_state)\n",
        "normalizer_state = 'drive/MyDrive/Colab Data/Conore Data/data/ihm_normalizer'\n",
        "normalizer.load_params(normalizer_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:12:44.729970Z",
          "start_time": "2021-11-02T02:11:20.413422Z"
        },
        "id": "YqxmepTJkmcZ"
      },
      "outputs": [],
      "source": [
        "n_trained_chunks = 0\n",
        "train_raw = utils.load_data(train_reader, discretizer, normalizer, small_part, return_names=True)\n",
        "val_raw = utils.load_data(val_reader, discretizer, normalizer, small_part, return_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:12:48.064359Z",
          "start_time": "2021-11-02T02:12:44.733279Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeovCBL0kmca",
        "outputId": "38eb1037-6248-4c11-d0dd-e91c2d7ffa47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ],
      "source": [
        "demographic_data = []\n",
        "diagnosis_data = []\n",
        "idx_list = []\n",
        "\n",
        "demo_path = 'drive/MyDrive/Colab Data/Conore Data/data/demographic/'\n",
        "for cur_name in os.listdir(demo_path):\n",
        "    cur_id, cur_episode = cur_name.split('_', 1)\n",
        "    cur_episode = cur_episode[:-4]\n",
        "    cur_file = demo_path + cur_name\n",
        "\n",
        "    with open(cur_file, \"r\") as tsfile:\n",
        "        header = tsfile.readline().strip().split(',')\n",
        "        if header[0] != \"Icustay\":\n",
        "            continue\n",
        "        cur_data = tsfile.readline().strip().split(',')\n",
        "        \n",
        "    if len(cur_data) == 1:\n",
        "        cur_demo = np.zeros(12)\n",
        "        cur_diag = np.zeros(128)\n",
        "    else:\n",
        "        if cur_data[3] == '':\n",
        "            cur_data[3] = 60.0\n",
        "        if cur_data[4] == '':\n",
        "            cur_data[4] = 160\n",
        "        if cur_data[5] == '':\n",
        "            cur_data[5] = 60\n",
        "\n",
        "        cur_demo = np.zeros(12)\n",
        "        cur_demo[int(cur_data[1])] = 1\n",
        "        cur_demo[5 + int(cur_data[2])] = 1\n",
        "        cur_demo[9:] = cur_data[3:6]\n",
        "        cur_diag = np.array(cur_data[8:], dtype=np.int)\n",
        "\n",
        "    demographic_data.append(cur_demo)\n",
        "    diagnosis_data.append(cur_diag)\n",
        "    idx_list.append(cur_id+'_'+cur_episode)\n",
        "\n",
        "for each_idx in range(9,12):\n",
        "    cur_val = []\n",
        "    for i in range(len(demographic_data)):\n",
        "        cur_val.append(demographic_data[i][each_idx])\n",
        "    cur_val = np.array(cur_val)\n",
        "    _mean = np.mean(cur_val)\n",
        "    _std = np.std(cur_val)\n",
        "    _std = _std if _std > 1e-7 else 1e-7\n",
        "    for i in range(len(demographic_data)):\n",
        "        demographic_data[i][each_idx] = (demographic_data[i][each_idx] - _mean) / _std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:12:48.079449Z",
          "start_time": "2021-11-02T02:12:48.067022Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzO1BESVkmcb",
        "outputId": "2b17f7b5-a71b-47ce-aa6c-b15c8ea555c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "available device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() == True else 'cpu')\n",
        "#device = torch.device('cpu')\n",
        "print(\"available device: {}\".format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4p7kD3Xkmcc"
      },
      "source": [
        "### model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:12:48.189439Z",
          "start_time": "2021-11-02T02:12:48.082871Z"
        },
        "id": "wKMDoV05kmcc"
      },
      "outputs": [],
      "source": [
        "class SingleAttention(nn.Module):\n",
        "    def __init__(self, attention_input_dim, attention_hidden_dim, attention_type='add', demographic_dim=12, time_aware=False, use_demographic=False):\n",
        "        super(SingleAttention, self).__init__()\n",
        "        \n",
        "        self.attention_type = attention_type\n",
        "        self.attention_hidden_dim = attention_hidden_dim\n",
        "        self.attention_input_dim = attention_input_dim\n",
        "        self.use_demographic = use_demographic\n",
        "        self.demographic_dim = demographic_dim\n",
        "        self.time_aware = time_aware\n",
        "\n",
        "        # batch_time = torch.arange(0, batch_mask.size()[1], dtype=torch.float32).reshape(1, batch_mask.size()[1], 1)\n",
        "        # batch_time = batch_time.repeat(batch_mask.size()[0], 1, 1)\n",
        "        \n",
        "        if attention_type == 'add':\n",
        "            if self.time_aware == True:\n",
        "                # self.Wx = nn.Parameter(torch.randn(attention_input_dim+1, attention_hidden_dim))\n",
        "                self.Wx = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
        "                self.Wtime_aware = nn.Parameter(torch.randn(1, attention_hidden_dim))\n",
        "                nn.init.kaiming_uniform_(self.Wtime_aware, a=math.sqrt(5))\n",
        "            else:\n",
        "                self.Wx = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
        "            self.Wt = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
        "            self.Wd = nn.Parameter(torch.randn(demographic_dim, attention_hidden_dim))\n",
        "            self.bh = nn.Parameter(torch.zeros(attention_hidden_dim,))\n",
        "            self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
        "            self.ba = nn.Parameter(torch.zeros(1,))\n",
        "            \n",
        "            nn.init.kaiming_uniform_(self.Wd, a=math.sqrt(5))\n",
        "            nn.init.kaiming_uniform_(self.Wx, a=math.sqrt(5))\n",
        "            nn.init.kaiming_uniform_(self.Wt, a=math.sqrt(5))\n",
        "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
        "        elif attention_type == 'mul':\n",
        "            self.Wa = nn.Parameter(torch.randn(attention_input_dim, attention_input_dim))\n",
        "            self.ba = nn.Parameter(torch.zeros(1,))\n",
        "            \n",
        "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
        "        elif attention_type == 'concat':\n",
        "            if self.time_aware == True:\n",
        "                self.Wh = nn.Parameter(torch.randn(2*attention_input_dim+1, attention_hidden_dim))\n",
        "            else:\n",
        "                self.Wh = nn.Parameter(torch.randn(2*attention_input_dim, attention_hidden_dim))\n",
        "\n",
        "            self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
        "            self.ba = nn.Parameter(torch.zeros(1,))\n",
        "            \n",
        "            nn.init.kaiming_uniform_(self.Wh, a=math.sqrt(5))\n",
        "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
        "            \n",
        "        elif attention_type == 'new':\n",
        "            self.Wt = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
        "            self.Wx = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
        "\n",
        "            self.rate = nn.Parameter(torch.zeros(1)+0.8)\n",
        "            nn.init.kaiming_uniform_(self.Wx, a=math.sqrt(5))\n",
        "            nn.init.kaiming_uniform_(self.Wt, a=math.sqrt(5))\n",
        "            \n",
        "        else:\n",
        "            raise RuntimeError('Wrong attention type.')\n",
        "        \n",
        "        self.tanh = nn.Tanh()\n",
        "        self.softmax = nn.Softmax()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, input, demo=None):\n",
        " \n",
        "        batch_size, time_step, input_dim = input.size() # batch_size * time_step * hidden_dim(i)\n",
        "        #assert(input_dim == self.input_dim)\n",
        "\n",
        "        # time_decays = torch.zeros((time_step,time_step)).to(device)# t*t\n",
        "        # for this_time in range(time_step):\n",
        "        #     for pre_time in range(time_step):\n",
        "        #         if pre_time > this_time:\n",
        "        #             break\n",
        "        #         time_decays[this_time][pre_time] = torch.tensor(this_time - pre_time, dtype=torch.float32).to(device)\n",
        "        # b_time_decays = tile(time_decays, 0, batch_size).view(batch_size,time_step,time_step).unsqueeze(-1).to(device)# b t t 1\n",
        "\n",
        "        time_decays = torch.tensor(range(47,-1,-1), dtype=torch.float32).unsqueeze(-1).unsqueeze(0).to(device)# 1*t*1\n",
        "        b_time_decays = time_decays.repeat(batch_size,1,1)+1# b t 1\n",
        "        \n",
        "        if self.attention_type == 'add': #B*T*I  @ H*I\n",
        "            q = torch.matmul(input[:,-1,:], self.Wt)# b h\n",
        "            q = torch.reshape(q, (batch_size, 1, self.attention_hidden_dim)) #B*1*H\n",
        "            if self.time_aware == True:\n",
        "                # k_input = torch.cat((input, time), dim=-1)\n",
        "                k = torch.matmul(input, self.Wx)#b t h\n",
        "                # k = torch.reshape(k, (batch_size, 1, time_step, self.attention_hidden_dim)) #B*1*T*H\n",
        "                time_hidden = torch.matmul(b_time_decays, self.Wtime_aware)#  b t h\n",
        "            else:\n",
        "                k = torch.matmul(input, self.Wx)# b t h\n",
        "                # k = torch.reshape(k, (batch_size, 1, time_step, self.attention_hidden_dim)) #B*1*T*H\n",
        "            if self.use_demographic == True:\n",
        "                d = torch.matmul(demo, self.Wd) #B*H\n",
        "                d = torch.reshape(d, (batch_size, 1, self.attention_hidden_dim)) # b 1 h\n",
        "            h = q + k + self.bh # b t h\n",
        "            if self.time_aware == True:\n",
        "                h += time_hidden\n",
        "            h = self.tanh(h) #B*T*H\n",
        "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
        "            e = torch.reshape(e, (batch_size, time_step))# b t\n",
        "        elif self.attention_type == 'mul':\n",
        "            e = torch.matmul(input[:,-1,:], self.Wa)#b i\n",
        "            e = torch.matmul(e.unsqueeze(1), input.permute(0,2,1)).squeeze() + self.ba #b t\n",
        "        elif self.attention_type == 'concat':\n",
        "            q = input[:,-1,:].unsqueeze(1).repeat(1,time_step,1)# b t i\n",
        "            k = input\n",
        "            c = torch.cat((q, k), dim=-1) #B*T*2I\n",
        "            if self.time_aware == True:\n",
        "                c = torch.cat((c, b_time_decays), dim=-1) #B*T*2I+1\n",
        "            h = torch.matmul(c, self.Wh)\n",
        "            h = self.tanh(h)\n",
        "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
        "            e = torch.reshape(e, (batch_size, time_step)) # b t \n",
        "            \n",
        "        elif self.attention_type == 'new':\n",
        "            \n",
        "            q = torch.matmul(input[:,-1,:], self.Wt)# b h\n",
        "            q = torch.reshape(q, (batch_size, 1, self.attention_hidden_dim)) #B*1*H\n",
        "            k = torch.matmul(input, self.Wx)#b t h\n",
        "            dot_product = torch.matmul(q, k.transpose(1, 2)).squeeze() # b t\n",
        "            denominator =  self.sigmoid(self.rate) * (torch.log(2.72 +  (1-self.sigmoid(dot_product)))* (b_time_decays.squeeze()))\n",
        "            e = self.relu(self.sigmoid(dot_product)/(denominator)) # b * t\n",
        "#          * (b_time_decays.squeeze())\n",
        "        # e = torch.exp(e - torch.max(e, dim=-1, keepdim=True).values)\n",
        "        \n",
        "        # if self.attention_width is not None:\n",
        "        #     if self.history_only:\n",
        "        #         lower = torch.arange(0, time_step).to(device) - (self.attention_width - 1)\n",
        "        #     else:\n",
        "        #         lower = torch.arange(0, time_step).to(device) - self.attention_width // 2\n",
        "        #     lower = lower.unsqueeze(-1)\n",
        "        #     upper = lower + self.attention_width\n",
        "        #     indices = torch.arange(0, time_step).unsqueeze(0).to(device)\n",
        "        #     e = e * (lower <= indices).float() * (indices < upper).float()\n",
        "        \n",
        "        # s = torch.sum(e, dim=-1, keepdim=True)\n",
        "        # mask = subsequent_mask(time_step).to(device) # 1 t t 下三角\n",
        "        # scores = e.masked_fill(mask == 0, -1e9)# b t t 下三角\n",
        "        a = self.softmax(e) #B*T\n",
        "        v = torch.matmul(a.unsqueeze(1), input).squeeze() #B*I\n",
        "\n",
        "        return v, a\n",
        "\n",
        "class FinalAttentionQKV(nn.Module):\n",
        "    def __init__(self, attention_input_dim, attention_hidden_dim, attention_type='add', dropout=None):\n",
        "        super(FinalAttentionQKV, self).__init__()\n",
        "        \n",
        "        self.attention_type = attention_type\n",
        "        self.attention_hidden_dim = attention_hidden_dim\n",
        "        self.attention_input_dim = attention_input_dim\n",
        "\n",
        "\n",
        "        self.W_q = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
        "        self.W_k = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
        "        self.W_v = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
        "\n",
        "        self.W_out = nn.Linear(attention_hidden_dim, 1)\n",
        "\n",
        "        self.b_in = nn.Parameter(torch.zeros(1,))\n",
        "        self.b_out = nn.Parameter(torch.zeros(1,))\n",
        "\n",
        "        nn.init.kaiming_uniform_(self.W_q.weight, a=math.sqrt(5))\n",
        "        nn.init.kaiming_uniform_(self.W_k.weight, a=math.sqrt(5))\n",
        "        nn.init.kaiming_uniform_(self.W_v.weight, a=math.sqrt(5))\n",
        "        nn.init.kaiming_uniform_(self.W_out.weight, a=math.sqrt(5))\n",
        "\n",
        "        self.Wh = nn.Parameter(torch.randn(2*attention_input_dim, attention_hidden_dim))\n",
        "        self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
        "        self.ba = nn.Parameter(torch.zeros(1,))\n",
        "        \n",
        "        nn.init.kaiming_uniform_(self.Wh, a=math.sqrt(5))\n",
        "        nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.softmax = nn.Softmax()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, input):\n",
        " \n",
        "        batch_size, time_step, input_dim = input.size() # batch_size * input_dim + 1 * hidden_dim(i)\n",
        "        input_q = self.W_q(input[:, -1, :]) # b h\n",
        "        input_k = self.W_k(input)# b t h\n",
        "        input_v = self.W_v(input)# b t h\n",
        "\n",
        "        if self.attention_type == 'add': #B*T*I  @ H*I\n",
        "\n",
        "            q = torch.reshape(input_q, (batch_size, 1, self.attention_hidden_dim)) #B*1*H\n",
        "            h = q + input_k + self.b_in # b t h\n",
        "            h = self.tanh(h) #B*T*H\n",
        "            e = self.W_out(h) # b t 1\n",
        "            e = torch.reshape(e, (batch_size, time_step))# b t\n",
        "\n",
        "        elif self.attention_type == 'mul':\n",
        "            q = torch.reshape(input_q, (batch_size, self.attention_hidden_dim, 1)) #B*h 1\n",
        "            e = torch.matmul(input_k, q).squeeze()#b t\n",
        "            \n",
        "        elif self.attention_type == 'concat':\n",
        "            q = input_q.unsqueeze(1).repeat(1,time_step,1)# b t h\n",
        "            k = input_k\n",
        "            c = torch.cat((q, k), dim=-1) #B*T*2I\n",
        "            h = torch.matmul(c, self.Wh)\n",
        "            h = self.tanh(h)\n",
        "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
        "            e = torch.reshape(e, (batch_size, time_step)) # b t \n",
        "        \n",
        "        a = self.softmax(e) #B*T\n",
        "        if self.dropout is not None:\n",
        "            a = self.dropout(a)\n",
        "        v = torch.matmul(a.unsqueeze(1), input_v).squeeze() #B*I\n",
        "\n",
        "        return v, a\n",
        "\n",
        "def clones(module, N):\n",
        "    \"Produce N identical layers.\"\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
        "\n",
        "def tile(a, dim, n_tile):\n",
        "    init_dim = a.size(dim)\n",
        "    repeat_idx = [1] * a.dim()\n",
        "    repeat_idx[dim] = n_tile\n",
        "    a = a.repeat(*(repeat_idx))\n",
        "    order_index = torch.LongTensor(np.concatenate([init_dim * np.arange(n_tile) + i for i in range(init_dim)])).to(device)\n",
        "    return torch.index_select(a, dim, order_index).to(device)\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module): # new added\n",
        "    \"Implements FFN equation.\"\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.w_1 = nn.Linear(d_model, d_ff)\n",
        "        self.w_2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w_2(self.dropout(F.relu(self.w_1(x)))), None\n",
        "\n",
        "# class PositionwiseFeedForwardConv(nn.Module):\n",
        "\n",
        "#     def __init__(self, model_dim=512, ffn_dim=2048, dropout=0.0):\n",
        "#         super(PositionalWiseFeedForward, self).__init__()\n",
        "#         self.w1 = nn.Conv1d(model_dim, ffn_dim, 1)\n",
        "#         self.w2 = nn.Conv1d(model_dim, ffn_dim, 1)\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "#         self.layer_norm = nn.LayerNorm(model_dim)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         output = x.transpose(1, 2)\n",
        "#         output = self.w2(F.relu(self.w1(output)))\n",
        "#         output = self.dropout(output.transpose(1, 2))\n",
        "\n",
        "#         # add residual and norm layer\n",
        "#         output = self.layer_norm(x + output)\n",
        "#         return output\n",
        "\n",
        "class PositionalEncoding(nn.Module): # new added / not use anymore\n",
        "    \"Implement the PE function.\"\n",
        "    def __init__(self, d_model, dropout, max_len=400):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        \n",
        "        # Compute the positional encodings once in log space.\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0., max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0., d_model, 2) * -(math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x + Variable(self.pe[:, :x.size(1)], \n",
        "                         requires_grad=False)\n",
        "        return self.dropout(x)\n",
        "\n",
        "def subsequent_mask(size):\n",
        "    \"Mask out subsequent positions.\"\n",
        "    attn_shape = (1, size, size)\n",
        "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
        "    return torch.from_numpy(subsequent_mask) == 0 # 下三角矩阵\n",
        "\n",
        "def attention(query, key, value, mask=None, dropout=None):\n",
        "    \"Compute 'Scaled Dot Product Attention'\"\n",
        "    d_k = query.size(-1)# b h t d_k\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
        "             / math.sqrt(d_k) # b h t t\n",
        "    if mask is not None:# 1 1 t t\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)# b h t t 下三角\n",
        "    p_attn = F.softmax(scores, dim = -1)# b h t t\n",
        "    if dropout is not None:\n",
        "        p_attn = dropout(p_attn)\n",
        "    return torch.matmul(p_attn, value), p_attn # b h t v (d_k) \n",
        "    \n",
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, h, d_model, dropout=0):\n",
        "        \"Take in model size and number of heads.\"\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        assert d_model % h == 0\n",
        "        # We assume d_v always equals d_k\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.linears = clones(nn.Linear(d_model, self.d_k * self.h), 3)\n",
        "        self.final_linear = nn.Linear(d_model, d_model)\n",
        "        self.attn = None\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        \n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        if mask is not None:\n",
        "            # Same mask applied to all h heads.\n",
        "            mask = mask.unsqueeze(1) # 1 1 t t\n",
        "\n",
        "        nbatches = query.size(0)# b\n",
        "        input_dim = query.size(1)# i+1\n",
        "        feature_dim = query.size(-1)# i+1\n",
        "\n",
        "        #input size -> # batch_size * d_input * hidden_dim\n",
        "        \n",
        "        # d_model => h * d_k \n",
        "        query, key, value = \\\n",
        "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "             for l, x in zip(self.linears, (query, key, value))] # b num_head d_input d_k\n",
        "        \n",
        "       \n",
        "        x, self.attn = attention(query, key, value, mask=mask, \n",
        "                                 dropout=self.dropout)# b num_head d_input d_v (d_k) \n",
        "\n",
        "      \n",
        "        x = x.transpose(1, 2).contiguous() \\\n",
        "             .view(nbatches, -1, self.h * self.d_k)# batch_size * d_input * hidden_dim\n",
        "\n",
        "        #DeCov \n",
        "        DeCov_contexts = x.transpose(0, 1).transpose(1, 2) # I+1 H B\n",
        "        Covs = cov(DeCov_contexts[0,:,:])\n",
        "        DeCov_loss = 0.5 * (torch.norm(Covs, p = 'fro')**2 - torch.norm(torch.diag(Covs))**2 ) \n",
        "        for i in range(feature_dim -1 + 1):\n",
        "            Covs = cov(DeCov_contexts[i+1,:,:])\n",
        "            DeCov_loss += 0.5 * (torch.norm(Covs, p = 'fro')**2 - torch.norm(torch.diag(Covs))**2 ) \n",
        "\n",
        "\n",
        "        return self.final_linear(x), DeCov_loss\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, features, eps=1e-7):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
        "\n",
        "def cov(m, y=None):\n",
        "    if y is not None:\n",
        "        m = torch.cat((m, y), dim=0)\n",
        "    m_exp = torch.mean(m, dim=1)\n",
        "    x = m - m_exp[:, None]\n",
        "    cov = 1 / (x.size(1) - 1) * x.mm(x.t())\n",
        "    return cov\n",
        "\n",
        "class SublayerConnection(nn.Module):\n",
        "    \"\"\"\n",
        "    A residual connection followed by a layer norm.\n",
        "    Note for code simplicity the norm is first as opposed to last.\n",
        "    \"\"\"\n",
        "    def __init__(self, size, dropout):\n",
        "        super(SublayerConnection, self).__init__()\n",
        "        self.norm = LayerNorm(size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        \"Apply residual connection to any sublayer with the same size.\"\n",
        "        returned_value = sublayer(self.norm(x))\n",
        "        return x + self.dropout(returned_value[0]) , returned_value[1]\n",
        "\n",
        "class ConCare(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, d_model,  MHD_num_head, d_ff, output_dim, keep_prob=0.5):\n",
        "        super(ConCare, self).__init__()\n",
        "\n",
        "        # hyperparameters\n",
        "        self.input_dim = input_dim  \n",
        "        self.hidden_dim = hidden_dim  # d_model\n",
        "        self.d_model = d_model\n",
        "        self.MHD_num_head = MHD_num_head\n",
        "        self.d_ff = d_ff\n",
        "        self.output_dim = output_dim\n",
        "        self.keep_prob = keep_prob\n",
        "\n",
        "        # layers\n",
        "        self.PositionalEncoding = PositionalEncoding(self.d_model, dropout = 0, max_len = 400)\n",
        "\n",
        "        self.GRUs = clones(nn.GRU(1, self.hidden_dim, batch_first = True), self.input_dim)\n",
        "        self.LastStepAttentions = clones(SingleAttention(self.hidden_dim, 8, attention_type='new', demographic_dim=12, time_aware=True, use_demographic=False),self.input_dim)\n",
        "        \n",
        "        self.FinalAttentionQKV = FinalAttentionQKV(self.hidden_dim, self.hidden_dim, attention_type='mul',dropout = 1 - self.keep_prob)\n",
        "\n",
        "        self.MultiHeadedAttention = MultiHeadedAttention(self.MHD_num_head, self.d_model,dropout = 1 - self.keep_prob)\n",
        "        self.SublayerConnection = SublayerConnection(self.d_model, dropout = 1 - self.keep_prob)\n",
        "\n",
        "        self.PositionwiseFeedForward = PositionwiseFeedForward(self.d_model, self.d_ff, dropout=0.1)\n",
        "\n",
        "        self.demo_proj_main = nn.Linear(12, self.hidden_dim)\n",
        "        self.demo_proj = nn.Linear(12, self.hidden_dim)\n",
        "        self.output0 = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "        self.output1 = nn.Linear(self.hidden_dim, self.output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(p = 1 - self.keep_prob)\n",
        "        self.tanh=nn.Tanh()\n",
        "        self.softmax = nn.Softmax()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.relu=nn.ReLU()\n",
        "        self.f1 = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            nn.Dropout(p = 1 - self.keep_prob),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.hidden_dim, self.output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, input, demo_input):\n",
        "        # input shape [batch_size, timestep, feature_dim]\n",
        "        demo_main = self.tanh(self.demo_proj_main(demo_input)).unsqueeze(1)# b hidden_dim\n",
        "        \n",
        "        batch_size = input.size(0)\n",
        "        time_step = input.size(1)\n",
        "        feature_dim = input.size(2)\n",
        "        assert(feature_dim == self.input_dim)# input Tensor : 256 * 48 * 76\n",
        "        assert(self.d_model % self.MHD_num_head == 0)\n",
        "\n",
        "\n",
        "        # Initialization\n",
        "        h0 = Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0)).to(device)\n",
        "\n",
        "        # GRU\n",
        "        output, hn = self.GRU(input, h0)\n",
        "        # print(output.shape) # 256,48,64\n",
        "        output = self.f1(output[:, -1, :])\n",
        "        output = self.sigmoid(output)\n",
        "        # print(output.shape)\n",
        "\n",
        "        # forward\n",
        "#         GRU_embeded_input = self.GRUs[0](input[:,:,0].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0)).to(device))[0] # b t h\n",
        "#         Attention_embeded_input = self.LastStepAttentions[0](GRU_embeded_input)[0].unsqueeze(1)# b 1 h\n",
        "#         for i in range(feature_dim-1):\n",
        "#             embeded_input = self.GRUs[i+1](input[:,:,i+1].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0)).to(device))[0] # b 1 h\n",
        "#             embeded_input = self.LastStepAttentions[i+1](embeded_input)[0].unsqueeze(1)# b 1 h\n",
        "#             Attention_embeded_input = torch.cat((Attention_embeded_input, embeded_input), 1)# b i h\n",
        "\n",
        "#         Attention_embeded_input = torch.cat((Attention_embeded_input, demo_main), 1)# b i+1 h\n",
        "#         posi_input = self.dropout(Attention_embeded_input) # batch_size * d_input+1 * hidden_dim\n",
        "\n",
        "# #         GRU_embeded_input = self.GRUs[0](input[:,:,0].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0)).to(device))[0][:,-1,:].unsqueeze(1) # b 1 h\n",
        "# #         for i in range(feature_dim-1):\n",
        "# #             embeded_input = self.GRUs[i+1](input[:,:,i+1].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0)).to(device))[0][:,-1,:].unsqueeze(1) # b 1 h\n",
        "# #             GRU_embeded_input = torch.cat((GRU_embeded_input, embeded_input), 1)\n",
        "\n",
        "# #         GRU_embeded_input = torch.cat((GRU_embeded_input, demo_main), 1)# b i+1 h\n",
        "# #         posi_input = self.dropout(GRU_embeded_input) # batch_size * d_input * hidden_dim\n",
        "\n",
        "\n",
        "#         #mask = subsequent_mask(time_step).to(device) # 1 t t 下三角 N to 1任务不用mask\n",
        "#         contexts = self.SublayerConnection(posi_input, lambda x: self.MultiHeadedAttention(posi_input, posi_input, posi_input, None))# # batch_size * d_input * hidden_dim\n",
        "    \n",
        "#         DeCov_loss = contexts[1]\n",
        "#         contexts = contexts[0]\n",
        "\n",
        "#         contexts = self.SublayerConnection(contexts, lambda x: self.PositionwiseFeedForward(contexts))[0]# # batch_size * d_input * hidden_dim\n",
        "        #contexts = contexts.view(batch_size, feature_dim * self.hidden_dim)#\n",
        "        # contexts = torch.matmul(self.Wproj, contexts) + self.bproj\n",
        "        # contexts = contexts.squeeze()\n",
        "        # demo_key = self.demo_proj(demo_input)# b hidden_dim\n",
        "        # demo_key = self.relu(demo_key)\n",
        "        # input_dim_scores = torch.matmul(contexts, demo_key.unsqueeze(-1)).squeeze() # b i\n",
        "        # input_dim_scores = self.dropout(self.sigmoid(input_dim_scores)).unsqueeze(1)# b i\n",
        "        \n",
        "        # weighted_contexts = torch.matmul(input_dim_scores, contexts).squeeze()\n",
        "\n",
        "        # weighted_contexts = self.FinalAttentionQKV(contexts)[0]\n",
        "        # output = self.output1(self.relu(self.output0(weighted_contexts)))# b 1\n",
        "        # output = self.sigmoid(output)\n",
        "          \n",
        "        return output, DeCov_loss\n",
        "    #, self.MultiHeadedAttention.attn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:12:48.282265Z",
          "start_time": "2021-11-02T02:12:48.191901Z"
        },
        "id": "SBmPEKdKkmcf"
      },
      "outputs": [],
      "source": [
        "def get_loss(y_pred, y_true):\n",
        "    loss = torch.nn.BCELoss()\n",
        "    return loss(y_pred, y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:12:48.355893Z",
          "start_time": "2021-11-02T02:12:48.284802Z"
        },
        "id": "iPkFjqErkmcg"
      },
      "outputs": [],
      "source": [
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, x, y, name):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.name = name\n",
        "\n",
        "    def __getitem__(self, index):#返回的是tensor\n",
        "        return self.x[index], self.y[index], self.name[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T02:12:48.442051Z",
          "start_time": "2021-11-02T02:12:48.358759Z"
        },
        "id": "k5Yr2lP0kmch"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset(train_raw['data'][0], train_raw['data'][1], train_raw['names'])\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_dataset = Dataset(val_raw['data'][0], val_raw['data'][1], val_raw['names'])\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFK_WZ_rkmch"
      },
      "source": [
        "### Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T03:27:01.575443Z",
          "start_time": "2021-11-02T02:12:48.445259Z"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVJeeQ5skmch",
        "outputId": "850e05d1-392f-4546-8b47-5bfc92360d9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Batch 0: Train Loss = 0.7099\n",
            "Model Loss = 0.7099, Decov Loss = 0.0003\n",
            "Epoch 0 Batch 30: Train Loss = 0.4819\n",
            "Model Loss = 0.4819, Decov Loss = 0.0015\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3941\n",
            "valid_model Loss = 0.3941\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2786    0]\n",
            " [ 436    0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Conore/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
            "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = 0.8646803498268127\n",
            "precision class 0 = 0.8646803498268127\n",
            "precision class 1 = nan\n",
            "recall class 0 = 1.0\n",
            "recall class 1 = 0.0\n",
            "AUC of ROC = 0.770005416993223\n",
            "AUC of PRC = 0.35893383623952235\n",
            "min(+P, Se) = 0.4013761467889908\n",
            "f1_score = nan\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0: Train Loss = 0.4302\n",
            "Model Loss = 0.4302, Decov Loss = 0.0010\n",
            "Epoch 1 Batch 30: Train Loss = 0.3948\n",
            "Model Loss = 0.3948, Decov Loss = 0.0010\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3889\n",
            "valid_model Loss = 0.3889\n",
            "valid_decov Loss = 0.0000\n",
            "confusion matrix:\n",
            "[[2786    0]\n",
            " [ 436    0]]\n",
            "accuracy = 0.8646803498268127\n",
            "precision class 0 = 0.8646803498268127\n",
            "precision class 1 = nan\n",
            "recall class 0 = 1.0\n",
            "recall class 1 = 0.0\n",
            "AUC of ROC = 0.7266143133755277\n",
            "AUC of PRC = 0.33712199499740264\n",
            "min(+P, Se) = 0.37844036697247707\n",
            "f1_score = nan\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Conore/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
            "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Batch 0: Train Loss = 0.4222\n",
            "Model Loss = 0.4222, Decov Loss = 0.0011\n",
            "Epoch 2 Batch 30: Train Loss = 0.3927\n",
            "Model Loss = 0.3927, Decov Loss = 0.0015\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3630\n",
            "valid_model Loss = 0.3630\n",
            "valid_decov Loss = 0.0001\n",
            "confusion matrix:\n",
            "[[2786    0]\n",
            " [ 436    0]]\n",
            "accuracy = 0.8646803498268127\n",
            "precision class 0 = 0.8646803498268127\n",
            "precision class 1 = nan\n",
            "recall class 0 = 1.0\n",
            "recall class 1 = 0.0\n",
            "AUC of ROC = 0.7653083569880857\n",
            "AUC of PRC = 0.30665951481384346\n",
            "min(+P, Se) = 0.35655737704918034\n",
            "f1_score = nan\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Conore/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
            "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Batch 0: Train Loss = 0.3462\n",
            "Model Loss = 0.3462, Decov Loss = 0.0019\n",
            "Epoch 3 Batch 30: Train Loss = 0.3717\n",
            "Model Loss = 0.3717, Decov Loss = 0.0048\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3356\n",
            "valid_model Loss = 0.3356\n",
            "valid_decov Loss = 0.0006\n",
            "confusion matrix:\n",
            "[[2786    0]\n",
            " [ 436    0]]\n",
            "accuracy = 0.8646803498268127\n",
            "precision class 0 = 0.8646803498268127\n",
            "precision class 1 = nan\n",
            "recall class 0 = 1.0\n",
            "recall class 1 = 0.0\n",
            "AUC of ROC = 0.7949536344896171\n",
            "AUC of PRC = 0.40938969337997333\n",
            "min(+P, Se) = 0.43577981651376146\n",
            "f1_score = nan\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Conore/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
            "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Batch 0: Train Loss = 0.3095\n",
            "Model Loss = 0.3095, Decov Loss = 0.0031\n",
            "Epoch 4 Batch 30: Train Loss = 0.3486\n",
            "Model Loss = 0.3486, Decov Loss = 0.0172\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3216\n",
            "valid_model Loss = 0.3216\n",
            "valid_decov Loss = 0.0036\n",
            "confusion matrix:\n",
            "[[2739   47]\n",
            " [ 355   81]]\n",
            "accuracy = 0.8752327561378479\n",
            "precision class 0 = 0.8852617740631104\n",
            "precision class 1 = 0.6328125\n",
            "recall class 0 = 0.9831299185752869\n",
            "recall class 1 = 0.18577980995178223\n",
            "AUC of ROC = 0.8110506661749113\n",
            "AUC of PRC = 0.4407709926488728\n",
            "min(+P, Se) = 0.4376417233560091\n",
            "f1_score = 0.28723403471023834\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Batch 0: Train Loss = 0.3666\n",
            "Model Loss = 0.3666, Decov Loss = 0.2717\n",
            "Epoch 5 Batch 30: Train Loss = 0.3380\n",
            "Model Loss = 0.3380, Decov Loss = 0.0259\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3144\n",
            "valid_model Loss = 0.3144\n",
            "valid_decov Loss = 0.0082\n",
            "confusion matrix:\n",
            "[[2786    0]\n",
            " [ 436    0]]\n",
            "accuracy = 0.8646803498268127\n",
            "precision class 0 = 0.8646803498268127\n",
            "precision class 1 = nan\n",
            "recall class 0 = 1.0\n",
            "recall class 1 = 0.0\n",
            "AUC of ROC = 0.8204991207676655\n",
            "AUC of PRC = 0.44196926939107173\n",
            "min(+P, Se) = 0.44495412844036697\n",
            "f1_score = nan\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Conore/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
            "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Batch 0: Train Loss = 0.3319\n",
            "Model Loss = 0.3319, Decov Loss = 0.0190\n",
            "Epoch 6 Batch 30: Train Loss = 0.3315\n",
            "Model Loss = 0.3315, Decov Loss = 0.0157\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3121\n",
            "valid_model Loss = 0.3121\n",
            "valid_decov Loss = 0.0186\n",
            "confusion matrix:\n",
            "[[2752   34]\n",
            " [ 367   69]]\n",
            "accuracy = 0.8755431175231934\n",
            "precision class 0 = 0.8823340535163879\n",
            "precision class 1 = 0.6699029207229614\n",
            "recall class 0 = 0.9877961277961731\n",
            "recall class 1 = 0.1582568734884262\n",
            "AUC of ROC = 0.8174481516362941\n",
            "AUC of PRC = 0.45896674538408916\n",
            "min(+P, Se) = 0.4701834862385321\n",
            "f1_score = 0.25602967110415037\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Batch 0: Train Loss = 0.2969\n",
            "Model Loss = 0.2969, Decov Loss = 0.0393\n",
            "Epoch 7 Batch 30: Train Loss = 0.3218\n",
            "Model Loss = 0.3218, Decov Loss = 0.0338\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3065\n",
            "valid_model Loss = 0.3065\n",
            "valid_decov Loss = 0.0239\n",
            "confusion matrix:\n",
            "[[2740   46]\n",
            " [ 351   85]]\n",
            "accuracy = 0.87678462266922\n",
            "precision class 0 = 0.8864445090293884\n",
            "precision class 1 = 0.6488549709320068\n",
            "recall class 0 = 0.9834888577461243\n",
            "recall class 1 = 0.19495412707328796\n",
            "AUC of ROC = 0.8265862405079132\n",
            "AUC of PRC = 0.4642404766440288\n",
            "min(+P, Se) = 0.47368421052631576\n",
            "f1_score = 0.29982362192235845\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Batch 0: Train Loss = 0.3451\n",
            "Model Loss = 0.3451, Decov Loss = 0.0322\n",
            "Epoch 8 Batch 30: Train Loss = 0.3160\n",
            "Model Loss = 0.3160, Decov Loss = 0.0646\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3033\n",
            "valid_model Loss = 0.3033\n",
            "valid_decov Loss = 0.1501\n",
            "confusion matrix:\n",
            "[[2712   74]\n",
            " [ 324  112]]\n",
            "accuracy = 0.8764742612838745\n",
            "precision class 0 = 0.8932806253433228\n",
            "precision class 1 = 0.602150559425354\n",
            "recall class 0 = 0.9734386205673218\n",
            "recall class 1 = 0.2568807303905487\n",
            "AUC of ROC = 0.8349158966523311\n",
            "AUC of PRC = 0.4725813948851058\n",
            "min(+P, Se) = 0.4793577981651376\n",
            "f1_score = 0.3601286052736854\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Batch 0: Train Loss = 0.3346\n",
            "Model Loss = 0.3346, Decov Loss = 0.4341\n",
            "Epoch 9 Batch 30: Train Loss = 0.3103\n",
            "Model Loss = 0.3103, Decov Loss = 0.2279\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3125\n",
            "valid_model Loss = 0.3125\n",
            "valid_decov Loss = 0.0483\n",
            "confusion matrix:\n",
            "[[2771   15]\n",
            " [ 400   36]]\n",
            "accuracy = 0.8711979985237122\n",
            "precision class 0 = 0.8738568425178528\n",
            "precision class 1 = 0.7058823704719543\n",
            "recall class 0 = 0.994615912437439\n",
            "recall class 1 = 0.08256880939006805\n",
            "AUC of ROC = 0.8349249524160777\n",
            "AUC of PRC = 0.48788330592654244\n",
            "min(+P, Se) = 0.4897025171624714\n",
            "f1_score = 0.14784394338273313\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Batch 0: Train Loss = 0.3015\n",
            "Model Loss = 0.3015, Decov Loss = 0.1052\n",
            "Epoch 10 Batch 30: Train Loss = 0.3111\n",
            "Model Loss = 0.3111, Decov Loss = 0.1507\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3001\n",
            "valid_model Loss = 0.3001\n",
            "valid_decov Loss = 0.0614\n",
            "confusion matrix:\n",
            "[[2732   54]\n",
            " [ 316  120]]\n",
            "accuracy = 0.8851644992828369\n",
            "precision class 0 = 0.8963254690170288\n",
            "precision class 1 = 0.6896551847457886\n",
            "recall class 0 = 0.980617344379425\n",
            "recall class 1 = 0.2752293646335602\n",
            "AUC of ROC = 0.8401501280978945\n",
            "AUC of PRC = 0.506924491480583\n",
            "min(+P, Se) = 0.4874715261958998\n",
            "f1_score = 0.3934426440938899\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Batch 0: Train Loss = 0.3020\n",
            "Model Loss = 0.3020, Decov Loss = 0.1304\n",
            "Epoch 11 Batch 30: Train Loss = 0.3056\n",
            "Model Loss = 0.3056, Decov Loss = 0.0886\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2925\n",
            "valid_model Loss = 0.2925\n",
            "valid_decov Loss = 0.0514\n",
            "confusion matrix:\n",
            "[[2722   64]\n",
            " [ 307  129]]\n",
            "accuracy = 0.8848541378974915\n",
            "precision class 0 = 0.8986464142799377\n",
            "precision class 1 = 0.6683937907218933\n",
            "recall class 0 = 0.9770280122756958\n",
            "recall class 1 = 0.2958715558052063\n",
            "AUC of ROC = 0.844391518536325\n",
            "AUC of PRC = 0.5176186144936307\n",
            "min(+P, Se) = 0.5\n",
            "f1_score = 0.4101748786548729\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Batch 0: Train Loss = 0.2531\n",
            "Model Loss = 0.2531, Decov Loss = 0.0766\n",
            "Epoch 12 Batch 30: Train Loss = 0.2905\n",
            "Model Loss = 0.2905, Decov Loss = 0.0982\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2971\n",
            "valid_model Loss = 0.2971\n",
            "valid_decov Loss = 0.0661\n",
            "confusion matrix:\n",
            "[[2718   68]\n",
            " [ 314  122]]\n",
            "accuracy = 0.8814401030540466\n",
            "precision class 0 = 0.8964380025863647\n",
            "precision class 1 = 0.6421052813529968\n",
            "recall class 0 = 0.9755922555923462\n",
            "recall class 1 = 0.27981650829315186\n",
            "AUC of ROC = 0.8472058029334089\n",
            "AUC of PRC = 0.5221791518426132\n",
            "min(+P, Se) = 0.5045871559633027\n",
            "f1_score = 0.3897763558745018\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Batch 0: Train Loss = 0.2705\n",
            "Model Loss = 0.2705, Decov Loss = 0.0950\n",
            "Epoch 13 Batch 30: Train Loss = 0.3017\n",
            "Model Loss = 0.3017, Decov Loss = 0.0923\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3086\n",
            "valid_model Loss = 0.3086\n",
            "valid_decov Loss = 0.0606\n",
            "confusion matrix:\n",
            "[[2737   49]\n",
            " [ 337   99]]\n",
            "accuracy = 0.8801986575126648\n",
            "precision class 0 = 0.8903708457946777\n",
            "precision class 1 = 0.6689189076423645\n",
            "recall class 0 = 0.9824120402336121\n",
            "recall class 1 = 0.22706422209739685\n",
            "AUC of ROC = 0.8434958211766567\n",
            "AUC of PRC = 0.5061036132357051\n",
            "min(+P, Se) = 0.4870689655172414\n",
            "f1_score = 0.33904110785272473\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Batch 0: Train Loss = 0.2934\n",
            "Model Loss = 0.2934, Decov Loss = 0.1070\n",
            "Epoch 14 Batch 30: Train Loss = 0.2947\n",
            "Model Loss = 0.2947, Decov Loss = 0.1105\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2884\n",
            "valid_model Loss = 0.2884\n",
            "valid_decov Loss = 0.0602\n",
            "confusion matrix:\n",
            "[[2707   79]\n",
            " [ 306  130]]\n",
            "accuracy = 0.8805090188980103\n",
            "precision class 0 = 0.8984401226043701\n",
            "precision class 1 = 0.6220095753669739\n",
            "recall class 0 = 0.9716439247131348\n",
            "recall class 1 = 0.29816514253616333\n",
            "AUC of ROC = 0.847767671911326\n",
            "AUC of PRC = 0.5230687519733925\n",
            "min(+P, Se) = 0.5114678899082569\n",
            "f1_score = 0.40310078094902607\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Batch 0: Train Loss = 0.2469\n",
            "Model Loss = 0.2469, Decov Loss = 0.1116\n",
            "Epoch 15 Batch 30: Train Loss = 0.2856\n",
            "Model Loss = 0.2856, Decov Loss = 0.1144\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3024\n",
            "valid_model Loss = 0.3024\n",
            "valid_decov Loss = 0.0499\n",
            "confusion matrix:\n",
            "[[2756   30]\n",
            " [ 359   77]]\n",
            "accuracy = 0.8792675137519836\n",
            "precision class 0 = 0.8847512006759644\n",
            "precision class 1 = 0.7196261882781982\n",
            "recall class 0 = 0.9892318844795227\n",
            "recall class 1 = 0.17660550773143768\n",
            "AUC of ROC = 0.8522371029459223\n",
            "AUC of PRC = 0.5332400038424877\n",
            "min(+P, Se) = 0.5412844036697247\n",
            "f1_score = 0.28360957732360303\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Batch 0: Train Loss = 0.3248\n",
            "Model Loss = 0.3248, Decov Loss = 0.1143\n",
            "Epoch 16 Batch 30: Train Loss = 0.2942\n",
            "Model Loss = 0.2942, Decov Loss = 0.0925\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2911\n",
            "valid_model Loss = 0.2911\n",
            "valid_decov Loss = 0.0654\n",
            "confusion matrix:\n",
            "[[2718   68]\n",
            " [ 313  123]]\n",
            "accuracy = 0.8817504644393921\n",
            "precision class 0 = 0.8967337608337402\n",
            "precision class 1 = 0.6439790725708008\n",
            "recall class 0 = 0.9755922555923462\n",
            "recall class 1 = 0.2821100950241089\n",
            "AUC of ROC = 0.8510952534625946\n",
            "AUC of PRC = 0.5247446009830675\n",
            "min(+P, Se) = 0.5229357798165137\n",
            "f1_score = 0.39234450356070594\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 Batch 0: Train Loss = 0.2591\n",
            "Model Loss = 0.2591, Decov Loss = 0.0831\n",
            "Epoch 17 Batch 30: Train Loss = 0.2876\n",
            "Model Loss = 0.2876, Decov Loss = 0.1217\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2854\n",
            "valid_model Loss = 0.2854\n",
            "valid_decov Loss = 0.0626\n",
            "confusion matrix:\n",
            "[[2715   71]\n",
            " [ 308  128]]\n",
            "accuracy = 0.882371187210083\n",
            "precision class 0 = 0.8981144428253174\n",
            "precision class 1 = 0.643216073513031\n",
            "recall class 0 = 0.974515438079834\n",
            "recall class 1 = 0.29357796907424927\n",
            "AUC of ROC = 0.8533781291780003\n",
            "AUC of PRC = 0.5183881637108986\n",
            "min(+P, Se) = 0.5160550458715596\n",
            "f1_score = 0.40314959308737314\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 Batch 0: Train Loss = 0.2574\n",
            "Model Loss = 0.2574, Decov Loss = 0.0818\n",
            "Epoch 18 Batch 30: Train Loss = 0.2952\n",
            "Model Loss = 0.2952, Decov Loss = 0.1087\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3173\n",
            "valid_model Loss = 0.3173\n",
            "valid_decov Loss = 0.0813\n",
            "confusion matrix:\n",
            "[[2755   31]\n",
            " [ 360   76]]\n",
            "accuracy = 0.8786467909812927\n",
            "precision class 0 = 0.8844301700592041\n",
            "precision class 1 = 0.7102803587913513\n",
            "recall class 0 = 0.9888729453086853\n",
            "recall class 1 = 0.17431192100048065\n",
            "AUC of ROC = 0.8532587577467944\n",
            "AUC of PRC = 0.5240809387237906\n",
            "min(+P, Se) = 0.5148741418764302\n",
            "f1_score = 0.27992632206411144\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 Batch 0: Train Loss = 0.3035\n",
            "Model Loss = 0.3035, Decov Loss = 0.1054\n",
            "Epoch 19 Batch 30: Train Loss = 0.2951\n",
            "Model Loss = 0.2951, Decov Loss = 0.1257\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2933\n",
            "valid_model Loss = 0.2933\n",
            "valid_decov Loss = 0.0797\n",
            "confusion matrix:\n",
            "[[2631  155]\n",
            " [ 244  192]]\n",
            "accuracy = 0.876163899898529\n",
            "precision class 0 = 0.9151304364204407\n",
            "precision class 1 = 0.5533141493797302\n",
            "recall class 0 = 0.9443646669387817\n",
            "recall class 1 = 0.4403669834136963\n",
            "AUC of ROC = 0.8540614277152474\n",
            "AUC of PRC = 0.5253809981261814\n",
            "min(+P, Se) = 0.517162471395881\n",
            "f1_score = 0.49042147385346635\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Batch 0: Train Loss = 0.3008\n",
            "Model Loss = 0.3008, Decov Loss = 0.1268\n",
            "Epoch 20 Batch 30: Train Loss = 0.2859\n",
            "Model Loss = 0.2859, Decov Loss = 0.1483\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2839\n",
            "valid_model Loss = 0.2839\n",
            "valid_decov Loss = 0.0914\n",
            "confusion matrix:\n",
            "[[2710   76]\n",
            " [ 300  136]]\n",
            "accuracy = 0.8833022713661194\n",
            "precision class 0 = 0.9003322124481201\n",
            "precision class 1 = 0.6415094137191772\n",
            "recall class 0 = 0.972720742225647\n",
            "recall class 1 = 0.31192660331726074\n",
            "AUC of ROC = 0.8542787660451667\n",
            "AUC of PRC = 0.5260445964279373\n",
            "min(+P, Se) = 0.5068807339449541\n",
            "f1_score = 0.4197530801058941\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 Batch 0: Train Loss = 0.3285\n",
            "Model Loss = 0.3285, Decov Loss = 0.1497\n",
            "Epoch 21 Batch 30: Train Loss = 0.2931\n",
            "Model Loss = 0.2931, Decov Loss = 0.1445\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2844\n",
            "valid_model Loss = 0.2844\n",
            "valid_decov Loss = 0.0789\n",
            "confusion matrix:\n",
            "[[2673  113]\n",
            " [ 265  171]]\n",
            "accuracy = 0.8826815485954285\n",
            "precision class 0 = 0.9098026156425476\n",
            "precision class 1 = 0.6021126508712769\n",
            "recall class 0 = 0.9594400525093079\n",
            "recall class 1 = 0.39220184087753296\n",
            "AUC of ROC = 0.8557894320883578\n",
            "AUC of PRC = 0.5304102062712368\n",
            "min(+P, Se) = 0.5137614678899083\n",
            "f1_score = 0.4749999965745722\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 Batch 0: Train Loss = 0.3098\n",
            "Model Loss = 0.3098, Decov Loss = 0.0836\n",
            "Epoch 22 Batch 30: Train Loss = 0.2818\n",
            "Model Loss = 0.2818, Decov Loss = 0.1219\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2806\n",
            "valid_model Loss = 0.2806\n",
            "valid_decov Loss = 0.0795\n",
            "confusion matrix:\n",
            "[[2726   60]\n",
            " [ 310  126]]\n",
            "accuracy = 0.8851644992828369\n",
            "precision class 0 = 0.8978919386863708\n",
            "precision class 1 = 0.6774193644523621\n",
            "recall class 0 = 0.9784637689590454\n",
            "recall class 1 = 0.2889908254146576\n",
            "AUC of ROC = 0.8577751141026232\n",
            "AUC of PRC = 0.5468721007226803\n",
            "min(+P, Se) = 0.5344036697247706\n",
            "f1_score = 0.4051447084783442\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 Batch 0: Train Loss = 0.2724\n",
            "Model Loss = 0.2724, Decov Loss = 0.3537\n",
            "Epoch 23 Batch 30: Train Loss = 0.2812\n",
            "Model Loss = 0.2812, Decov Loss = 0.1703\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2833\n",
            "valid_model Loss = 0.2833\n",
            "valid_decov Loss = 0.0879\n",
            "confusion matrix:\n",
            "[[2719   67]\n",
            " [ 297  139]]\n",
            "accuracy = 0.8870266675949097\n",
            "precision class 0 = 0.9015251994132996\n",
            "precision class 1 = 0.6747573018074036\n",
            "recall class 0 = 0.9759511947631836\n",
            "recall class 1 = 0.31880733370780945\n",
            "AUC of ROC = 0.8563648847118951\n",
            "AUC of PRC = 0.534073502097475\n",
            "min(+P, Se) = 0.5234899328859061\n",
            "f1_score = 0.4330218187165502\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 Batch 0: Train Loss = 0.3347\n",
            "Model Loss = 0.3347, Decov Loss = 0.1183\n",
            "Epoch 24 Batch 30: Train Loss = 0.2717\n",
            "Model Loss = 0.2717, Decov Loss = 0.1652\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2872\n",
            "valid_model Loss = 0.2872\n",
            "valid_decov Loss = 0.0772\n",
            "confusion matrix:\n",
            "[[2669  117]\n",
            " [ 256  180]]\n",
            "accuracy = 0.8842334151268005\n",
            "precision class 0 = 0.9124786257743835\n",
            "precision class 1 = 0.6060606241226196\n",
            "recall class 0 = 0.9580042958259583\n",
            "recall class 1 = 0.4128440320491791\n",
            "AUC of ROC = 0.8588198199384867\n",
            "AUC of PRC = 0.53777654770141\n",
            "min(+P, Se) = 0.5137614678899083\n",
            "f1_score = 0.49113232115487443\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 Batch 0: Train Loss = 0.2836\n",
            "Model Loss = 0.2836, Decov Loss = 0.0833\n",
            "Epoch 25 Batch 30: Train Loss = 0.2761\n",
            "Model Loss = 0.2761, Decov Loss = 0.1527\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2810\n",
            "valid_model Loss = 0.2810\n",
            "valid_decov Loss = 0.0866\n",
            "confusion matrix:\n",
            "[[2734   52]\n",
            " [ 322  114]]\n",
            "accuracy = 0.8839230537414551\n",
            "precision class 0 = 0.8946335315704346\n",
            "precision class 1 = 0.6867470145225525\n",
            "recall class 0 = 0.9813352227210999\n",
            "recall class 1 = 0.26146790385246277\n",
            "AUC of ROC = 0.8590231629971615\n",
            "AUC of PRC = 0.5428690053772902\n",
            "min(+P, Se) = 0.518348623853211\n",
            "f1_score = 0.3787375721012692\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 Batch 0: Train Loss = 0.2377\n",
            "Model Loss = 0.2377, Decov Loss = 0.2032\n",
            "Epoch 26 Batch 30: Train Loss = 0.2805\n",
            "Model Loss = 0.2805, Decov Loss = 0.1675\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2840\n",
            "valid_model Loss = 0.2840\n",
            "valid_decov Loss = 0.0865\n",
            "confusion matrix:\n",
            "[[2729   57]\n",
            " [ 314  122]]\n",
            "accuracy = 0.8848541378974915\n",
            "precision class 0 = 0.896812379360199\n",
            "precision class 1 = 0.6815642714500427\n",
            "recall class 0 = 0.9795405864715576\n",
            "recall class 1 = 0.27981650829315186\n",
            "AUC of ROC = 0.8563624149581459\n",
            "AUC of PRC = 0.5393794960134252\n",
            "min(+P, Se) = 0.5321100917431193\n",
            "f1_score = 0.39674796632705805\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 Batch 0: Train Loss = 0.3440\n",
            "Model Loss = 0.3440, Decov Loss = 0.1162\n",
            "Epoch 27 Batch 30: Train Loss = 0.2811\n",
            "Model Loss = 0.2811, Decov Loss = 0.1563\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2913\n",
            "valid_model Loss = 0.2913\n",
            "valid_decov Loss = 0.0677\n",
            "confusion matrix:\n",
            "[[2754   32]\n",
            " [ 355   81]]\n",
            "accuracy = 0.8798882961273193\n",
            "precision class 0 = 0.8858153820037842\n",
            "precision class 1 = 0.7168141603469849\n",
            "recall class 0 = 0.9885140061378479\n",
            "recall class 1 = 0.18577980995178223\n",
            "AUC of ROC = 0.86151349802749\n",
            "AUC of PRC = 0.5409059488081871\n",
            "min(+P, Se) = 0.525\n",
            "f1_score = 0.2950819590251169\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 Batch 0: Train Loss = 0.2457\n",
            "Model Loss = 0.2457, Decov Loss = 0.0951\n",
            "Epoch 28 Batch 30: Train Loss = 0.2787\n",
            "Model Loss = 0.2787, Decov Loss = 0.2240\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2817\n",
            "valid_model Loss = 0.2817\n",
            "valid_decov Loss = 0.1425\n",
            "confusion matrix:\n",
            "[[2708   78]\n",
            " [ 280  156]]\n",
            "accuracy = 0.8888888955116272\n",
            "precision class 0 = 0.9062918424606323\n",
            "precision class 1 = 0.6666666865348816\n",
            "recall class 0 = 0.9720028638839722\n",
            "recall class 1 = 0.35779815912246704\n",
            "AUC of ROC = 0.8573997115327623\n",
            "AUC of PRC = 0.5367528146892462\n",
            "min(+P, Se) = 0.517162471395881\n",
            "f1_score = 0.46567164154354385\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 Batch 0: Train Loss = 0.2321\n",
            "Model Loss = 0.2321, Decov Loss = 0.3090\n",
            "Epoch 29 Batch 30: Train Loss = 0.2740\n",
            "Model Loss = 0.2740, Decov Loss = 0.3708\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2874\n",
            "valid_model Loss = 0.2874\n",
            "valid_decov Loss = 0.1656\n",
            "confusion matrix:\n",
            "[[2726   60]\n",
            " [ 318  118]]\n",
            "accuracy = 0.8826815485954285\n",
            "precision class 0 = 0.8955321907997131\n",
            "precision class 1 = 0.6629213690757751\n",
            "recall class 0 = 0.9784637689590454\n",
            "recall class 1 = 0.2706421911716461\n",
            "AUC of ROC = 0.857262228574063\n",
            "AUC of PRC = 0.5324838670849734\n",
            "min(+P, Se) = 0.5160550458715596\n",
            "f1_score = 0.3843648013128178\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 Batch 0: Train Loss = 0.2990\n",
            "Model Loss = 0.2990, Decov Loss = 0.5234\n",
            "Epoch 30 Batch 30: Train Loss = 0.2732\n",
            "Model Loss = 0.2732, Decov Loss = 0.3043\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2878\n",
            "valid_model Loss = 0.2878\n",
            "valid_decov Loss = 0.1858\n",
            "confusion matrix:\n",
            "[[2622  164]\n",
            " [ 234  202]]\n",
            "accuracy = 0.8764742612838745\n",
            "precision class 0 = 0.918067216873169\n",
            "precision class 1 = 0.5519125461578369\n",
            "recall class 0 = 0.9411342144012451\n",
            "recall class 1 = 0.46330276131629944\n",
            "AUC of ROC = 0.8595376950282209\n",
            "AUC of PRC = 0.5345547052318724\n",
            "min(+P, Se) = 0.5170068027210885\n",
            "f1_score = 0.5037406592746247\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31 Batch 0: Train Loss = 0.3375\n",
            "Model Loss = 0.3375, Decov Loss = 0.4368\n",
            "Epoch 31 Batch 30: Train Loss = 0.2819\n",
            "Model Loss = 0.2819, Decov Loss = 0.7226\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2774\n",
            "valid_model Loss = 0.2774\n",
            "valid_decov Loss = 0.1251\n",
            "confusion matrix:\n",
            "[[2714   72]\n",
            " [ 296  140]]\n",
            "accuracy = 0.8857852220535278\n",
            "precision class 0 = 0.9016611576080322\n",
            "precision class 1 = 0.6603773832321167\n",
            "recall class 0 = 0.9741564989089966\n",
            "recall class 1 = 0.3211009204387665\n",
            "AUC of ROC = 0.8630776754019112\n",
            "AUC of PRC = 0.5434658104752997\n",
            "min(+P, Se) = 0.528604118993135\n",
            "f1_score = 0.4320987603310463\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32 Batch 0: Train Loss = 0.2915\n",
            "Model Loss = 0.2915, Decov Loss = 6.4650\n",
            "Epoch 32 Batch 30: Train Loss = 0.2699\n",
            "Model Loss = 0.2699, Decov Loss = 0.4425\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2824\n",
            "valid_model Loss = 0.2824\n",
            "valid_decov Loss = 0.1057\n",
            "confusion matrix:\n",
            "[[2719   67]\n",
            " [ 303  133]]\n",
            "accuracy = 0.8851644992828369\n",
            "precision class 0 = 0.8997352719306946\n",
            "precision class 1 = 0.6650000214576721\n",
            "recall class 0 = 0.9759511947631836\n",
            "recall class 1 = 0.30504587292671204\n",
            "AUC of ROC = 0.8644203981901646\n",
            "AUC of PRC = 0.5491888500998282\n",
            "min(+P, Se) = 0.5458715596330275\n",
            "f1_score = 0.4182389863900791\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33 Batch 0: Train Loss = 0.3093\n",
            "Model Loss = 0.3093, Decov Loss = 0.1263\n",
            "Epoch 33 Batch 30: Train Loss = 0.2851\n",
            "Model Loss = 0.2851, Decov Loss = 0.2030\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2771\n",
            "valid_model Loss = 0.2771\n",
            "valid_decov Loss = 0.1258\n",
            "confusion matrix:\n",
            "[[2705   81]\n",
            " [ 276  160]]\n",
            "accuracy = 0.8891992568969727\n",
            "precision class 0 = 0.9074136018753052\n",
            "precision class 1 = 0.6639004349708557\n",
            "recall class 0 = 0.97092604637146\n",
            "recall class 1 = 0.3669724762439728\n",
            "AUC of ROC = 0.8636037329504667\n",
            "AUC of PRC = 0.5491065213991483\n",
            "min(+P, Se) = 0.528604118993135\n",
            "f1_score = 0.4726735505547665\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34 Batch 0: Train Loss = 0.2314\n",
            "Model Loss = 0.2314, Decov Loss = 0.1938\n",
            "Epoch 34 Batch 30: Train Loss = 0.2797\n",
            "Model Loss = 0.2797, Decov Loss = 0.2701\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2810\n",
            "valid_model Loss = 0.2810\n",
            "valid_decov Loss = 0.1277\n",
            "confusion matrix:\n",
            "[[2685  101]\n",
            " [ 268  168]]\n",
            "accuracy = 0.8854748606681824\n",
            "precision class 0 = 0.9092448353767395\n",
            "precision class 1 = 0.624535322189331\n",
            "recall class 0 = 0.9637473225593567\n",
            "recall class 1 = 0.38532111048698425\n",
            "AUC of ROC = 0.8637004649723057\n",
            "AUC of PRC = 0.54117602356917\n",
            "min(+P, Se) = 0.536697247706422\n",
            "f1_score = 0.47659573974242925\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 Batch 0: Train Loss = 0.2401\n",
            "Model Loss = 0.2401, Decov Loss = 0.1361\n",
            "Epoch 35 Batch 30: Train Loss = 0.2777\n",
            "Model Loss = 0.2777, Decov Loss = 0.4233\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2859\n",
            "valid_model Loss = 0.2859\n",
            "valid_decov Loss = 0.1232\n",
            "confusion matrix:\n",
            "[[2741   45]\n",
            " [ 321  115]]\n",
            "accuracy = 0.8864059448242188\n",
            "precision class 0 = 0.8951665759086609\n",
            "precision class 1 = 0.71875\n",
            "recall class 0 = 0.9838477969169617\n",
            "recall class 1 = 0.2637614607810974\n",
            "AUC of ROC = 0.865446169247285\n",
            "AUC of PRC = 0.5533846502589365\n",
            "min(+P, Se) = 0.5344036697247706\n",
            "f1_score = 0.3859060326598097\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36 Batch 0: Train Loss = 0.2637\n",
            "Model Loss = 0.2637, Decov Loss = 0.1186\n",
            "Epoch 36 Batch 30: Train Loss = 0.2781\n",
            "Model Loss = 0.2781, Decov Loss = 0.2244\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2775\n",
            "valid_model Loss = 0.2775\n",
            "valid_decov Loss = 0.1404\n",
            "confusion matrix:\n",
            "[[2687   99]\n",
            " [ 274  162]]\n",
            "accuracy = 0.8842334151268005\n",
            "precision class 0 = 0.9074636697769165\n",
            "precision class 1 = 0.6206896305084229\n",
            "recall class 0 = 0.9644652009010315\n",
            "recall class 1 = 0.37155961990356445\n",
            "AUC of ROC = 0.8646039832188466\n",
            "AUC of PRC = 0.5473783164203297\n",
            "min(+P, Se) = 0.5240274599542334\n",
            "f1_score = 0.464849337188287\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37 Batch 0: Train Loss = 0.2595\n",
            "Model Loss = 0.2595, Decov Loss = 0.2700\n",
            "Epoch 37 Batch 30: Train Loss = 0.2745\n",
            "Model Loss = 0.2745, Decov Loss = 0.2620\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2779\n",
            "valid_model Loss = 0.2779\n",
            "valid_decov Loss = 0.1241\n",
            "confusion matrix:\n",
            "[[2677  109]\n",
            " [ 264  172]]\n",
            "accuracy = 0.8842334151268005\n",
            "precision class 0 = 0.9102346301078796\n",
            "precision class 1 = 0.6120996475219727\n",
            "recall class 0 = 0.9608758091926575\n",
            "recall class 1 = 0.39449542760849\n",
            "AUC of ROC = 0.8641421392677674\n",
            "AUC of PRC = 0.5476870723976082\n",
            "min(+P, Se) = 0.5321100917431193\n",
            "f1_score = 0.4797768315296522\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38 Batch 0: Train Loss = 0.2982\n",
            "Model Loss = 0.2982, Decov Loss = 0.1583\n",
            "Epoch 38 Batch 30: Train Loss = 0.2796\n",
            "Model Loss = 0.2796, Decov Loss = 0.2676\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2777\n",
            "valid_model Loss = 0.2777\n",
            "valid_decov Loss = 0.1371\n",
            "confusion matrix:\n",
            "[[2687   99]\n",
            " [ 257  179]]\n",
            "accuracy = 0.8895096182823181\n",
            "precision class 0 = 0.912703812122345\n",
            "precision class 1 = 0.6438848972320557\n",
            "recall class 0 = 0.9644652009010315\n",
            "recall class 1 = 0.41055044531822205\n",
            "AUC of ROC = 0.8641199114840257\n",
            "AUC of PRC = 0.5561039480688633\n",
            "min(+P, Se) = 0.5354691075514875\n",
            "f1_score = 0.5014005376213824\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39 Batch 0: Train Loss = 0.2447\n",
            "Model Loss = 0.2447, Decov Loss = 0.1898\n",
            "Epoch 39 Batch 30: Train Loss = 0.2702\n",
            "Model Loss = 0.2702, Decov Loss = 0.2347\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2832\n",
            "valid_model Loss = 0.2832\n",
            "valid_decov Loss = 0.1389\n",
            "confusion matrix:\n",
            "[[2745   41]\n",
            " [ 324  112]]\n",
            "accuracy = 0.8867163062095642\n",
            "precision class 0 = 0.8944281339645386\n",
            "precision class 1 = 0.7320261597633362\n",
            "recall class 0 = 0.9852835536003113\n",
            "recall class 1 = 0.2568807303905487\n",
            "AUC of ROC = 0.8634917707805081\n",
            "AUC of PRC = 0.5450750204440481\n",
            "min(+P, Se) = 0.5240274599542334\n",
            "f1_score = 0.38030561243784616\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40 Batch 0: Train Loss = 0.3522\n",
            "Model Loss = 0.3522, Decov Loss = 0.2370\n",
            "Epoch 40 Batch 30: Train Loss = 0.2759\n",
            "Model Loss = 0.2759, Decov Loss = 0.2290\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2813\n",
            "valid_model Loss = 0.2813\n",
            "valid_decov Loss = 0.1332\n",
            "confusion matrix:\n",
            "[[2717   69]\n",
            " [ 288  148]]\n",
            "accuracy = 0.8891992568969727\n",
            "precision class 0 = 0.9041597247123718\n",
            "precision class 1 = 0.6820276379585266\n",
            "recall class 0 = 0.9752333164215088\n",
            "recall class 1 = 0.33944955468177795\n",
            "AUC of ROC = 0.8641248509915238\n",
            "AUC of PRC = 0.5415634929697026\n",
            "min(+P, Se) = 0.5229357798165137\n",
            "f1_score = 0.4532924922830379\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41 Batch 0: Train Loss = 0.2468\n",
            "Model Loss = 0.2468, Decov Loss = 0.1679\n",
            "Epoch 41 Batch 30: Train Loss = 0.2696\n",
            "Model Loss = 0.2696, Decov Loss = 0.2506\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2762\n",
            "valid_model Loss = 0.2762\n",
            "valid_decov Loss = 0.1332\n",
            "confusion matrix:\n",
            "[[2727   59]\n",
            " [ 305  131]]\n",
            "accuracy = 0.8870266675949097\n",
            "precision class 0 = 0.8994063138961792\n",
            "precision class 1 = 0.6894736886024475\n",
            "recall class 0 = 0.9788227081298828\n",
            "recall class 1 = 0.30045872926712036\n",
            "AUC of ROC = 0.8642203481364884\n",
            "AUC of PRC = 0.5488956784582681\n",
            "min(+P, Se) = 0.5206422018348624\n",
            "f1_score = 0.4185303655100636\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42 Batch 0: Train Loss = 0.2649\n",
            "Model Loss = 0.2649, Decov Loss = 0.2322\n",
            "Epoch 42 Batch 30: Train Loss = 0.2683\n",
            "Model Loss = 0.2683, Decov Loss = 0.3029\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2813\n",
            "valid_model Loss = 0.2813\n",
            "valid_decov Loss = 0.1330\n",
            "confusion matrix:\n",
            "[[2655  131]\n",
            " [ 243  193]]\n",
            "accuracy = 0.8839230537414551\n",
            "precision class 0 = 0.9161490797996521\n",
            "precision class 1 = 0.595678985118866\n",
            "recall class 0 = 0.9529792070388794\n",
            "recall class 1 = 0.44266054034233093\n",
            "AUC of ROC = 0.8645323603601229\n",
            "AUC of PRC = 0.553634231853964\n",
            "min(+P, Se) = 0.5298165137614679\n",
            "f1_score = 0.50789473486409\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43 Batch 0: Train Loss = 0.1669\n",
            "Model Loss = 0.1669, Decov Loss = 0.2688\n",
            "Epoch 43 Batch 30: Train Loss = 0.2768\n",
            "Model Loss = 0.2768, Decov Loss = 0.2170\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2847\n",
            "valid_model Loss = 0.2847\n",
            "valid_decov Loss = 0.1489\n",
            "confusion matrix:\n",
            "[[2736   50]\n",
            " [ 312  124]]\n",
            "accuracy = 0.8876474499702454\n",
            "precision class 0 = 0.8976377844810486\n",
            "precision class 1 = 0.7126436829566956\n",
            "recall class 0 = 0.9820531010627747\n",
            "recall class 1 = 0.2844036817550659\n",
            "AUC of ROC = 0.8668004175530339\n",
            "AUC of PRC = 0.5487684933022232\n",
            "min(+P, Se) = 0.5275229357798165\n",
            "f1_score = 0.4065573901215152\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44 Batch 0: Train Loss = 0.3399\n",
            "Model Loss = 0.3399, Decov Loss = 0.3299\n",
            "Epoch 44 Batch 30: Train Loss = 0.2595\n",
            "Model Loss = 0.2595, Decov Loss = 0.4253\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2796\n",
            "valid_model Loss = 0.2796\n",
            "valid_decov Loss = 0.1489\n",
            "confusion matrix:\n",
            "[[2737   49]\n",
            " [ 322  114]]\n",
            "accuracy = 0.8848541378974915\n",
            "precision class 0 = 0.8947368264198303\n",
            "precision class 1 = 0.699386477470398\n",
            "recall class 0 = 0.9824120402336121\n",
            "recall class 1 = 0.26146790385246277\n",
            "AUC of ROC = 0.8658075765459013\n",
            "AUC of PRC = 0.5531608069875597\n",
            "min(+P, Se) = 0.5331807780320366\n",
            "f1_score = 0.38063438982977854\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45 Batch 0: Train Loss = 0.2561\n",
            "Model Loss = 0.2561, Decov Loss = 0.2043\n",
            "Epoch 45 Batch 30: Train Loss = 0.2691\n",
            "Model Loss = 0.2691, Decov Loss = 0.2668\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2810\n",
            "valid_model Loss = 0.2810\n",
            "valid_decov Loss = 0.1529\n",
            "confusion matrix:\n",
            "[[2734   52]\n",
            " [ 313  123]]\n",
            "accuracy = 0.8867163062095642\n",
            "precision class 0 = 0.897275984287262\n",
            "precision class 1 = 0.7028571367263794\n",
            "recall class 0 = 0.9813352227210999\n",
            "recall class 1 = 0.2821100950241089\n",
            "AUC of ROC = 0.8649711532762105\n",
            "AUC of PRC = 0.5497570240378485\n",
            "min(+P, Se) = 0.5298165137614679\n",
            "f1_score = 0.4026186602733217\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46 Batch 0: Train Loss = 0.2670\n",
            "Model Loss = 0.2670, Decov Loss = 0.2531\n",
            "Epoch 46 Batch 30: Train Loss = 0.2721\n",
            "Model Loss = 0.2721, Decov Loss = 0.3383\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2761\n",
            "valid_model Loss = 0.2761\n",
            "valid_decov Loss = 0.1470\n",
            "confusion matrix:\n",
            "[[2726   60]\n",
            " [ 305  131]]\n",
            "accuracy = 0.8867163062095642\n",
            "precision class 0 = 0.8993731737136841\n",
            "precision class 1 = 0.6858638525009155\n",
            "recall class 0 = 0.9784637689590454\n",
            "recall class 1 = 0.30045872926712036\n",
            "AUC of ROC = 0.8668012408042836\n",
            "AUC of PRC = 0.5537893788862358\n",
            "min(+P, Se) = 0.5252293577981652\n",
            "f1_score = 0.41786284808217306\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47 Batch 0: Train Loss = 0.2968\n",
            "Model Loss = 0.2968, Decov Loss = 0.1766\n",
            "Epoch 47 Batch 30: Train Loss = 0.2605\n",
            "Model Loss = 0.2605, Decov Loss = 0.2257\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2767\n",
            "valid_model Loss = 0.2767\n",
            "valid_decov Loss = 0.1333\n",
            "confusion matrix:\n",
            "[[2719   67]\n",
            " [ 284  152]]\n",
            "accuracy = 0.8910614252090454\n",
            "precision class 0 = 0.9054279327392578\n",
            "precision class 1 = 0.6940639019012451\n",
            "recall class 0 = 0.9759511947631836\n",
            "recall class 1 = 0.3486238420009613\n",
            "AUC of ROC = 0.8645480021338673\n",
            "AUC of PRC = 0.5516282734529838\n",
            "min(+P, Se) = 0.5321100917431193\n",
            "f1_score = 0.46412210860651704\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48 Batch 0: Train Loss = 0.3007\n",
            "Model Loss = 0.3007, Decov Loss = 0.1688\n",
            "Epoch 48 Batch 30: Train Loss = 0.2738\n",
            "Model Loss = 0.2738, Decov Loss = 0.2814\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2795\n",
            "valid_model Loss = 0.2795\n",
            "valid_decov Loss = 0.1407\n",
            "confusion matrix:\n",
            "[[2715   71]\n",
            " [ 289  147]]\n",
            "accuracy = 0.8882681727409363\n",
            "precision class 0 = 0.9037949442863464\n",
            "precision class 1 = 0.6743119359016418\n",
            "recall class 0 = 0.974515438079834\n",
            "recall class 1 = 0.3371559679508209\n",
            "AUC of ROC = 0.8659030736908657\n",
            "AUC of PRC = 0.55035818723638\n",
            "min(+P, Se) = 0.5321100917431193\n",
            "f1_score = 0.44954127735561833\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49 Batch 0: Train Loss = 0.2141\n",
            "Model Loss = 0.2141, Decov Loss = 0.3852\n",
            "Epoch 49 Batch 30: Train Loss = 0.2705\n",
            "Model Loss = 0.2705, Decov Loss = 0.2381\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2873\n",
            "valid_model Loss = 0.2873\n",
            "valid_decov Loss = 0.1468\n",
            "confusion matrix:\n",
            "[[2617  169]\n",
            " [ 226  210]]\n",
            "accuracy = 0.8774053454399109\n",
            "precision class 0 = 0.9205065369606018\n",
            "precision class 1 = 0.5540897250175476\n",
            "recall class 0 = 0.9393395781517029\n",
            "recall class 1 = 0.4816513657569885\n",
            "AUC of ROC = 0.8632744324505884\n",
            "AUC of PRC = 0.5554166107218185\n",
            "min(+P, Se) = 0.5275229357798165\n",
            "f1_score = 0.5153374239638253\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 Batch 0: Train Loss = 0.2641\n",
            "Model Loss = 0.2641, Decov Loss = 0.2253\n",
            "Epoch 50 Batch 30: Train Loss = 0.2602\n",
            "Model Loss = 0.2602, Decov Loss = 0.2846\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2777\n",
            "valid_model Loss = 0.2777\n",
            "valid_decov Loss = 0.0971\n",
            "confusion matrix:\n",
            "[[2737   49]\n",
            " [ 305  131]]\n",
            "accuracy = 0.890130341053009\n",
            "precision class 0 = 0.8997370004653931\n",
            "precision class 1 = 0.7277777791023254\n",
            "recall class 0 = 0.9824120402336121\n",
            "recall class 1 = 0.30045872926712036\n",
            "AUC of ROC = 0.8650007903211997\n",
            "AUC of PRC = 0.5490303682356096\n",
            "min(+P, Se) = 0.518348623853211\n",
            "f1_score = 0.4253246892481754\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51 Batch 0: Train Loss = 0.2362\n",
            "Model Loss = 0.2362, Decov Loss = 0.1263\n",
            "Epoch 51 Batch 30: Train Loss = 0.2649\n",
            "Model Loss = 0.2649, Decov Loss = 0.3246\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2806\n",
            "valid_model Loss = 0.2806\n",
            "valid_decov Loss = 0.1272\n",
            "confusion matrix:\n",
            "[[2731   55]\n",
            " [ 310  126]]\n",
            "accuracy = 0.8867163062095642\n",
            "precision class 0 = 0.8980598449707031\n",
            "precision class 1 = 0.6961326003074646\n",
            "recall class 0 = 0.9802584648132324\n",
            "recall class 1 = 0.2889908254146576\n",
            "AUC of ROC = 0.8650724131799232\n",
            "AUC of PRC = 0.5494624574172112\n",
            "min(+P, Se) = 0.5284738041002278\n",
            "f1_score = 0.4084278895296567\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52 Batch 0: Train Loss = 0.3584\n",
            "Model Loss = 0.3584, Decov Loss = 0.5263\n",
            "Epoch 52 Batch 30: Train Loss = 0.2672\n",
            "Model Loss = 0.2672, Decov Loss = 0.2163\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2781\n",
            "valid_model Loss = 0.2781\n",
            "valid_decov Loss = 0.1310\n",
            "confusion matrix:\n",
            "[[2703   83]\n",
            " [ 281  155]]\n",
            "accuracy = 0.8870266675949097\n",
            "precision class 0 = 0.9058310985565186\n",
            "precision class 1 = 0.651260495185852\n",
            "recall class 0 = 0.9702081680297852\n",
            "recall class 1 = 0.35550457239151\n",
            "AUC of ROC = 0.8646402062738331\n",
            "AUC of PRC = 0.553876781748409\n",
            "min(+P, Se) = 0.518348623853211\n",
            "f1_score = 0.4599406109835849\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53 Batch 0: Train Loss = 0.2396\n",
            "Model Loss = 0.2396, Decov Loss = 0.2263\n",
            "Epoch 53 Batch 30: Train Loss = 0.2643\n",
            "Model Loss = 0.2643, Decov Loss = 0.2208\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2796\n",
            "valid_model Loss = 0.2796\n",
            "valid_decov Loss = 0.1443\n",
            "confusion matrix:\n",
            "[[2749   37]\n",
            " [ 332  104]]\n",
            "accuracy = 0.8854748606681824\n",
            "precision class 0 = 0.8922427892684937\n",
            "precision class 1 = 0.73758864402771\n",
            "recall class 0 = 0.9867193102836609\n",
            "recall class 1 = 0.23853211104869843\n",
            "AUC of ROC = 0.8672639080066122\n",
            "AUC of PRC = 0.5545593229442793\n",
            "min(+P, Se) = 0.5321100917431193\n",
            "f1_score = 0.3604852632108618\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54 Batch 0: Train Loss = 0.2043\n",
            "Model Loss = 0.2043, Decov Loss = 0.1913\n",
            "Epoch 54 Batch 30: Train Loss = 0.2665\n",
            "Model Loss = 0.2665, Decov Loss = 0.2703\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2829\n",
            "valid_model Loss = 0.2829\n",
            "valid_decov Loss = 0.1539\n",
            "confusion matrix:\n",
            "[[2655  131]\n",
            " [ 242  194]]\n",
            "accuracy = 0.8842334151268005\n",
            "precision class 0 = 0.9164652824401855\n",
            "precision class 1 = 0.5969230532646179\n",
            "recall class 0 = 0.9529792070388794\n",
            "recall class 1 = 0.44495412707328796\n",
            "AUC of ROC = 0.8646681968163228\n",
            "AUC of PRC = 0.5544855419602848\n",
            "min(+P, Se) = 0.5377574370709383\n",
            "f1_score = 0.5098554584074423\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55 Batch 0: Train Loss = 0.2653\n",
            "Model Loss = 0.2653, Decov Loss = 0.1957\n",
            "Epoch 55 Batch 30: Train Loss = 0.2634\n",
            "Model Loss = 0.2634, Decov Loss = 0.2396\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2774\n",
            "valid_model Loss = 0.2774\n",
            "valid_decov Loss = 0.1556\n",
            "confusion matrix:\n",
            "[[2734   52]\n",
            " [ 305  131]]\n",
            "accuracy = 0.8891992568969727\n",
            "precision class 0 = 0.8996380567550659\n",
            "precision class 1 = 0.7158470153808594\n",
            "recall class 0 = 0.9813352227210999\n",
            "recall class 1 = 0.30045872926712036\n",
            "AUC of ROC = 0.8670408069179449\n",
            "AUC of PRC = 0.5590953513492629\n",
            "min(+P, Se) = 0.5321100917431193\n",
            "f1_score = 0.4232633699807017\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56 Batch 0: Train Loss = 0.2827\n",
            "Model Loss = 0.2827, Decov Loss = 0.2265\n",
            "Epoch 56 Batch 30: Train Loss = 0.2599\n",
            "Model Loss = 0.2599, Decov Loss = 0.2677\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2792\n",
            "valid_model Loss = 0.2792\n",
            "valid_decov Loss = 0.1889\n",
            "confusion matrix:\n",
            "[[2684  102]\n",
            " [ 259  177]]\n",
            "accuracy = 0.8879578113555908\n",
            "precision class 0 = 0.9119945764541626\n",
            "precision class 1 = 0.6344085931777954\n",
            "recall class 0 = 0.9633883833885193\n",
            "recall class 1 = 0.40596330165863037\n",
            "AUC of ROC = 0.8637996667478941\n",
            "AUC of PRC = 0.5550945437050976\n",
            "min(+P, Se) = 0.5319634703196348\n",
            "f1_score = 0.49510489155910514\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57 Batch 0: Train Loss = 0.2426\n",
            "Model Loss = 0.2426, Decov Loss = 0.2161\n",
            "Epoch 57 Batch 30: Train Loss = 0.2612\n",
            "Model Loss = 0.2612, Decov Loss = 0.5837\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2857\n",
            "valid_model Loss = 0.2857\n",
            "valid_decov Loss = 0.1514\n",
            "confusion matrix:\n",
            "[[2738   48]\n",
            " [ 307  129]]\n",
            "accuracy = 0.8898199796676636\n",
            "precision class 0 = 0.8991789817810059\n",
            "precision class 1 = 0.7288135886192322\n",
            "recall class 0 = 0.9827709794044495\n",
            "recall class 1 = 0.2958715558052063\n",
            "AUC of ROC = 0.864924227954978\n",
            "AUC of PRC = 0.5486151454573932\n",
            "min(+P, Se) = 0.5273972602739726\n",
            "f1_score = 0.42088091455228277\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58 Batch 0: Train Loss = 0.2309\n",
            "Model Loss = 0.2309, Decov Loss = 0.1737\n",
            "Epoch 58 Batch 30: Train Loss = 0.2611\n",
            "Model Loss = 0.2611, Decov Loss = 0.3954\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2775\n",
            "valid_model Loss = 0.2775\n",
            "valid_decov Loss = 0.1454\n",
            "confusion matrix:\n",
            "[[2692   94]\n",
            " [ 275  161]]\n",
            "accuracy = 0.8854748606681824\n",
            "precision class 0 = 0.9073137640953064\n",
            "precision class 1 = 0.6313725709915161\n",
            "recall class 0 = 0.9662598967552185\n",
            "recall class 1 = 0.3692660629749298\n",
            "AUC of ROC = 0.8632834882143351\n",
            "AUC of PRC = 0.555218962951094\n",
            "min(+P, Se) = 0.5389908256880734\n",
            "f1_score = 0.4659913431086384\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59 Batch 0: Train Loss = 0.2958\n",
            "Model Loss = 0.2958, Decov Loss = 0.2031\n",
            "Epoch 59 Batch 30: Train Loss = 0.2655\n",
            "Model Loss = 0.2655, Decov Loss = 0.4607\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2815\n",
            "valid_model Loss = 0.2815\n",
            "valid_decov Loss = 0.1374\n",
            "confusion matrix:\n",
            "[[2724   62]\n",
            " [ 291  145]]\n",
            "accuracy = 0.8904407024383545\n",
            "precision class 0 = 0.9034826159477234\n",
            "precision class 1 = 0.7004830837249756\n",
            "recall class 0 = 0.9777458906173706\n",
            "recall class 1 = 0.33256879448890686\n",
            "AUC of ROC = 0.8643825286326784\n",
            "AUC of PRC = 0.5546171868542057\n",
            "min(+P, Se) = 0.5344036697247706\n",
            "f1_score = 0.4510108859927776\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60 Batch 0: Train Loss = 0.3002\n",
            "Model Loss = 0.3002, Decov Loss = 0.1884\n",
            "Epoch 60 Batch 30: Train Loss = 0.2650\n",
            "Model Loss = 0.2650, Decov Loss = 0.2448\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2836\n",
            "valid_model Loss = 0.2836\n",
            "valid_decov Loss = 0.1595\n",
            "confusion matrix:\n",
            "[[2655  131]\n",
            " [ 252  184]]\n",
            "accuracy = 0.8811297416687012\n",
            "precision class 0 = 0.9133126735687256\n",
            "precision class 1 = 0.5841270089149475\n",
            "recall class 0 = 0.9529792070388794\n",
            "recall class 1 = 0.4220183491706848\n",
            "AUC of ROC = 0.8629895875181939\n",
            "AUC of PRC = 0.549768025278324\n",
            "min(+P, Se) = 0.5160550458715596\n",
            "f1_score = 0.49001332466976516\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61 Batch 0: Train Loss = 0.2454\n",
            "Model Loss = 0.2454, Decov Loss = 0.1795\n",
            "Epoch 61 Batch 30: Train Loss = 0.2665\n",
            "Model Loss = 0.2665, Decov Loss = 0.2342\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2960\n",
            "valid_model Loss = 0.2960\n",
            "valid_decov Loss = 0.1390\n",
            "confusion matrix:\n",
            "[[2743   43]\n",
            " [ 312  124]]\n",
            "accuracy = 0.8898199796676636\n",
            "precision class 0 = 0.8978723287582397\n",
            "precision class 1 = 0.742514967918396\n",
            "recall class 0 = 0.9845656752586365\n",
            "recall class 1 = 0.2844036817550659\n",
            "AUC of ROC = 0.8579669316438022\n",
            "AUC of PRC = 0.5535149791683068\n",
            "min(+P, Se) = 0.5263157894736842\n",
            "f1_score = 0.4112769608408325\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62 Batch 0: Train Loss = 0.2454\n",
            "Model Loss = 0.2454, Decov Loss = 0.1425\n",
            "Epoch 62 Batch 30: Train Loss = 0.2713\n",
            "Model Loss = 0.2713, Decov Loss = 0.2647\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2776\n",
            "valid_model Loss = 0.2776\n",
            "valid_decov Loss = 0.1325\n",
            "confusion matrix:\n",
            "[[2682  104]\n",
            " [ 257  179]]\n",
            "accuracy = 0.8879578113555908\n",
            "precision class 0 = 0.9125552773475647\n",
            "precision class 1 = 0.6325088143348694\n",
            "recall class 0 = 0.9626705050468445\n",
            "recall class 1 = 0.41055044531822205\n",
            "AUC of ROC = 0.8636712395529417\n",
            "AUC of PRC = 0.5575885117489995\n",
            "min(+P, Se) = 0.5193621867881549\n",
            "f1_score = 0.4979137674282089\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63 Batch 0: Train Loss = 0.2253\n",
            "Model Loss = 0.2253, Decov Loss = 0.2378\n",
            "Epoch 63 Batch 30: Train Loss = 0.2563\n",
            "Model Loss = 0.2563, Decov Loss = 0.2235\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2768\n",
            "valid_model Loss = 0.2768\n",
            "valid_decov Loss = 0.1355\n",
            "confusion matrix:\n",
            "[[2676  110]\n",
            " [ 250  186]]\n",
            "accuracy = 0.8882681727409363\n",
            "precision class 0 = 0.9145591259002686\n",
            "precision class 1 = 0.6283783912658691\n",
            "recall class 0 = 0.9605168700218201\n",
            "recall class 1 = 0.4266054928302765\n",
            "AUC of ROC = 0.8668942681954991\n",
            "AUC of PRC = 0.5673833769758472\n",
            "min(+P, Se) = 0.5321100917431193\n",
            "f1_score = 0.5081967315401443\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64 Batch 0: Train Loss = 0.2192\n",
            "Model Loss = 0.2192, Decov Loss = 0.1626\n",
            "Epoch 64 Batch 30: Train Loss = 0.2629\n",
            "Model Loss = 0.2629, Decov Loss = 0.2417\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2880\n",
            "valid_model Loss = 0.2880\n",
            "valid_decov Loss = 0.1447\n",
            "confusion matrix:\n",
            "[[2702   84]\n",
            " [ 275  161]]\n",
            "accuracy = 0.8885785341262817\n",
            "precision class 0 = 0.907625138759613\n",
            "precision class 1 = 0.6571428775787354\n",
            "recall class 0 = 0.9698492288589478\n",
            "recall class 1 = 0.3692660629749298\n",
            "AUC of ROC = 0.8619926302548128\n",
            "AUC of PRC = 0.5568422488510884\n",
            "min(+P, Se) = 0.5205479452054794\n",
            "f1_score = 0.4728340930670324\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65 Batch 0: Train Loss = 0.2245\n",
            "Model Loss = 0.2245, Decov Loss = 0.1798\n",
            "Epoch 65 Batch 30: Train Loss = 0.2564\n",
            "Model Loss = 0.2564, Decov Loss = 0.2289\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2789\n",
            "valid_model Loss = 0.2789\n",
            "valid_decov Loss = 0.1156\n",
            "confusion matrix:\n",
            "[[2698   88]\n",
            " [ 272  164]]\n",
            "accuracy = 0.8882681727409363\n",
            "precision class 0 = 0.9084175229072571\n",
            "precision class 1 = 0.6507936716079712\n",
            "recall class 0 = 0.9684134721755981\n",
            "recall class 1 = 0.3761467933654785\n",
            "AUC of ROC = 0.8649736230299598\n",
            "AUC of PRC = 0.5597305891539683\n",
            "min(+P, Se) = 0.5389908256880734\n",
            "f1_score = 0.4767441951451654\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66 Batch 0: Train Loss = 0.2361\n",
            "Model Loss = 0.2361, Decov Loss = 0.1709\n",
            "Epoch 66 Batch 30: Train Loss = 0.2572\n",
            "Model Loss = 0.2572, Decov Loss = 0.2013\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2757\n",
            "valid_model Loss = 0.2757\n",
            "valid_decov Loss = 0.1154\n",
            "confusion matrix:\n",
            "[[2716   70]\n",
            " [ 290  146]]\n",
            "accuracy = 0.8882681727409363\n",
            "precision class 0 = 0.9035263061523438\n",
            "precision class 1 = 0.6759259104728699\n",
            "recall class 0 = 0.9748743772506714\n",
            "recall class 1 = 0.3348623812198639\n",
            "AUC of ROC = 0.8660389101470657\n",
            "AUC of PRC = 0.5615832908235006\n",
            "min(+P, Se) = 0.5321100917431193\n",
            "f1_score = 0.4478527404716494\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67 Batch 0: Train Loss = 0.2906\n",
            "Model Loss = 0.2906, Decov Loss = 0.1737\n",
            "Epoch 67 Batch 30: Train Loss = 0.2579\n",
            "Model Loss = 0.2579, Decov Loss = 0.1815\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2760\n",
            "valid_model Loss = 0.2760\n",
            "valid_decov Loss = 0.1156\n",
            "confusion matrix:\n",
            "[[2701   85]\n",
            " [ 277  159]]\n",
            "accuracy = 0.8876474499702454\n",
            "precision class 0 = 0.9069845676422119\n",
            "precision class 1 = 0.6516393423080444\n",
            "recall class 0 = 0.9694902896881104\n",
            "recall class 1 = 0.36467888951301575\n",
            "AUC of ROC = 0.8657845255109096\n",
            "AUC of PRC = 0.5560014593364956\n",
            "min(+P, Se) = 0.5331807780320366\n",
            "f1_score = 0.4676470641652608\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68 Batch 0: Train Loss = 0.2264\n",
            "Model Loss = 0.2264, Decov Loss = 0.1949\n",
            "Epoch 68 Batch 30: Train Loss = 0.2532\n",
            "Model Loss = 0.2532, Decov Loss = 0.1903\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2844\n",
            "valid_model Loss = 0.2844\n",
            "valid_decov Loss = 0.1189\n",
            "confusion matrix:\n",
            "[[2702   84]\n",
            " [ 279  157]]\n",
            "accuracy = 0.8873370289802551\n",
            "precision class 0 = 0.9064072370529175\n",
            "precision class 1 = 0.6514523029327393\n",
            "recall class 0 = 0.9698492288589478\n",
            "recall class 1 = 0.3600917458534241\n",
            "AUC of ROC = 0.8651819055961327\n",
            "AUC of PRC = 0.5562724846799805\n",
            "min(+P, Se) = 0.518348623853211\n",
            "f1_score = 0.463810965439267\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69 Batch 0: Train Loss = 0.3283\n",
            "Model Loss = 0.3283, Decov Loss = 0.2161\n",
            "Epoch 69 Batch 30: Train Loss = 0.2491\n",
            "Model Loss = 0.2491, Decov Loss = 0.3245\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2863\n",
            "valid_model Loss = 0.2863\n",
            "valid_decov Loss = 0.1289\n",
            "confusion matrix:\n",
            "[[2730   56]\n",
            " [ 307  129]]\n",
            "accuracy = 0.8873370289802551\n",
            "precision class 0 = 0.8989133834838867\n",
            "precision class 1 = 0.6972972750663757\n",
            "recall class 0 = 0.979899525642395\n",
            "recall class 1 = 0.2958715558052063\n",
            "AUC of ROC = 0.8628092954945106\n",
            "AUC of PRC = 0.5635252738546807\n",
            "min(+P, Se) = 0.5331807780320366\n",
            "f1_score = 0.4154589294784175\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70 Batch 0: Train Loss = 0.2903\n",
            "Model Loss = 0.2903, Decov Loss = 0.1223\n",
            "Epoch 70 Batch 30: Train Loss = 0.2668\n",
            "Model Loss = 0.2668, Decov Loss = 0.2334\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2738\n",
            "valid_model Loss = 0.2738\n",
            "valid_decov Loss = 0.1227\n",
            "confusion matrix:\n",
            "[[2694   92]\n",
            " [ 254  182]]\n",
            "accuracy = 0.8926132917404175\n",
            "precision class 0 = 0.9138398766517639\n",
            "precision class 1 = 0.6642335653305054\n",
            "recall class 0 = 0.9669777750968933\n",
            "recall class 1 = 0.41743120551109314\n",
            "AUC of ROC = 0.8693327383970969\n",
            "AUC of PRC = 0.573530693651089\n",
            "min(+P, Se) = 0.5489749430523918\n",
            "f1_score = 0.5126760485351523\n",
            "\n",
            "\n",
            "------------ Save best model ------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71 Batch 0: Train Loss = 0.2147\n",
            "Model Loss = 0.2147, Decov Loss = 0.1956\n",
            "Epoch 71 Batch 30: Train Loss = 0.2600\n",
            "Model Loss = 0.2600, Decov Loss = 0.1971\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2871\n",
            "valid_model Loss = 0.2871\n",
            "valid_decov Loss = 0.1405\n",
            "confusion matrix:\n",
            "[[2643  143]\n",
            " [ 247  189]]\n",
            "accuracy = 0.8789571523666382\n",
            "precision class 0 = 0.9145328998565674\n",
            "precision class 1 = 0.5692771077156067\n",
            "recall class 0 = 0.9486719369888306\n",
            "recall class 1 = 0.4334862530231476\n",
            "AUC of ROC = 0.858692215994784\n",
            "AUC of PRC = 0.5407870983892136\n",
            "min(+P, Se) = 0.5114678899082569\n",
            "f1_score = 0.49218749444440235\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72 Batch 0: Train Loss = 0.2334\n",
            "Model Loss = 0.2334, Decov Loss = 0.1949\n",
            "Epoch 72 Batch 30: Train Loss = 0.2549\n",
            "Model Loss = 0.2549, Decov Loss = 0.2637\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.3045\n",
            "valid_model Loss = 0.3045\n",
            "valid_decov Loss = 0.1504\n",
            "confusion matrix:\n",
            "[[2734   52]\n",
            " [ 310  126]]\n",
            "accuracy = 0.8876474499702454\n",
            "precision class 0 = 0.8981603384017944\n",
            "precision class 1 = 0.7078651785850525\n",
            "recall class 0 = 0.9813352227210999\n",
            "recall class 1 = 0.2889908254146576\n",
            "AUC of ROC = 0.8599377951355731\n",
            "AUC of PRC = 0.5417803499194244\n",
            "min(+P, Se) = 0.5263157894736842\n",
            "f1_score = 0.41042346645169836\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73 Batch 0: Train Loss = 0.2929\n",
            "Model Loss = 0.2929, Decov Loss = 0.3936\n",
            "Epoch 73 Batch 30: Train Loss = 0.2597\n",
            "Model Loss = 0.2597, Decov Loss = 0.2567\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2854\n",
            "valid_model Loss = 0.2854\n",
            "valid_decov Loss = 0.1591\n",
            "confusion matrix:\n",
            "[[2706   80]\n",
            " [ 289  147]]\n",
            "accuracy = 0.8854748606681824\n",
            "precision class 0 = 0.9035058617591858\n",
            "precision class 1 = 0.6475771069526672\n",
            "recall class 0 = 0.9712849855422974\n",
            "recall class 1 = 0.3371559679508209\n",
            "AUC of ROC = 0.8636531280254485\n",
            "AUC of PRC = 0.5317922767457051\n",
            "min(+P, Se) = 0.5365296803652968\n",
            "f1_score = 0.44343890801283936\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74 Batch 0: Train Loss = 0.2469\n",
            "Model Loss = 0.2469, Decov Loss = 0.3138\n",
            "Epoch 74 Batch 30: Train Loss = 0.2484\n",
            "Model Loss = 0.2484, Decov Loss = 0.2822\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2860\n",
            "valid_model Loss = 0.2860\n",
            "valid_decov Loss = 0.1636\n",
            "confusion matrix:\n",
            "[[2629  157]\n",
            " [ 231  205]]\n",
            "accuracy = 0.8795778751373291\n",
            "precision class 0 = 0.9192307591438293\n",
            "precision class 1 = 0.5662983655929565\n",
            "recall class 0 = 0.9436467885971069\n",
            "recall class 1 = 0.47018349170684814\n",
            "AUC of ROC = 0.8639914842890732\n",
            "AUC of PRC = 0.555594433590575\n",
            "min(+P, Se) = 0.5315315315315315\n",
            "f1_score = 0.5137844739049012\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75 Batch 0: Train Loss = 0.2382\n",
            "Model Loss = 0.2382, Decov Loss = 0.2159\n",
            "Epoch 75 Batch 30: Train Loss = 0.2578\n",
            "Model Loss = 0.2578, Decov Loss = 0.2523\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2881\n",
            "valid_model Loss = 0.2881\n",
            "valid_decov Loss = 0.1751\n",
            "confusion matrix:\n",
            "[[2743   43]\n",
            " [ 318  118]]\n",
            "accuracy = 0.8879578113555908\n",
            "precision class 0 = 0.8961123824119568\n",
            "precision class 1 = 0.7329192757606506\n",
            "recall class 0 = 0.9845656752586365\n",
            "recall class 1 = 0.2706421911716461\n",
            "AUC of ROC = 0.8603173139616825\n",
            "AUC of PRC = 0.5529010260114867\n",
            "min(+P, Se) = 0.5217391304347826\n",
            "f1_score = 0.39530986270241947\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76 Batch 0: Train Loss = 0.2360\n",
            "Model Loss = 0.2360, Decov Loss = 0.2564\n",
            "Epoch 76 Batch 30: Train Loss = 0.2600\n",
            "Model Loss = 0.2600, Decov Loss = 0.2969\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2781\n",
            "valid_model Loss = 0.2781\n",
            "valid_decov Loss = 0.1600\n",
            "confusion matrix:\n",
            "[[2695   91]\n",
            " [ 271  165]]\n",
            "accuracy = 0.8876474499702454\n",
            "precision class 0 = 0.9086311459541321\n",
            "precision class 1 = 0.64453125\n",
            "recall class 0 = 0.9673366546630859\n",
            "recall class 1 = 0.37844038009643555\n",
            "AUC of ROC = 0.8652156588973703\n",
            "AUC of PRC = 0.5591245301941865\n",
            "min(+P, Se) = 0.536697247706422\n",
            "f1_score = 0.4768786231364729\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77 Batch 0: Train Loss = 0.2193\n",
            "Model Loss = 0.2193, Decov Loss = 0.2921\n",
            "Epoch 77 Batch 30: Train Loss = 0.2528\n",
            "Model Loss = 0.2528, Decov Loss = 0.2775\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2816\n",
            "valid_model Loss = 0.2816\n",
            "valid_decov Loss = 0.1732\n",
            "confusion matrix:\n",
            "[[2664  122]\n",
            " [ 250  186]]\n",
            "accuracy = 0.884543776512146\n",
            "precision class 0 = 0.9142072796821594\n",
            "precision class 1 = 0.6038960814476013\n",
            "recall class 0 = 0.9562095999717712\n",
            "recall class 1 = 0.4266054928302765\n",
            "AUC of ROC = 0.8631855213156214\n",
            "AUC of PRC = 0.5553123674294795\n",
            "min(+P, Se) = 0.536697247706422\n",
            "f1_score = 0.49999996977040456\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78 Batch 0: Train Loss = 0.2295\n",
            "Model Loss = 0.2295, Decov Loss = 0.2620\n",
            "Epoch 78 Batch 30: Train Loss = 0.2549\n",
            "Model Loss = 0.2549, Decov Loss = 0.2874\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2777\n",
            "valid_model Loss = 0.2777\n",
            "valid_decov Loss = 0.1651\n",
            "confusion matrix:\n",
            "[[2680  106]\n",
            " [ 263  173]]\n",
            "accuracy = 0.8854748606681824\n",
            "precision class 0 = 0.9106354117393494\n",
            "precision class 1 = 0.6200717091560364\n",
            "recall class 0 = 0.9619526267051697\n",
            "recall class 1 = 0.39678898453712463\n",
            "AUC of ROC = 0.8637971969941451\n",
            "AUC of PRC = 0.559092395056899\n",
            "min(+P, Se) = 0.5275229357798165\n",
            "f1_score = 0.4839160725383564\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79 Batch 0: Train Loss = 0.2511\n",
            "Model Loss = 0.2511, Decov Loss = 0.2181\n",
            "Epoch 79 Batch 30: Train Loss = 0.2490\n",
            "Model Loss = 0.2490, Decov Loss = 0.4001\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2810\n",
            "valid_model Loss = 0.2810\n",
            "valid_decov Loss = 0.1845\n",
            "confusion matrix:\n",
            "[[2661  125]\n",
            " [ 247  189]]\n",
            "accuracy = 0.884543776512146\n",
            "precision class 0 = 0.915061891078949\n",
            "precision class 1 = 0.6019108295440674\n",
            "recall class 0 = 0.955132782459259\n",
            "recall class 1 = 0.4334862530231476\n",
            "AUC of ROC = 0.8639602007415847\n",
            "AUC of PRC = 0.5671721422408971\n",
            "min(+P, Se) = 0.5298165137614679\n",
            "f1_score = 0.5040000248336796\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80 Batch 0: Train Loss = 0.2724\n",
            "Model Loss = 0.2724, Decov Loss = 0.3029\n",
            "Epoch 80 Batch 30: Train Loss = 0.2622\n",
            "Model Loss = 0.2622, Decov Loss = 0.2979\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2764\n",
            "valid_model Loss = 0.2764\n",
            "valid_decov Loss = 0.1670\n",
            "confusion matrix:\n",
            "[[2717   69]\n",
            " [ 286  150]]\n",
            "accuracy = 0.8898199796676636\n",
            "precision class 0 = 0.9047619104385376\n",
            "precision class 1 = 0.6849315166473389\n",
            "recall class 0 = 0.9752333164215088\n",
            "recall class 1 = 0.34403669834136963\n",
            "AUC of ROC = 0.8639700797565811\n",
            "AUC of PRC = 0.5624905550910041\n",
            "min(+P, Se) = 0.536697247706422\n",
            "f1_score = 0.4580152703354071\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81 Batch 0: Train Loss = 0.2610\n",
            "Model Loss = 0.2610, Decov Loss = 0.2494\n",
            "Epoch 81 Batch 30: Train Loss = 0.2516\n",
            "Model Loss = 0.2516, Decov Loss = 0.2772\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2848\n",
            "valid_model Loss = 0.2848\n",
            "valid_decov Loss = 0.1781\n",
            "confusion matrix:\n",
            "[[2659  127]\n",
            " [ 245  191]]\n",
            "accuracy = 0.884543776512146\n",
            "precision class 0 = 0.9156336188316345\n",
            "precision class 1 = 0.6006289124488831\n",
            "recall class 0 = 0.9544149041175842\n",
            "recall class 1 = 0.43807339668273926\n",
            "AUC of ROC = 0.8614822144800015\n",
            "AUC of PRC = 0.5626118614367668\n",
            "min(+P, Se) = 0.5398633257403189\n",
            "f1_score = 0.5066313237352972\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82 Batch 0: Train Loss = 0.2655\n",
            "Model Loss = 0.2655, Decov Loss = 0.2332\n",
            "Epoch 82 Batch 30: Train Loss = 0.2504\n",
            "Model Loss = 0.2504, Decov Loss = 0.3507\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2815\n",
            "valid_model Loss = 0.2815\n",
            "valid_decov Loss = 0.1767\n",
            "confusion matrix:\n",
            "[[2703   83]\n",
            " [ 283  153]]\n",
            "accuracy = 0.8864059448242188\n",
            "precision class 0 = 0.9052243828773499\n",
            "precision class 1 = 0.6483050584793091\n",
            "recall class 0 = 0.9702081680297852\n",
            "recall class 1 = 0.35091742873191833\n",
            "AUC of ROC = 0.8635131753130001\n",
            "AUC of PRC = 0.5609491529096784\n",
            "min(+P, Se) = 0.5298165137614679\n",
            "f1_score = 0.45535712072503287\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83 Batch 0: Train Loss = 0.2452\n",
            "Model Loss = 0.2452, Decov Loss = 0.3141\n",
            "Epoch 83 Batch 30: Train Loss = 0.2601\n",
            "Model Loss = 0.2601, Decov Loss = 0.2832\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2867\n",
            "valid_model Loss = 0.2867\n",
            "valid_decov Loss = 0.1793\n",
            "confusion matrix:\n",
            "[[2706   80]\n",
            " [ 275  161]]\n",
            "accuracy = 0.8898199796676636\n",
            "precision class 0 = 0.9077490568161011\n",
            "precision class 1 = 0.6680498123168945\n",
            "recall class 0 = 0.9712849855422974\n",
            "recall class 1 = 0.3692660629749298\n",
            "AUC of ROC = 0.8643249010451998\n",
            "AUC of PRC = 0.5629073252294828\n",
            "min(+P, Se) = 0.5275229357798165\n",
            "f1_score = 0.4756277948284691\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84 Batch 0: Train Loss = 0.1851\n",
            "Model Loss = 0.1851, Decov Loss = 0.2675\n",
            "Epoch 84 Batch 30: Train Loss = 0.2491\n",
            "Model Loss = 0.2491, Decov Loss = 0.2814\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2791\n",
            "valid_model Loss = 0.2791\n",
            "valid_decov Loss = 0.1863\n",
            "confusion matrix:\n",
            "[[2704   82]\n",
            " [ 274  162]]\n",
            "accuracy = 0.8895096182823181\n",
            "precision class 0 = 0.9079919457435608\n",
            "precision class 1 = 0.6639344096183777\n",
            "recall class 0 = 0.9705671072006226\n",
            "recall class 1 = 0.37155961990356445\n",
            "AUC of ROC = 0.8629681829857017\n",
            "AUC of PRC = 0.5652592380826476\n",
            "min(+P, Se) = 0.5344036697247706\n",
            "f1_score = 0.4764705457406902\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85 Batch 0: Train Loss = 0.2297\n",
            "Model Loss = 0.2297, Decov Loss = 0.4103\n",
            "Epoch 85 Batch 30: Train Loss = 0.2501\n",
            "Model Loss = 0.2501, Decov Loss = 0.2750\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2854\n",
            "valid_model Loss = 0.2854\n",
            "valid_decov Loss = 0.1622\n",
            "confusion matrix:\n",
            "[[2631  155]\n",
            " [ 233  203]]\n",
            "accuracy = 0.8795778751373291\n",
            "precision class 0 = 0.9186452627182007\n",
            "precision class 1 = 0.5670391321182251\n",
            "recall class 0 = 0.9443646669387817\n",
            "recall class 1 = 0.4655963182449341\n",
            "AUC of ROC = 0.8621449317360065\n",
            "AUC of PRC = 0.5560711779429565\n",
            "min(+P, Se) = 0.5275229357798165\n",
            "f1_score = 0.511335015899755\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86 Batch 0: Train Loss = 0.2537\n",
            "Model Loss = 0.2537, Decov Loss = 0.2617\n",
            "Epoch 86 Batch 30: Train Loss = 0.2548\n",
            "Model Loss = 0.2548, Decov Loss = 0.3066\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2772\n",
            "valid_model Loss = 0.2772\n",
            "valid_decov Loss = 0.1588\n",
            "confusion matrix:\n",
            "[[2699   87]\n",
            " [ 278  158]]\n",
            "accuracy = 0.8867163062095642\n",
            "precision class 0 = 0.9066174030303955\n",
            "precision class 1 = 0.6448979377746582\n",
            "recall class 0 = 0.9687724113464355\n",
            "recall class 1 = 0.3623853325843811\n",
            "AUC of ROC = 0.8651020502249122\n",
            "AUC of PRC = 0.5665148075649661\n",
            "min(+P, Se) = 0.5298165137614679\n",
            "f1_score = 0.4640235261906582\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87 Batch 0: Train Loss = 0.2369\n",
            "Model Loss = 0.2369, Decov Loss = 0.3812\n",
            "Epoch 87 Batch 30: Train Loss = 0.2515\n",
            "Model Loss = 0.2515, Decov Loss = 0.3095\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2759\n",
            "valid_model Loss = 0.2759\n",
            "valid_decov Loss = 0.1595\n",
            "confusion matrix:\n",
            "[[2723   63]\n",
            " [ 289  147]]\n",
            "accuracy = 0.8907510638237\n",
            "precision class 0 = 0.9040504693984985\n",
            "precision class 1 = 0.699999988079071\n",
            "recall class 0 = 0.9773869514465332\n",
            "recall class 1 = 0.3371559679508209\n",
            "AUC of ROC = 0.864138023011519\n",
            "AUC of PRC = 0.5671858303315672\n",
            "min(+P, Se) = 0.5377574370709383\n",
            "f1_score = 0.4551083477708292\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 88 Batch 0: Train Loss = 0.2354\n",
            "Model Loss = 0.2354, Decov Loss = 0.1994\n",
            "Epoch 88 Batch 30: Train Loss = 0.2511\n",
            "Model Loss = 0.2511, Decov Loss = 0.2995\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2837\n",
            "valid_model Loss = 0.2837\n",
            "valid_decov Loss = 0.2097\n",
            "confusion matrix:\n",
            "[[2715   71]\n",
            " [ 285  151]]\n",
            "accuracy = 0.8895096182823181\n",
            "precision class 0 = 0.9049999713897705\n",
            "precision class 1 = 0.6801801919937134\n",
            "recall class 0 = 0.974515438079834\n",
            "recall class 1 = 0.34633028507232666\n",
            "AUC of ROC = 0.8592816638895657\n",
            "AUC of PRC = 0.5480076530588989\n",
            "min(+P, Se) = 0.5123595505617977\n",
            "f1_score = 0.45896657668225155\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89 Batch 0: Train Loss = 0.2685\n",
            "Model Loss = 0.2685, Decov Loss = 0.2919\n",
            "Epoch 89 Batch 30: Train Loss = 0.2491\n",
            "Model Loss = 0.2491, Decov Loss = 0.3431\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2825\n",
            "valid_model Loss = 0.2825\n",
            "valid_decov Loss = 0.1877\n",
            "confusion matrix:\n",
            "[[2672  114]\n",
            " [ 259  177]]\n",
            "accuracy = 0.8842334151268005\n",
            "precision class 0 = 0.9116342663764954\n",
            "precision class 1 = 0.6082473993301392\n",
            "recall class 0 = 0.9590811133384705\n",
            "recall class 1 = 0.40596330165863037\n",
            "AUC of ROC = 0.861273108662579\n",
            "AUC of PRC = 0.560973032351826\n",
            "min(+P, Se) = 0.5193621867881549\n",
            "f1_score = 0.4869325914558122\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90 Batch 0: Train Loss = 0.2137\n",
            "Model Loss = 0.2137, Decov Loss = 0.2323\n",
            "Epoch 90 Batch 30: Train Loss = 0.2526\n",
            "Model Loss = 0.2526, Decov Loss = 0.3145\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2795\n",
            "valid_model Loss = 0.2795\n",
            "valid_decov Loss = 0.1747\n",
            "confusion matrix:\n",
            "[[2710   76]\n",
            " [ 272  164]]\n",
            "accuracy = 0.8919925689697266\n",
            "precision class 0 = 0.9087860584259033\n",
            "precision class 1 = 0.6833333373069763\n",
            "recall class 0 = 0.972720742225647\n",
            "recall class 1 = 0.3761467933654785\n",
            "AUC of ROC = 0.8609578034339456\n",
            "AUC of PRC = 0.5632008094995228\n",
            "min(+P, Se) = 0.5240274599542334\n",
            "f1_score = 0.4852070779360673\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91 Batch 0: Train Loss = 0.2262\n",
            "Model Loss = 0.2262, Decov Loss = 0.2222\n",
            "Epoch 91 Batch 30: Train Loss = 0.2486\n",
            "Model Loss = 0.2486, Decov Loss = 0.2721\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2810\n",
            "valid_model Loss = 0.2810\n",
            "valid_decov Loss = 0.1905\n",
            "confusion matrix:\n",
            "[[2670  116]\n",
            " [ 255  181]]\n",
            "accuracy = 0.8848541378974915\n",
            "precision class 0 = 0.9128205180168152\n",
            "precision class 1 = 0.6094276309013367\n",
            "recall class 0 = 0.9583632349967957\n",
            "recall class 1 = 0.4151376187801361\n",
            "AUC of ROC = 0.8625738456370977\n",
            "AUC of PRC = 0.5661733122616631\n",
            "min(+P, Se) = 0.5294117647058824\n",
            "f1_score = 0.4938608701572791\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92 Batch 0: Train Loss = 0.2367\n",
            "Model Loss = 0.2367, Decov Loss = 0.2818\n",
            "Epoch 92 Batch 30: Train Loss = 0.2471\n",
            "Model Loss = 0.2471, Decov Loss = 0.3244\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2823\n",
            "valid_model Loss = 0.2823\n",
            "valid_decov Loss = 0.1689\n",
            "confusion matrix:\n",
            "[[2666  120]\n",
            " [ 257  179]]\n",
            "accuracy = 0.8829919099807739\n",
            "precision class 0 = 0.9120766520500183\n",
            "precision class 1 = 0.5986621975898743\n",
            "recall class 0 = 0.956927478313446\n",
            "recall class 1 = 0.41055044531822205\n",
            "AUC of ROC = 0.864175892569005\n",
            "AUC of PRC = 0.5593868166161192\n",
            "min(+P, Se) = 0.5319634703196348\n",
            "f1_score = 0.4870748316538299\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93 Batch 0: Train Loss = 0.2512\n",
            "Model Loss = 0.2512, Decov Loss = 0.2547\n",
            "Epoch 93 Batch 30: Train Loss = 0.2513\n",
            "Model Loss = 0.2513, Decov Loss = 0.2905\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2792\n",
            "valid_model Loss = 0.2792\n",
            "valid_decov Loss = 0.2008\n",
            "confusion matrix:\n",
            "[[2663  123]\n",
            " [ 251  185]]\n",
            "accuracy = 0.8839230537414551\n",
            "precision class 0 = 0.9138640761375427\n",
            "precision class 1 = 0.600649356842041\n",
            "recall class 0 = 0.9558506608009338\n",
            "recall class 1 = 0.42431193590164185\n",
            "AUC of ROC = 0.8646064529725956\n",
            "AUC of PRC = 0.563570038628829\n",
            "min(+P, Se) = 0.5342465753424658\n",
            "f1_score = 0.49731186538476596\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94 Batch 0: Train Loss = 0.2634\n",
            "Model Loss = 0.2634, Decov Loss = 0.3017\n",
            "Epoch 94 Batch 30: Train Loss = 0.2429\n",
            "Model Loss = 0.2429, Decov Loss = 0.3384\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2756\n",
            "valid_model Loss = 0.2756\n",
            "valid_decov Loss = 0.2000\n",
            "confusion matrix:\n",
            "[[2718   68]\n",
            " [ 283  153]]\n",
            "accuracy = 0.8910614252090454\n",
            "precision class 0 = 0.9056981205940247\n",
            "precision class 1 = 0.692307710647583\n",
            "recall class 0 = 0.9755922555923462\n",
            "recall class 1 = 0.35091742873191833\n",
            "AUC of ROC = 0.864585871691353\n",
            "AUC of PRC = 0.5642053795928847\n",
            "min(+P, Se) = 0.5344036697247706\n",
            "f1_score = 0.46575341333504244\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95 Batch 0: Train Loss = 0.2958\n",
            "Model Loss = 0.2958, Decov Loss = 0.4093\n",
            "Epoch 95 Batch 30: Train Loss = 0.2438\n",
            "Model Loss = 0.2438, Decov Loss = 0.3519\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2800\n",
            "valid_model Loss = 0.2800\n",
            "valid_decov Loss = 0.1806\n",
            "confusion matrix:\n",
            "[[2736   50]\n",
            " [ 314  122]]\n",
            "accuracy = 0.8870266675949097\n",
            "precision class 0 = 0.8970491886138916\n",
            "precision class 1 = 0.7093023061752319\n",
            "recall class 0 = 0.9820531010627747\n",
            "recall class 1 = 0.27981650829315186\n",
            "AUC of ROC = 0.8597410380868957\n",
            "AUC of PRC = 0.555414082040617\n",
            "min(+P, Se) = 0.5275229357798165\n",
            "f1_score = 0.4013157807435025\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96 Batch 0: Train Loss = 0.2468\n",
            "Model Loss = 0.2468, Decov Loss = 0.6771\n",
            "Epoch 96 Batch 30: Train Loss = 0.2361\n",
            "Model Loss = 0.2361, Decov Loss = 0.3085\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2816\n",
            "valid_model Loss = 0.2816\n",
            "valid_decov Loss = 0.2010\n",
            "confusion matrix:\n",
            "[[2715   71]\n",
            " [ 289  147]]\n",
            "accuracy = 0.8882681727409363\n",
            "precision class 0 = 0.9037949442863464\n",
            "precision class 1 = 0.6743119359016418\n",
            "recall class 0 = 0.974515438079834\n",
            "recall class 1 = 0.3371559679508209\n",
            "AUC of ROC = 0.8596834104994172\n",
            "AUC of PRC = 0.5575261983720387\n",
            "min(+P, Se) = 0.5252293577981652\n",
            "f1_score = 0.44954127735561833\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97 Batch 0: Train Loss = 0.2504\n",
            "Model Loss = 0.2504, Decov Loss = 0.3192\n",
            "Epoch 97 Batch 30: Train Loss = 0.2442\n",
            "Model Loss = 0.2442, Decov Loss = 0.3442\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2845\n",
            "valid_model Loss = 0.2845\n",
            "valid_decov Loss = 0.2097\n",
            "confusion matrix:\n",
            "[[2679  107]\n",
            " [ 263  173]]\n",
            "accuracy = 0.8851644992828369\n",
            "precision class 0 = 0.9106050133705139\n",
            "precision class 1 = 0.6178571581840515\n",
            "recall class 0 = 0.9615936875343323\n",
            "recall class 1 = 0.39678898453712463\n",
            "AUC of ROC = 0.8583843200273977\n",
            "AUC of PRC = 0.5547934898795995\n",
            "min(+P, Se) = 0.5321100917431193\n",
            "f1_score = 0.48324020929407424\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98 Batch 0: Train Loss = 0.2823\n",
            "Model Loss = 0.2823, Decov Loss = 0.4487\n",
            "Epoch 98 Batch 30: Train Loss = 0.2426\n",
            "Model Loss = 0.2426, Decov Loss = 0.3114\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2854\n",
            "valid_model Loss = 0.2854\n",
            "valid_decov Loss = 0.1843\n",
            "confusion matrix:\n",
            "[[2688   98]\n",
            " [ 272  164]]\n",
            "accuracy = 0.8851644992828369\n",
            "precision class 0 = 0.908108115196228\n",
            "precision class 1 = 0.6259542107582092\n",
            "recall class 0 = 0.9648241400718689\n",
            "recall class 1 = 0.3761467933654785\n",
            "AUC of ROC = 0.859426967735137\n",
            "AUC of PRC = 0.5511771389977229\n",
            "min(+P, Se) = 0.5137614678899083\n",
            "f1_score = 0.4699140749404713\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99 Batch 0: Train Loss = 0.2232\n",
            "Model Loss = 0.2232, Decov Loss = 0.2811\n",
            "Epoch 99 Batch 30: Train Loss = 0.2405\n",
            "Model Loss = 0.2405, Decov Loss = 0.3008\n",
            "\n",
            "==>Predicting on validation\n",
            "Valid Loss = 0.2869\n",
            "valid_model Loss = 0.2869\n",
            "valid_decov Loss = 0.1841\n",
            "confusion matrix:\n",
            "[[2701   85]\n",
            " [ 277  159]]\n",
            "accuracy = 0.8876474499702454\n",
            "precision class 0 = 0.9069845676422119\n",
            "precision class 1 = 0.6516393423080444\n",
            "recall class 0 = 0.9694902896881104\n",
            "recall class 1 = 0.36467888951301575\n",
            "AUC of ROC = 0.8597311590718996\n",
            "AUC of PRC = 0.5564923436549519\n",
            "min(+P, Se) = 0.5275229357798165\n",
            "f1_score = 0.4676470641652608\n",
            "\n"
          ]
        }
      ],
      "source": [
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED) #numpy\n",
        "random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED) # cpu\n",
        "torch.cuda.manual_seed(RANDOM_SEED) #gpu\n",
        "torch.backends.cudnn.deterministic=True # cudnn\n",
        "\n",
        "model = ConCare(input_dim = 76, hidden_dim = 64, d_model = 64,  MHD_num_head = 4 , d_ff = 256, output_dim = 1).to(device)\n",
        "# input_dim, d_model, d_k, d_v, MHD_num_head, d_ff, output_dim\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "max_roc = 0\n",
        "max_prc = 0\n",
        "train_loss = []\n",
        "train_model_loss = []\n",
        "train_decov_loss = []\n",
        "valid_loss = []\n",
        "valid_model_loss = []\n",
        "valid_decov_loss = []\n",
        "history = []\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "np.set_printoptions(precision=2)\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "for each_epoch in range(100):\n",
        "    batch_loss = []\n",
        "    model_batch_loss = []\n",
        "    decov_batch_loss = []\n",
        "\n",
        "    model.train()\n",
        " \n",
        "    for step, (batch_x, batch_y, batch_name) in enumerate(train_loader):   \n",
        "        optimizer.zero_grad()\n",
        "        batch_x = batch_x.float().to(device)\n",
        "        batch_y = batch_y.float().to(device)\n",
        "\n",
        "        batch_demo = []\n",
        "        for i in range(len(batch_name)):\n",
        "            cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n",
        "            cur_idx = cur_id + '_' + cur_ep\n",
        "            cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n",
        "            batch_demo.append(cur_demo)\n",
        "        \n",
        "        batch_demo = torch.stack(batch_demo).to(device)\n",
        "        output, decov_loss = model(batch_x, batch_demo)\n",
        "        \n",
        "        \n",
        "        model_loss = get_loss(output, batch_y.unsqueeze(-1))\n",
        "        loss = model_loss + 800* decov_loss\n",
        "\n",
        "        \n",
        "        batch_loss.append(loss.cpu().detach().numpy())\n",
        "        model_batch_loss.append(model_loss.cpu().detach().numpy())\n",
        "        decov_batch_loss.append(decov_loss.cpu().detach().numpy())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if step % 30 == 0:\n",
        "            print('Epoch %d Batch %d: Train Loss = %.4f'%(each_epoch, step, np.mean(np.array(batch_loss))))\n",
        "            print('Model Loss = %.4f, Decov Loss = %.4f'%(np.mean(np.array(model_batch_loss)), np.mean(np.array(decov_batch_loss))))\n",
        "    train_loss.append(np.mean(np.array(batch_loss)))\n",
        "    train_model_loss.append(np.mean(np.array(model_batch_loss)))\n",
        "    train_decov_loss.append(np.mean(np.array(decov_batch_loss)))\n",
        "    \n",
        "    batch_loss = []\n",
        "    model_batch_loss = []\n",
        "    decov_batch_loss = []\n",
        "    \n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for step, (batch_x, batch_y, batch_name) in enumerate(valid_loader):\n",
        "            batch_x = batch_x.float().to(device)\n",
        "            batch_y = batch_y.float().to(device)\n",
        "            batch_demo = []\n",
        "            for i in range(len(batch_name)):\n",
        "                cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n",
        "                cur_idx = cur_id + '_' + cur_ep\n",
        "                cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n",
        "                batch_demo.append(cur_demo)\n",
        "\n",
        "            batch_demo = torch.stack(batch_demo).to(device)\n",
        "            output,decov_loss = model(batch_x, batch_demo)\n",
        "            \n",
        "            model_loss = get_loss(output, batch_y.unsqueeze(-1))\n",
        "\n",
        "            loss = model_loss\n",
        "            batch_loss.append(loss.cpu().detach().numpy())\n",
        "            model_batch_loss.append(model_loss.cpu().detach().numpy())\n",
        "            decov_batch_loss.append(decov_loss.cpu().detach().numpy())\n",
        "            y_pred += list(output.cpu().detach().numpy().flatten())\n",
        "            y_true += list(batch_y.cpu().numpy().flatten())\n",
        "            \n",
        "    valid_loss.append(np.mean(np.array(batch_loss)))\n",
        "    valid_model_loss.append(np.mean(np.array(model_batch_loss)))\n",
        "    valid_decov_loss.append(np.mean(np.array(decov_batch_loss)))\n",
        "    \n",
        "    print(\"\\n==>Predicting on validation\")\n",
        "    print('Valid Loss = %.4f'%(valid_loss[-1]))\n",
        "    print('valid_model Loss = %.4f'%(valid_model_loss[-1]))\n",
        "    print('valid_decov Loss = %.4f'%(valid_decov_loss[-1]))\n",
        "    y_pred = np.array(y_pred)\n",
        "    y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n",
        "    ret = metrics.print_metrics_binary(y_true, y_pred)\n",
        "    history.append(ret)\n",
        "    print()\n",
        "\n",
        "    cur_auroc = ret['auroc']\n",
        "    \n",
        "    if cur_auroc > max_roc:\n",
        "        max_roc = cur_auroc\n",
        "        state = {\n",
        "            'net': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'epoch': each_epoch\n",
        "        }\n",
        "        torch.save(state, file_name)\n",
        "        print('\\n------------ Save best model ------------\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZQbDZOdkmci"
      },
      "source": [
        "### Run for test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T03:27:16.741911Z",
          "start_time": "2021-11-02T03:27:01.578022Z"
        },
        "id": "VBdjo2Hhkmci"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load(file_name)\n",
        "save_epoch = checkpoint['epoch']\n",
        "model.load_state_dict(checkpoint['net'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "model.eval()\n",
        "\n",
        "test_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data_path, 'test'),\n",
        "                                            listfile=os.path.join(data_path, 'test_listfile.csv'),\n",
        "                                            period_length=48.0)\n",
        "test_raw = utils.load_data(test_reader, discretizer, normalizer, small_part, return_names=True)\n",
        "test_dataset = Dataset(test_raw['data'][0], test_raw['data'][1], test_raw['names'])\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T03:27:20.964397Z",
          "start_time": "2021-11-02T03:27:16.745558Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKzF0xjMkmci",
        "outputId": "4c5ec060-b306-4e36-9e44-36c973a34fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:208: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==>Predicting on test\n",
            "Test Loss = 0.2625\n",
            "confusion matrix:\n",
            "[[2761  101]\n",
            " [ 234  140]]\n",
            "accuracy = 0.8964771032333374\n",
            "precision class 0 = 0.9218697547912598\n",
            "precision class 1 = 0.5809128880500793\n",
            "recall class 0 = 0.964709997177124\n",
            "recall class 1 = 0.3743315637111664\n",
            "AUC of ROC = 0.8599993647163459\n",
            "AUC of PRC = 0.49033588539364065\n",
            "min(+P, Se) = 0.4909090909090909\n",
            "f1_score = 0.45528458426969326\n"
          ]
        }
      ],
      "source": [
        "batch_loss = []\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for step, (batch_x, batch_y, batch_name) in enumerate(test_loader):\n",
        "        batch_x = batch_x.float().to(device)\n",
        "        batch_y = batch_y.float().to(device)\n",
        "        batch_demo = []\n",
        "        for i in range(len(batch_name)):\n",
        "            cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n",
        "            cur_idx = cur_id + '_' + cur_ep\n",
        "            cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n",
        "            batch_demo.append(cur_demo)\n",
        "\n",
        "        batch_demo = torch.stack(batch_demo).to(device)\n",
        "        output = model(batch_x, batch_demo)[0]\n",
        "\n",
        "        loss = get_loss(output, batch_y.unsqueeze(-1))\n",
        "        batch_loss.append(loss.cpu().detach().numpy())\n",
        "        y_pred += list(output.cpu().detach().numpy().flatten())\n",
        "        y_true += list(batch_y.cpu().numpy().flatten())\n",
        "\n",
        "print(\"\\n==>Predicting on test\")\n",
        "print('Test Loss = %.4f'%(np.mean(np.array(batch_loss))))\n",
        "y_pred = np.array(y_pred)\n",
        "y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n",
        "test_res = metrics.print_metrics_binary(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-02T03:27:35.542743Z",
          "start_time": "2021-11-02T03:27:20.967136Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clDjYlGekmcj",
        "outputId": "d91f5b6d-7f4f-4ed8-9542-7968005ba1f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1000\n",
            "2/1000\n",
            "3/1000\n",
            "4/1000\n",
            "5/1000\n",
            "6/1000\n",
            "7/1000\n",
            "8/1000\n",
            "9/1000\n",
            "10/1000\n",
            "11/1000\n",
            "12/1000\n",
            "13/1000\n",
            "14/1000\n",
            "15/1000\n",
            "16/1000\n",
            "17/1000\n",
            "18/1000\n",
            "19/1000\n",
            "20/1000\n",
            "21/1000\n",
            "22/1000\n",
            "23/1000\n",
            "24/1000\n",
            "25/1000\n",
            "26/1000\n",
            "27/1000\n",
            "28/1000\n",
            "29/1000\n",
            "30/1000\n",
            "31/1000\n",
            "32/1000\n",
            "33/1000\n",
            "34/1000\n",
            "35/1000\n",
            "36/1000\n",
            "37/1000\n",
            "38/1000\n",
            "39/1000\n",
            "40/1000\n",
            "41/1000\n",
            "42/1000\n",
            "43/1000\n",
            "44/1000\n",
            "45/1000\n",
            "46/1000\n",
            "47/1000\n",
            "48/1000\n",
            "49/1000\n",
            "50/1000\n",
            "51/1000\n",
            "52/1000\n",
            "53/1000\n",
            "54/1000\n",
            "55/1000\n",
            "56/1000\n",
            "57/1000\n",
            "58/1000\n",
            "59/1000\n",
            "60/1000\n",
            "61/1000\n",
            "62/1000\n",
            "63/1000\n",
            "64/1000\n",
            "65/1000\n",
            "66/1000\n",
            "67/1000\n",
            "68/1000\n",
            "69/1000\n",
            "70/1000\n",
            "71/1000\n",
            "72/1000\n",
            "73/1000\n",
            "74/1000\n",
            "75/1000\n",
            "76/1000\n",
            "77/1000\n",
            "78/1000\n",
            "79/1000\n",
            "80/1000\n",
            "81/1000\n",
            "82/1000\n",
            "83/1000\n",
            "84/1000\n",
            "85/1000\n",
            "86/1000\n",
            "87/1000\n",
            "88/1000\n",
            "89/1000\n",
            "90/1000\n",
            "91/1000\n",
            "92/1000\n",
            "93/1000\n",
            "94/1000\n",
            "95/1000\n",
            "96/1000\n",
            "97/1000\n",
            "98/1000\n",
            "99/1000\n",
            "100/1000\n",
            "101/1000\n",
            "102/1000\n",
            "103/1000\n",
            "104/1000\n",
            "105/1000\n",
            "106/1000\n",
            "107/1000\n",
            "108/1000\n",
            "109/1000\n",
            "110/1000\n",
            "111/1000\n",
            "112/1000\n",
            "113/1000\n",
            "114/1000\n",
            "115/1000\n",
            "116/1000\n",
            "117/1000\n",
            "118/1000\n",
            "119/1000\n",
            "120/1000\n",
            "121/1000\n",
            "122/1000\n",
            "123/1000\n",
            "124/1000\n",
            "125/1000\n",
            "126/1000\n",
            "127/1000\n",
            "128/1000\n",
            "129/1000\n",
            "130/1000\n",
            "131/1000\n",
            "132/1000\n",
            "133/1000\n",
            "134/1000\n",
            "135/1000\n",
            "136/1000\n",
            "137/1000\n",
            "138/1000\n",
            "139/1000\n",
            "140/1000\n",
            "141/1000\n",
            "142/1000\n",
            "143/1000\n",
            "144/1000\n",
            "145/1000\n",
            "146/1000\n",
            "147/1000\n",
            "148/1000\n",
            "149/1000\n",
            "150/1000\n",
            "151/1000\n",
            "152/1000\n",
            "153/1000\n",
            "154/1000\n",
            "155/1000\n",
            "156/1000\n",
            "157/1000\n",
            "158/1000\n",
            "159/1000\n",
            "160/1000\n",
            "161/1000\n",
            "162/1000\n",
            "163/1000\n",
            "164/1000\n",
            "165/1000\n",
            "166/1000\n",
            "167/1000\n",
            "168/1000\n",
            "169/1000\n",
            "170/1000\n",
            "171/1000\n",
            "172/1000\n",
            "173/1000\n",
            "174/1000\n",
            "175/1000\n",
            "176/1000\n",
            "177/1000\n",
            "178/1000\n",
            "179/1000\n",
            "180/1000\n",
            "181/1000\n",
            "182/1000\n",
            "183/1000\n",
            "184/1000\n",
            "185/1000\n",
            "186/1000\n",
            "187/1000\n",
            "188/1000\n",
            "189/1000\n",
            "190/1000\n",
            "191/1000\n",
            "192/1000\n",
            "193/1000\n",
            "194/1000\n",
            "195/1000\n",
            "196/1000\n",
            "197/1000\n",
            "198/1000\n",
            "199/1000\n",
            "200/1000\n",
            "201/1000\n",
            "202/1000\n",
            "203/1000\n",
            "204/1000\n",
            "205/1000\n",
            "206/1000\n",
            "207/1000\n",
            "208/1000\n",
            "209/1000\n",
            "210/1000\n",
            "211/1000\n",
            "212/1000\n",
            "213/1000\n",
            "214/1000\n",
            "215/1000\n",
            "216/1000\n",
            "217/1000\n",
            "218/1000\n",
            "219/1000\n",
            "220/1000\n",
            "221/1000\n",
            "222/1000\n",
            "223/1000\n",
            "224/1000\n",
            "225/1000\n",
            "226/1000\n",
            "227/1000\n",
            "228/1000\n",
            "229/1000\n",
            "230/1000\n",
            "231/1000\n",
            "232/1000\n",
            "233/1000\n",
            "234/1000\n",
            "235/1000\n",
            "236/1000\n",
            "237/1000\n",
            "238/1000\n",
            "239/1000\n",
            "240/1000\n",
            "241/1000\n",
            "242/1000\n",
            "243/1000\n",
            "244/1000\n",
            "245/1000\n",
            "246/1000\n",
            "247/1000\n",
            "248/1000\n",
            "249/1000\n",
            "250/1000\n",
            "251/1000\n",
            "252/1000\n",
            "253/1000\n",
            "254/1000\n",
            "255/1000\n",
            "256/1000\n",
            "257/1000\n",
            "258/1000\n",
            "259/1000\n",
            "260/1000\n",
            "261/1000\n",
            "262/1000\n",
            "263/1000\n",
            "264/1000\n",
            "265/1000\n",
            "266/1000\n",
            "267/1000\n",
            "268/1000\n",
            "269/1000\n",
            "270/1000\n",
            "271/1000\n",
            "272/1000\n",
            "273/1000\n",
            "274/1000\n",
            "275/1000\n",
            "276/1000\n",
            "277/1000\n",
            "278/1000\n",
            "279/1000\n",
            "280/1000\n",
            "281/1000\n",
            "282/1000\n",
            "283/1000\n",
            "284/1000\n",
            "285/1000\n",
            "286/1000\n",
            "287/1000\n",
            "288/1000\n",
            "289/1000\n",
            "290/1000\n",
            "291/1000\n",
            "292/1000\n",
            "293/1000\n",
            "294/1000\n",
            "295/1000\n",
            "296/1000\n",
            "297/1000\n",
            "298/1000\n",
            "299/1000\n",
            "300/1000\n",
            "301/1000\n",
            "302/1000\n",
            "303/1000\n",
            "304/1000\n",
            "305/1000\n",
            "306/1000\n",
            "307/1000\n",
            "308/1000\n",
            "309/1000\n",
            "310/1000\n",
            "311/1000\n",
            "312/1000\n",
            "313/1000\n",
            "314/1000\n",
            "315/1000\n",
            "316/1000\n",
            "317/1000\n",
            "318/1000\n",
            "319/1000\n",
            "320/1000\n",
            "321/1000\n",
            "322/1000\n",
            "323/1000\n",
            "324/1000\n",
            "325/1000\n",
            "326/1000\n",
            "327/1000\n",
            "328/1000\n",
            "329/1000\n",
            "330/1000\n",
            "331/1000\n",
            "332/1000\n",
            "333/1000\n",
            "334/1000\n",
            "335/1000\n",
            "336/1000\n",
            "337/1000\n",
            "338/1000\n",
            "339/1000\n",
            "340/1000\n",
            "341/1000\n",
            "342/1000\n",
            "343/1000\n",
            "344/1000\n",
            "345/1000\n",
            "346/1000\n",
            "347/1000\n",
            "348/1000\n",
            "349/1000\n",
            "350/1000\n",
            "351/1000\n",
            "352/1000\n",
            "353/1000\n",
            "354/1000\n",
            "355/1000\n",
            "356/1000\n",
            "357/1000\n",
            "358/1000\n",
            "359/1000\n",
            "360/1000\n",
            "361/1000\n",
            "362/1000\n",
            "363/1000\n",
            "364/1000\n",
            "365/1000\n",
            "366/1000\n",
            "367/1000\n",
            "368/1000\n",
            "369/1000\n",
            "370/1000\n",
            "371/1000\n",
            "372/1000\n",
            "373/1000\n",
            "374/1000\n",
            "375/1000\n",
            "376/1000\n",
            "377/1000\n",
            "378/1000\n",
            "379/1000\n",
            "380/1000\n",
            "381/1000\n",
            "382/1000\n",
            "383/1000\n",
            "384/1000\n",
            "385/1000\n",
            "386/1000\n",
            "387/1000\n",
            "388/1000\n",
            "389/1000\n",
            "390/1000\n",
            "391/1000\n",
            "392/1000\n",
            "393/1000\n",
            "394/1000\n",
            "395/1000\n",
            "396/1000\n",
            "397/1000\n",
            "398/1000\n",
            "399/1000\n",
            "400/1000\n",
            "401/1000\n",
            "402/1000\n",
            "403/1000\n",
            "404/1000\n",
            "405/1000\n",
            "406/1000\n",
            "407/1000\n",
            "408/1000\n",
            "409/1000\n",
            "410/1000\n",
            "411/1000\n",
            "412/1000\n",
            "413/1000\n",
            "414/1000\n",
            "415/1000\n",
            "416/1000\n",
            "417/1000\n",
            "418/1000\n",
            "419/1000\n",
            "420/1000\n",
            "421/1000\n",
            "422/1000\n",
            "423/1000\n",
            "424/1000\n",
            "425/1000\n",
            "426/1000\n",
            "427/1000\n",
            "428/1000\n",
            "429/1000\n",
            "430/1000\n",
            "431/1000\n",
            "432/1000\n",
            "433/1000\n",
            "434/1000\n",
            "435/1000\n",
            "436/1000\n",
            "437/1000\n",
            "438/1000\n",
            "439/1000\n",
            "440/1000\n",
            "441/1000\n",
            "442/1000\n",
            "443/1000\n",
            "444/1000\n",
            "445/1000\n",
            "446/1000\n",
            "447/1000\n",
            "448/1000\n",
            "449/1000\n",
            "450/1000\n",
            "451/1000\n",
            "452/1000\n",
            "453/1000\n",
            "454/1000\n",
            "455/1000\n",
            "456/1000\n",
            "457/1000\n",
            "458/1000\n",
            "459/1000\n",
            "460/1000\n",
            "461/1000\n",
            "462/1000\n",
            "463/1000\n",
            "464/1000\n",
            "465/1000\n",
            "466/1000\n",
            "467/1000\n",
            "468/1000\n",
            "469/1000\n",
            "470/1000\n",
            "471/1000\n",
            "472/1000\n",
            "473/1000\n",
            "474/1000\n",
            "475/1000\n",
            "476/1000\n",
            "477/1000\n",
            "478/1000\n",
            "479/1000\n",
            "480/1000\n",
            "481/1000\n",
            "482/1000\n",
            "483/1000\n",
            "484/1000\n",
            "485/1000\n",
            "486/1000\n",
            "487/1000\n",
            "488/1000\n",
            "489/1000\n",
            "490/1000\n",
            "491/1000\n",
            "492/1000\n",
            "493/1000\n",
            "494/1000\n",
            "495/1000\n",
            "496/1000\n",
            "497/1000\n",
            "498/1000\n",
            "499/1000\n",
            "500/1000\n",
            "501/1000\n",
            "502/1000\n",
            "503/1000\n",
            "504/1000\n",
            "505/1000\n",
            "506/1000\n",
            "507/1000\n",
            "508/1000\n",
            "509/1000\n",
            "510/1000\n",
            "511/1000\n",
            "512/1000\n",
            "513/1000\n",
            "514/1000\n",
            "515/1000\n",
            "516/1000\n",
            "517/1000\n",
            "518/1000\n",
            "519/1000\n",
            "520/1000\n",
            "521/1000\n",
            "522/1000\n",
            "523/1000\n",
            "524/1000\n",
            "525/1000\n",
            "526/1000\n",
            "527/1000\n",
            "528/1000\n",
            "529/1000\n",
            "530/1000\n",
            "531/1000\n",
            "532/1000\n",
            "533/1000\n",
            "534/1000\n",
            "535/1000\n",
            "536/1000\n",
            "537/1000\n",
            "538/1000\n",
            "539/1000\n",
            "540/1000\n",
            "541/1000\n",
            "542/1000\n",
            "543/1000\n",
            "544/1000\n",
            "545/1000\n",
            "546/1000\n",
            "547/1000\n",
            "548/1000\n",
            "549/1000\n",
            "550/1000\n",
            "551/1000\n",
            "552/1000\n",
            "553/1000\n",
            "554/1000\n",
            "555/1000\n",
            "556/1000\n",
            "557/1000\n",
            "558/1000\n",
            "559/1000\n",
            "560/1000\n",
            "561/1000\n",
            "562/1000\n",
            "563/1000\n",
            "564/1000\n",
            "565/1000\n",
            "566/1000\n",
            "567/1000\n",
            "568/1000\n",
            "569/1000\n",
            "570/1000\n",
            "571/1000\n",
            "572/1000\n",
            "573/1000\n",
            "574/1000\n",
            "575/1000\n",
            "576/1000\n",
            "577/1000\n",
            "578/1000\n",
            "579/1000\n",
            "580/1000\n",
            "581/1000\n",
            "582/1000\n",
            "583/1000\n",
            "584/1000\n",
            "585/1000\n",
            "586/1000\n",
            "587/1000\n",
            "588/1000\n",
            "589/1000\n",
            "590/1000\n",
            "591/1000\n",
            "592/1000\n",
            "593/1000\n",
            "594/1000\n",
            "595/1000\n",
            "596/1000\n",
            "597/1000\n",
            "598/1000\n",
            "599/1000\n",
            "600/1000\n",
            "601/1000\n",
            "602/1000\n",
            "603/1000\n",
            "604/1000\n",
            "605/1000\n",
            "606/1000\n",
            "607/1000\n",
            "608/1000\n",
            "609/1000\n",
            "610/1000\n",
            "611/1000\n",
            "612/1000\n",
            "613/1000\n",
            "614/1000\n",
            "615/1000\n",
            "616/1000\n",
            "617/1000\n",
            "618/1000\n",
            "619/1000\n",
            "620/1000\n",
            "621/1000\n",
            "622/1000\n",
            "623/1000\n",
            "624/1000\n",
            "625/1000\n",
            "626/1000\n",
            "627/1000\n",
            "628/1000\n",
            "629/1000\n",
            "630/1000\n",
            "631/1000\n",
            "632/1000\n",
            "633/1000\n",
            "634/1000\n",
            "635/1000\n",
            "636/1000\n",
            "637/1000\n",
            "638/1000\n",
            "639/1000\n",
            "640/1000\n",
            "641/1000\n",
            "642/1000\n",
            "643/1000\n",
            "644/1000\n",
            "645/1000\n",
            "646/1000\n",
            "647/1000\n",
            "648/1000\n",
            "649/1000\n",
            "650/1000\n",
            "651/1000\n",
            "652/1000\n",
            "653/1000\n",
            "654/1000\n",
            "655/1000\n",
            "656/1000\n",
            "657/1000\n",
            "658/1000\n",
            "659/1000\n",
            "660/1000\n",
            "661/1000\n",
            "662/1000\n",
            "663/1000\n",
            "664/1000\n",
            "665/1000\n",
            "666/1000\n",
            "667/1000\n",
            "668/1000\n",
            "669/1000\n",
            "670/1000\n",
            "671/1000\n",
            "672/1000\n",
            "673/1000\n",
            "674/1000\n",
            "675/1000\n",
            "676/1000\n",
            "677/1000\n",
            "678/1000\n",
            "679/1000\n",
            "680/1000\n",
            "681/1000\n",
            "682/1000\n",
            "683/1000\n",
            "684/1000\n",
            "685/1000\n",
            "686/1000\n",
            "687/1000\n",
            "688/1000\n",
            "689/1000\n",
            "690/1000\n",
            "691/1000\n",
            "692/1000\n",
            "693/1000\n",
            "694/1000\n",
            "695/1000\n",
            "696/1000\n",
            "697/1000\n",
            "698/1000\n",
            "699/1000\n",
            "700/1000\n",
            "701/1000\n",
            "702/1000\n",
            "703/1000\n",
            "704/1000\n",
            "705/1000\n",
            "706/1000\n",
            "707/1000\n",
            "708/1000\n",
            "709/1000\n",
            "710/1000\n",
            "711/1000\n",
            "712/1000\n",
            "713/1000\n",
            "714/1000\n",
            "715/1000\n",
            "716/1000\n",
            "717/1000\n",
            "718/1000\n",
            "719/1000\n",
            "720/1000\n",
            "721/1000\n",
            "722/1000\n",
            "723/1000\n",
            "724/1000\n",
            "725/1000\n",
            "726/1000\n",
            "727/1000\n",
            "728/1000\n",
            "729/1000\n",
            "730/1000\n",
            "731/1000\n",
            "732/1000\n",
            "733/1000\n",
            "734/1000\n",
            "735/1000\n",
            "736/1000\n",
            "737/1000\n",
            "738/1000\n",
            "739/1000\n",
            "740/1000\n",
            "741/1000\n",
            "742/1000\n",
            "743/1000\n",
            "744/1000\n",
            "745/1000\n",
            "746/1000\n",
            "747/1000\n",
            "748/1000\n",
            "749/1000\n",
            "750/1000\n",
            "751/1000\n",
            "752/1000\n",
            "753/1000\n",
            "754/1000\n",
            "755/1000\n",
            "756/1000\n",
            "757/1000\n",
            "758/1000\n",
            "759/1000\n",
            "760/1000\n",
            "761/1000\n",
            "762/1000\n",
            "763/1000\n",
            "764/1000\n",
            "765/1000\n",
            "766/1000\n",
            "767/1000\n",
            "768/1000\n",
            "769/1000\n",
            "770/1000\n",
            "771/1000\n",
            "772/1000\n",
            "773/1000\n",
            "774/1000\n",
            "775/1000\n",
            "776/1000\n",
            "777/1000\n",
            "778/1000\n",
            "779/1000\n",
            "780/1000\n",
            "781/1000\n",
            "782/1000\n",
            "783/1000\n",
            "784/1000\n",
            "785/1000\n",
            "786/1000\n",
            "787/1000\n",
            "788/1000\n",
            "789/1000\n",
            "790/1000\n",
            "791/1000\n",
            "792/1000\n",
            "793/1000\n",
            "794/1000\n",
            "795/1000\n",
            "796/1000\n",
            "797/1000\n",
            "798/1000\n",
            "799/1000\n",
            "800/1000\n",
            "801/1000\n",
            "802/1000\n",
            "803/1000\n",
            "804/1000\n",
            "805/1000\n",
            "806/1000\n",
            "807/1000\n",
            "808/1000\n",
            "809/1000\n",
            "810/1000\n",
            "811/1000\n",
            "812/1000\n",
            "813/1000\n",
            "814/1000\n",
            "815/1000\n",
            "816/1000\n",
            "817/1000\n",
            "818/1000\n",
            "819/1000\n",
            "820/1000\n",
            "821/1000\n",
            "822/1000\n",
            "823/1000\n",
            "824/1000\n",
            "825/1000\n",
            "826/1000\n",
            "827/1000\n",
            "828/1000\n",
            "829/1000\n",
            "830/1000\n",
            "831/1000\n",
            "832/1000\n",
            "833/1000\n",
            "834/1000\n",
            "835/1000\n",
            "836/1000\n",
            "837/1000\n",
            "838/1000\n",
            "839/1000\n",
            "840/1000\n",
            "841/1000\n",
            "842/1000\n",
            "843/1000\n",
            "844/1000\n",
            "845/1000\n",
            "846/1000\n",
            "847/1000\n",
            "848/1000\n",
            "849/1000\n",
            "850/1000\n",
            "851/1000\n",
            "852/1000\n",
            "853/1000\n",
            "854/1000\n",
            "855/1000\n",
            "856/1000\n",
            "857/1000\n",
            "858/1000\n",
            "859/1000\n",
            "860/1000\n",
            "861/1000\n",
            "862/1000\n",
            "863/1000\n",
            "864/1000\n",
            "865/1000\n",
            "866/1000\n",
            "867/1000\n",
            "868/1000\n",
            "869/1000\n",
            "870/1000\n",
            "871/1000\n",
            "872/1000\n",
            "873/1000\n",
            "874/1000\n",
            "875/1000\n",
            "876/1000\n",
            "877/1000\n",
            "878/1000\n",
            "879/1000\n",
            "880/1000\n",
            "881/1000\n",
            "882/1000\n",
            "883/1000\n",
            "884/1000\n",
            "885/1000\n",
            "886/1000\n",
            "887/1000\n",
            "888/1000\n",
            "889/1000\n",
            "890/1000\n",
            "891/1000\n",
            "892/1000\n",
            "893/1000\n",
            "894/1000\n",
            "895/1000\n",
            "896/1000\n",
            "897/1000\n",
            "898/1000\n",
            "899/1000\n",
            "900/1000\n",
            "901/1000\n",
            "902/1000\n",
            "903/1000\n",
            "904/1000\n",
            "905/1000\n",
            "906/1000\n",
            "907/1000\n",
            "908/1000\n",
            "909/1000\n",
            "910/1000\n",
            "911/1000\n",
            "912/1000\n",
            "913/1000\n",
            "914/1000\n",
            "915/1000\n",
            "916/1000\n",
            "917/1000\n",
            "918/1000\n",
            "919/1000\n",
            "920/1000\n",
            "921/1000\n",
            "922/1000\n",
            "923/1000\n",
            "924/1000\n",
            "925/1000\n",
            "926/1000\n",
            "927/1000\n",
            "928/1000\n",
            "929/1000\n",
            "930/1000\n",
            "931/1000\n",
            "932/1000\n",
            "933/1000\n",
            "934/1000\n",
            "935/1000\n",
            "936/1000\n",
            "937/1000\n",
            "938/1000\n",
            "939/1000\n",
            "940/1000\n",
            "941/1000\n",
            "942/1000\n",
            "943/1000\n",
            "944/1000\n",
            "945/1000\n",
            "946/1000\n",
            "947/1000\n",
            "948/1000\n",
            "949/1000\n",
            "950/1000\n",
            "951/1000\n",
            "952/1000\n",
            "953/1000\n",
            "954/1000\n",
            "955/1000\n",
            "956/1000\n",
            "957/1000\n",
            "958/1000\n",
            "959/1000\n",
            "960/1000\n",
            "961/1000\n",
            "962/1000\n",
            "963/1000\n",
            "964/1000\n",
            "965/1000\n",
            "966/1000\n",
            "967/1000\n",
            "968/1000\n",
            "969/1000\n",
            "970/1000\n",
            "971/1000\n",
            "972/1000\n",
            "973/1000\n",
            "974/1000\n",
            "975/1000\n",
            "976/1000\n",
            "977/1000\n",
            "978/1000\n",
            "979/1000\n",
            "980/1000\n",
            "981/1000\n",
            "982/1000\n",
            "983/1000\n",
            "984/1000\n",
            "985/1000\n",
            "986/1000\n",
            "987/1000\n",
            "988/1000\n",
            "989/1000\n",
            "990/1000\n",
            "991/1000\n",
            "992/1000\n",
            "993/1000\n",
            "994/1000\n",
            "995/1000\n",
            "996/1000\n",
            "997/1000\n",
            "998/1000\n",
            "999/1000\n",
            "1000/1000\n",
            "auroc 0.8605(0.0092)\n",
            "auprc 0.4928(0.0280)\n",
            "minpse 0.4941(0.0227)\n"
          ]
        }
      ],
      "source": [
        "# Bootstrap\n",
        "N = len(y_true)\n",
        "N_idx = np.arange(N)\n",
        "K = 1000\n",
        "\n",
        "auroc = []\n",
        "auprc = []\n",
        "minpse = []\n",
        "for i in range(K):\n",
        "    boot_idx = np.random.choice(N_idx, N, replace=True)\n",
        "    boot_true = np.array(y_true)[boot_idx]\n",
        "    boot_pred = y_pred[boot_idx, :]\n",
        "    test_ret = metrics.print_metrics_binary(boot_true, boot_pred, verbose=0)\n",
        "    auroc.append(test_ret['auroc'])\n",
        "    auprc.append(test_ret['auprc'])\n",
        "    minpse.append(test_ret['minpse'])\n",
        "    print('%d/%d'%(i+1,K))\n",
        "    \n",
        "print('auroc %.4f(%.4f)'%(np.mean(auroc), np.std(auroc)))\n",
        "print('auprc %.4f(%.4f)'%(np.mean(auprc), np.std(auprc)))\n",
        "print('minpse %.4f(%.4f)'%(np.mean(minpse), np.std(minpse)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoM0T1vjkmcj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "ConCare-GRU-notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
